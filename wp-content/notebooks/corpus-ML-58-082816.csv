"L'apprendimento automatico (anche chiamato intelligenza computazionale, e in inglese come machine learning) rappresenta una delle aree fondamentali nel campo dell'intelligenza artificiale e si occupa della realizzazione di sistemi e algoritmi che si basano su osservazioni come dati per la rappresentazione di nuovi contenuti informativi. L'apprendimento puo avvenire catturando caratteristiche di interesse provenienti da esempi, strutture dati o sensori, per analizzarle e valutarne le relazioni tra le variabili osservate.   == Generalita == Uno degli obiettivi principali di ricerca sull'apprendimento automatico e quello di imparare a riconoscere automaticamente modelli complessi e prendere decisioni intelligenti basate su dati; la difficolta sta nel fatto che l'insieme di tutti i possibili comportamenti dati tutti gli input possibili e troppo grande per essere coperto da insiemi di esempi osservati (dati di allenamento). Da qui e necessario l'utilizzo di tecniche per generalizzare gli esempi citati, in modo da essere in grado di produrre un comportamento utile per casi nuovi. Al giorno d'oggi non siamo ancora in grado di riprodurre sistemi di apprendimento automatico simile a quello umano. Tuttavia sono stati inventati algoritmi efficaci per alcuni tipi di compiti di apprendimento, cosi significative applicazioni commerciali hanno iniziato a comparire. Per problemi come il riconoscimento vocale, algoritmi basati sull'apprendimento automatico danno i migliori risultati. Nel campo conosciuto come data mining, questi algoritmi sono utilizzati di routine per scoprire preziose conoscenze da grandi basi di dati commerciali contenenti un grande numero di informazioni. L'apprendimento automatico e di per se un campo multidisciplinare. Esso si basa sui risultati di intelligenza artificiale, probabilita e statistica, teoria della complessita computazionale, teoria di controllo, teoria dell'informazione, filosofia, psicologia, la neurobiologia e altri campi.   == Definizione formale == Tom M. Mitchell ha fornito una definizione che include qualsiasi programma per computer che migliora le sue prestazioni per un certo compito attraverso l'esperienza. Piu precisamente: Definizione: Ad esempio, un programma per computer che impara a giocare a dama potrebbe migliorare la sua performance, misurata dalla sua abilita a vincere la classe di attivita relative al giocare a dama, attraverso l'esperienza ottenuta giocando contro se stesso.   == Tipologie di algoritmi == Gli algoritmi di apprendimento automatico sono tradizionalmente divisi in cinque principali tipologie:   === Apprendimento supervisionato === Nell'apprendimento supervisionato il training data e composto da una coppia di esempi determinata da un oggetto di input (tipicamente un vettore) e un valore di output desiderato (anche chiamato supervisory signal). Un algoritmo di apprendimento supervisionato genera una funzione di inferenza (classificatore) che dovrebbe essere in grado di predire il corretto valore di output per ogni input valido.   === Apprendimento non supervisionato === Nell'apprendimento non supervisionato il problema diventa quello di trovare strutture nascoste in strutture dati non preclassificate da cui non e possibile valutare una possibile soluzione. L'apprendimento non supervisionato e strettamente collegato al problema di stima di densita in statistica.   === Apprendimento con rinforzo === La tecnica di programmazione dell'apprendimento per rinforzo si basa sul presupposto di potere ricevere degli stimoli dall'esterno a seconda delle scelte dell'algoritmo. Gli algoritmi per il reinforcement learning tentano di determinare una politica tesa a massimizzare gli incentivi cumulati ricevuti dall'agente nel corso della sua esplorazione del problema. L'apprendimento con rinforzo differisce da quello supervisionato poiche non sono mai presentate delle coppie input-output di esempi noti, ne si procede alla correzione esplicita di azioni subottimali. Volendo, gli algoritmi di apprendimento automatico possono essere classificati anche in base al modo in cui costruiscono la loro ""esperienza"" sulla base della quale poi effettuano le scelte. Da questo punto di vista si hanno:   === Esperienza con apprendimento continuo === Questi algoritmi partono dal presupposto di disporre di un meccanismo semplice in grado di valutare le scelte dell'algoritmo e quindi premiare o punire l'algoritmo a seconda del risultato, esse sono in grado di adattarsi anche a modifiche sostanziali dell'ambiente: un esempio sono i programmi di riconoscimento del parlato o i programmi di OCR che con l'utilizzo migliorano le loro prestazioni.   === Esperienza con addestramento preventivo === Questi algoritmi partono dalla constatazione che valutare costantemente le azioni dell'algoritmo puo essere un procedimento non automatizzabile oppure molto costoso e in questo caso si applica una prima fase in cui si istruisce l'algoritmo e quando il sistema viene ritenuto affidabile viene cristallizzato e reso non piu modificabile. Molti componenti elettronici usano delle reti neurali al loro interno, e i pesi sinaptici di queste reti non sono modificabili dato che sono fissati durante la realizzazione del circuito.   == Approcci ==   === Albero di decisione === L'albero di decisione e un metodo di apprendimento per approssimazione di una funzione obiettivo discreta in cui l'elemento che apprende e rappresentato da un albero di decisione. Gli alberi di decisione possono essere rappresentati da un insieme di regole if-else per migliorare la leggibilita umana.   === Rete neurale artificiale === Una rete neurale artificiale e un sistema adattivo che cambia la sua struttura basata su informazioni esterne o interne che scorrono attraverso la rete durante la fase di apprendimento. In termini pratici le reti neurali sono strutture non-lineari di dati statistici organizzate come strumenti di modellazione. Esse possono essere utilizzate per simulare relazioni complesse tra ingressi e uscite che altre funzioni analitiche non riescono a rappresentare. Inoltre esse sono robuste agli errori presenti nel training data.   === Programmazione genetica === Gli algoritmi genetici forniscono un approccio all'apprendimento che e liberamente ispirato all'evoluzione simulata. La ricerca di una soluzione del problema inizia con una popolazione di soluzioni iniziale. I membri della popolazione attuale danno luogo a una popolazione di nuova generazione per mezzo di operazioni quali la mutazione casuale e crossover, che sono modellati sui processi di evoluzione biologica. Ad ogni passo, le soluzioni della popolazione attuale sono valutate rispetto a una determinata misura di fitness, con le ipotesi piu adatte selezionate probabilisticamente come semi per la produzione della prossima generazione. Gli algoritmi genetici sono stati applicati con successo a una varieta di compiti di apprendimento e di altri problemi di ottimizzazione. Ad esempio, essi sono stati usati per imparare raccolte di norme per il controllo del robot e per ottimizzare la topologia dei parametri di apprendimento per reti neurali artificiali.   === Macchine a vettori di supporto === Macchine a vettori di supporto (Support Vector Machine, SVM) sono un insieme di metodi di apprendimento supervisionato usati per la classificazione e la regressione di pattern. Dato un insieme di esempi di addestramento, ciascuno contrassegnato come appartenente a due possibili categorie, un algoritmo di addestramento SVM costruisce un modello in grado di prevedere a quale categoria deve appartenere un nuovo esempio di input.   === Clustering === La cluster analisi, o clustering, e l'assegnazione di un insieme di osservazioni in sottogruppi (clusters) in modo che le osservazioni nello stesso cluster sono simili in certe caratteristiche. Il clustering e un metodo di apprendimento non supervisionato, e una tecnica comune per l'analisi statistica dei dati.   === Reti bayesiane === Il ragionamento bayesiano fornisce un approccio probabilistico di inferenza. Esso si basa sul presupposto che le quantita di interesse sono disciplinate da distribuzioni di probabilita e che le decisioni ottimali possono essere prese a seguito dell'analisi di queste probabilita insieme ai dati osservati. Nell'ambito dell'apprendimento automatico, la teoria Bayesiana e importante perche fornisce un approccio quantitativo per valutare le prove a sostegno dell'ipotesi alternativa. Il Ragionamento bayesiano fornisce la base per l'apprendimento negli algoritmi che manipolano direttamente le probabilita.   == Campi di utilizzo == Intelligenza artificiale: Rappresentazioni simboliche di apprendimento dei concetti. Macchina di apprendimento come un problema di ricerca. Apprendimento come approccio alternativo per migliorare la soluzione dei problemi. Metodi baesiani: Teorema di Bayes come base per il calcolo delle probabilita di ipotesi. Il classificatore Naive Bayes. teoria della complessita: Limiti teorici della complessita intrinseca dei diversi compiti di apprendimento, misurato in termini di sforzo computazionale. teoria del controllo: Procedure per imparare a controllare i processi al fine di ottimizzare gli obiettivi predefiniti e che imparano a predire lo stato successivo del processo che si sta controllando. teoria dell'informazione: Misure di entropia e di contenuto informativo. Lunghezza minima descrizione delle modalita di apprendimento. Codici ottimali e la loro relazione alle sequenze di allenamento ottimale per la codifica di una ipotesi. Filosofia: Rasoio di Occam, suggerisce che l'ipotesi piu semplice e la migliore. Analisi della giustificazione per generalizzare i dati osservati. Psicologia e neurobiologia: La legge di potenza della pratica, che stabilisce che in un intervallo molto ampio di problemi di apprendimento, il tempo di risposta della gente migliora con la pratica secondo una legge di potenza. Gli studi neurobiologici motivano modelli di reti neurali artificiali di apprendimento.   == Esempi di applicazioni pratiche ==   === Riconoscimento vocale del testo === Tutti i sistemi di riconoscimento vocale di maggior successo utilizzano metodi di apprendimento automatico. Ad esempio, il SPHINXsystem impara le strategie di altoparlanti specifici per riconoscere i suoni primitivi (fonemi) e le parole del segnale vocale osservato. Metodi di apprendimento basati su reti neurali e su modelli di Markov nascosti sono efficaci per la personalizzazione automatica di vocabolari, caratteristiche del microfono, rumore di fondo, ecc.   === Guida automatica di veicoli === Metodi di apprendimento automatico sono stati usati per addestrare i veicoli controllati da computer. Ad esempio, il sistema ALVINN ha usato le sue strategie per imparare a guidare senza assistenza a 70 miglia all'ora per 90 miglia su strade pubbliche, tra le altre auto. Con tecniche simili sono possibili applicazioni in molti problemi di controllo basato su sensori.   === Classificazione di nuove strutture astronomiche === Metodi di apprendimento automatico sono stati applicati ad una varieta di database di grandi dimensioni per imparare regolarita generali implicito nei dati. Ad esempio, algoritmi di apprendimento basati su alberi di decisione sono stati usati dalla NASA per classificare oggetti celesti a partire dal secondo Palomar Observatory Sky Survey. Questo sistema e oggi utilizzato per classificare automaticamente tutti gli oggetti nel Sky Survey, che si compone di tre terabyte di dati immagine.   === Giocatore di backgammon di classe mondiale === I programmi per computer di maggior successo per il gioco del backgammon sono basati su algoritmi di apprendimento. Ad esempio, il miglior programma di computer al mondo per backgammon, TD-Gammon, ha sviluppato la sua strategia giocando oltre un milione di partite di prova contro se stesso. Tecniche simili hanno applicazioni in molti problemi pratici in cui gli spazi di ricerca molto rilevanti devono essere esaminati in modo efficiente.   == Note ==   == Bibliografia == Alpaydin, E. (2004), Introduction to Machine Learning, the MIT Press. Langley, P. (1996), Elements of Machine Learning, Morgan Kaufmann. Mitchell, T. (1997), Machine Learning, McGraw Hill. ISBN 0-07-042807-7 Witten, I. & Frank, E. (2005), Data Mining: Practical Machine Learning Tools and Techniques, Morgan Kaufmann.   == Voci correlate == Overfitting Process mining Data mining Apprendimento approfondito Apprendimento supervisionato Apprendimento non supervisionato Apprendimento per rinforzo Vladimir Vapnik, Alexey Cervonenkis 20q Teorema del brutto anatroccolo Rete neurale Rete neurale a base radiale   == Altri progetti ==   Wikimedia Commons contiene immagini o altri file su apprendimento automatico"
Nell'apprendimento automatico, l'insieme di esempi utilizzati per valutare le prestazioni di un sistema prende il nome di test set. I test set sono utilizzati in diverse aree dell'informatica quali intelligenza artificiale, apprendimento automatico, programmazione genetica, sistemi intelligenti e nell'area della statistica.   == Motivazione == L'apprendimento di un classificatore supervisionato e tipicamente effettuato a partire da un insieme di addestramento (training set). Molti approcci alla supervisione cercano relazioni empiriche tra i dati dell'insieme di addestramento che tendono a generare il fenomeno del cosiddetto sovradattamento (overfitting). Cio significa che tendono a identificare relazioni nell'insieme di addestramento che non valgono in generale. Per verificare se le relazioni empiriche apprese dal classificatore sono realmente generali, si valuta il classificatore su un test set, tipicamente disgiunto dall'insieme di addestramento.   == Voci correlate == Training set Classificatore   == Bibliografia ==
La classificazione statistica e quell'attivita che si serve di un algoritmo statistico al fine di individuare una rappresentazione di alcune caratteristiche di un'entita da classificare (oggetto o nozione), associandole una etichetta classificatoria. Tale attivita puo essere svolta mediante algoritmi di apprendimento automatico supervisionato o non supervisionato. Esempi di questi algoritmi sono: classificatore bayesiano ingenuo (Naive Bayes) reti neurali macchine a vettori di supporto regressione logistica I programmi che effettuano l'attivita di classificazione sono detti classificatori. Talora si usa l'aggettivo statistica anche per classificazioni utilizzate per costruire indicazioni statistiche sulle entita assegnate ai diversi contenitori di una classificazione, soprattutto nel caso delle tassonomie, mentre nella definizione della classificazione non si sono utilizzati precisi metodi statistici.   == Bibliografia ==
Il riconoscimento di pattern (in inglese, pattern recognition) e una sottoarea dell'apprendimento automatico. Esso consiste nell'analisi e identificazione di pattern all'interno di dati grezzi al fine di identificarne la classificazione. La maggior parte della ricerca nel campo riguarda metodi di apprendimento supervisionato e non supervisionato. Il pattern recognition ha come obiettivo quello di apprendere un classificatore di dati (pattern) basati su conoscenza a priori o informazioni statistiche estratte dai pattern. I pattern da classificare sono tipicamente gruppi di misure od osservazioni, che definiscono punti in un appropriato spazio multidimensionale (al contrario del pattern matching, in cui il pattern e specificato in modo rigido). Il riconoscimento di pattern e studiato in molti campi, tra cui psicologia, psichiatria, etologia, scienze cognitive e informatica.   == Voci correlate == Pattern Apprendimento automatico Riconoscimento facciale Riconoscimento delle immagini
Il dendrogramma e uno strumento grafico per la visualizzazione dei coefficiente di similarita quantificato dalle varie macchine e dai vari cluster nel processo di raggruppamento. Nelle tecniche di clustering, il dendrogramma viene utilizzato per fornire una rappresentazione grafica del processo di raggruppamento delle istanze (o unita statistiche, o records, o elementi dell'insieme), che esprime: nell'asse delle ascisse, la distanza logica dei clusters secondo la metrica definita nell'asse delle ordinate, il livello gerarchico di aggregazione (valori interi positivi) La scelta del livello gerarchico (del valore dell'asse Y) definisce la partizione rappresentativa del processo di aggregazione.   == Voci correlate == Clustering Clustering gerarchico   == Altri progetti ==   Wikimedia Commons contiene immagini o altri file su Dendrogramma
In matematica e nell'apprendimento automatico, un classificatore e una mappatura da uno spazio (discreto o continuo) di feature X a un insieme di etichette Y. Un classificatore puo essere prefissato o basato su apprendimento automatico. Questi ultimi tipi di classificatori si dividono in supervisionati e non supervisionati, secondo se fanno uso o meno di un insieme di addestramento per apprendere il modello di classificazione. Esempi di classificatori basati sull'apprendimento automatico sono le reti neurali, i classificatori bayesiani e gli alberi di decisione.   == Voci correlate == Apprendimento supervisionato Apprendimento non supervisionato
"L'apprendimento supervisionato e una tecnica di apprendimento automatico che mira a istruire un sistema informatico in modo da consentirgli di risolvere dei compiti in maniera autonoma sulla base di una serie di esempi ideali, costituiti da coppie di input e di output desiderati, che gli vengono inizialmente forniti. Algoritmi di apprendimento supervisionato possono essere utilizzati nei piu disparati settori. Degli esempi riguardano il campo medico in cui si puo prevedere lo scatenarsi di particolari crisi sulla base dell'esperienza di passati dati biometrici, l'identificazione vocale che migliora sulla base degli ascolti audio passati, l'identificazione della scrittura manuale che si perfeziona sulle osservazioni degli esempi sottoposti dall'utente.   == Descrizione == L'obiettivo di un sistema basato sull'apprendimento supervisionato e quello di produrre un'ipotesi induttiva ossia una funzione in grado di produrre i risultati forniti durante la fase di esempio e in grado di avvicinarsi a dei risultati desiderati per tutti gli esempi non forniti.   === Componenti logici === Dal punto di vista logico, una classica implementazione di apprendimento supervisionato e costituita da: Un insieme esperienza E che contiene esempi del comportamento che si desidera nel sistema. E rappresentato come un insieme di coppie di input-output. Degli input I che rappresentano gli input al sistema e che tipicamente sono forniti sotto forma di vettori. Degli output O che rappresentano le risposte del sistema e che possono assumere forma di valori continui (regressione) o di etichetta numerica. Una funzione ha, chiamata ipotesi induttiva, che ad ogni dato in ingresso I associa l'ipotetica risposta corretta del sistema O. ha rappresenta la parte di sistema che deve cambiare per ottimizzare l'efficienza del suo comportamento. Un'ipotetica funzione hb, chiamata funzione obiettivo, che ad ogni dato in ingresso I associa la risposta corretta desiderata dal progettista-utilizzatore. E una formalizzazione teorica dei voleri del progettista-utilizzatore. Un parametro di efficienza F che rappresenta l'efficienza del sistema. Generalmente, a parita di input, consiste nella differenza di output tra ha e hb.   === Funzionamento generale === Tutti gli algoritmi di apprendimento supervisionato partono dal presupposto che, se forniamo al sistema un numero adeguato di esempi, questo accumulera un'esperienza E sufficiente da permettergli di creare una funzione ha adeguata ad approssimare la funzione hb (e quindi il comportamento desiderato da chi ha fornito gli esempi). Data la similitudine tra le funzioni ha e hb, quando proporremo al sistema dei dati in ingresso non presenti nella sua esperienza E, la funzione ha dovrebbe essere in grado di approssimare in maniera sufficientemente precisa la funzione hb e fornire delle risposte O sufficientemente soddisfacenti. Per raggiungere questo obiettivo il sistema sfrutta spesso due principi che sono quello della distribuzione (matematica) e quello della funzione di verosimiglianza. Una volta identificata la distribuzione matematica che lega il variare dei valori degli input ai valori degli output desiderati il sistema sceglie i parametri che massimizzano la probabilita dei dati ed esprime la funzione di verosimiglianza appropriata.   == Considerazioni == Molti di questi algoritmi funzionano in maniera efficiente se lavorano in un mondo lineare, presupponendo che ad ingressi simili corrispondano uscite simili. Esistono molte condizioni in cui una simile approssimazione e accettabile ma non sempre e cosi. La stima della funzione di verosimiglianza serve ad attenuare le problematiche che derivano dalla trattazione di problemi non completamente lineari. Si puo facilmente intuire che il funzionamento corretto ed efficiente di questi algoritmi dipende in modo significativo dall'esperienza; se si fornisce poca esperienza, l'algoritmo potrebbe non creare una funzione interna efficiente, mentre con un'esperienza eccessiva la funzione interna potrebbe divenire molto complessa tanto da rendere lenta l'esecuzione dell'algoritmo. Questi algoritmi sono molto sensibili al rumore, anche pochi dati errati potrebbero rendere l'intero sistema non affidabile e condurlo a decisioni errate. Una soluzione a questo problema e quello di associarli a controllori che si basano sulla logica logica fuzzy. Tradizionalmente i principali algoritmi sono stati: albero di decisione regole di decisione sistemi esperti La ricerca oggi si concentra su quelle che sono considerate le due classi principali di algoritmi possibili: Metodi Generativi Metodi Discriminativi I metodi generativi si basano sulla creazione di un modello dei dati che poi viene utilizzato per predire le risposte desiderate (o dati di uscita). Esempi sono le reti Bayesiane o piu in generale i modelli grafici. I metodi discriminativi al contrario cercano di modellare direttamente la relazione tra dati in entrata e quelli in uscita, in modo da minimizzare una funzione di perdita (loss function in letteratura). Esempi di questo tipo di modello sono le macchine a vettori di supporto (Support Vector Machines) e piu in generale i metodi basati su funzioni di kernel.   == Voci correlate == Apprendimento non supervisionato Apprendimento per rinforzo Version space"
Scikit-learn (ex scikits.learn) e una libreria open source di apprendimento automatico per il linguaggio di programmazione Python. Contiene algoritmi di Classificazione, regressione e clustering (raggruppamento) e Macchine a vettori di supporto, regressione logistica, Classificatore bayesiano, k-mean e DBSCAN, ed e progettato per operare con le librerie NumPy e SciPy. scikit-learn e attualmente sponsorizzato da INRIA e talvolta da Google.   == Voci correlate == Python Apprendimento automatico mlpy Orange NLTK   == Collegamenti esterni == (EN) Scikit-learn, scikit-learn.org. (EN) Scikit-learn in github, github.com.
L'apprendimento non supervisionato e una tecnica di apprendimento automatico che consiste nel fornire al sistema informatico una serie di input (esperienza del sistema) che egli riclassifichera ed organizzera sulla base di caratteristiche comuni per cercare di effettuare ragionamenti e previsioni sugli input successivi. Al contrario dell'apprendimento supervisionato, durante l'apprendimento vengono forniti all'apprendista solo esempi non annotati, in quanto le classi non sono note a priori ma devono essere apprese automaticamente. Un esempio tipico di questi algoritmi lo si ha nei motori di ricerca. Questi programmi, data una o piu parole chiave, sono in grado di creare una lista di link rimandanti alle pagine che l'algoritmo di ricerca ritiene attinenti alla ricerca effettuata. La validita di questi algoritmi e legata alla utilita delle informazioni che riescono ad estrarre dalla base di dati, nell'esempio sopracitato e legata all'attinenza dei link con l'argomento cercato. Le tecniche di apprendimento non supervisionato lavorano confrontando i dati e ricercando similarita o differenze. Sono molto efficienti con elementi di tipo numerico, dato che possono utilizzare tutte le tecniche derivate dalla statistica, ma risultano essere meno efficienti con dati non numerici. Se i dati sono dotati di un ordinamento intrinseco, gli algoritmi riescono comunque ad estrarre informazioni, al contrario possono fallire. Se i dati non sono dotati di ordinamento cercare di ordinarli imponendo una graduatoria arbitraria non risolve il problema. Questo si puo facilmente capire con un esempio. Supponiamo di disporre di un database con l'elenco dei colori utilizzati da uno stilista. Si potrebbe cercare di associare ad ogni colore uno specifico numero e su quello fare delle analisi di tipo statistico. Ma dato che l'associazione tra colore e numero e arbitraria si possono pensare ad infinite associazioni che darebbero infiniti risultati diversi. Questi algoritmi in conclusione lavorano correttamente in presenza di dati contenenti un ordinamento o un raggruppamento netto e chiaramente identificabile. Principali algoritmi: Clustering Regole di associazione   == Voci correlate == Apprendimento supervisionato Apprendimento per rinforzo
"L'intelligenza artificiale (o IA, dalle iniziali delle due parole, in italiano) e l'abilita di un computer di svolgere funzioni e ragionamenti tipici della mente umana. L'intelligenza artificiale e una disciplina dibattuta tra scienziati e filosofi, che manifesta aspetti teorici e pratici oltre che etici. Nel suo aspetto puramente informatico, essa comprende la teoria e le tecniche per lo sviluppo di algoritmi che consentano alle macchine (tipicamente ai calcolatori) di mostrare un'abilita e/o attivita intelligente, almeno in domini specifici. Uno dei problemi principali dell'intelligenza artificiale e quello di dare una definizione formale delle funzioni sintetiche/astratte di ragionamento, meta-ragionamento e apprendimento dell'uomo, per poter poi costruire dei modelli computazionali che le concretizzano e realizzano (in modo orientato all'obiettivo).   == Origine del termine == L'espressione ""Intelligenza Artificiale"" (Artificial Intelligence) fu coniata nel 1956 dal matematico statunitense John McCarthy, durante un seminario interdisciplinare svoltosi nel New Hampshire. Secondo le parole di Marvin Minsky, uno dei ""pionieri"" della I.A., lo scopo di questa nuova disciplina sarebbe stato quello di ""far fare alle macchine delle cose che richiederebbero l'intelligenza se fossero fatte dagli uomini"".   == Storia ==   === I primi passi === Nel XVII secolo, Blaise Pascal inventa la cosiddetta Pascalina per aiutare il padre, incaricato dall'amministrazione fiscale della Normandia di eseguire un difficile lavoro di calcolo. La macchina era capace di eseguire automaticamente addizione e sottrazione; questa ""macchina aritmetica"" fu la capostipite dei calcolatori ad ingranaggi. In eta vittoriana, Charles Babbage creo macchine calcolatrici a rotelle: la macchina differenziale (The difference engine) riusciva a compiere calcoli differenziali, e Babbage arrivo a progettarne una programmabile, che pero, per problemi tecnici, non riusci mai a funzionare e che avrebbe dovuto essere programmata con schede perforate, come accadde in seguito con i primi calcolatori. Le schede perforate, cartoncini forati a seconda della necessita, furono ampiamente usate, per esempio, per il funzionamento del Telaio Jacquard, di pianole meccaniche, e poi dei primi calcolatori. Herman Hollerith (statistico statunitense di origine tedesca) ideo le schede perforate applicate a calcolatrici attorno al 1885; questo sistema fu usato per la prima volta per i calcoli relativi all'11o censimento U.S.A., nel 1891. Il sistema meccanografico adottato da Hollerith riscosse tale successo da indurlo a fondare la Tabulating Machine Company. In seguito i calcolatori furono usati dalle forze armate per regolare il tiro dell'artiglieria.   === La rivoluzione informatica === Se la teoria dell'IA evolve indipendentemente dai progressi scientifici, le sue applicazioni sono fortemente legate agli avanzamenti della tecnologia informatica. Infatti, solo nella seconda meta del XX secolo e possibile disporre di dispositivi di calcolo e linguaggi di programmazione abbastanza potenti da permettere sperimentazioni sull'intelligenza. La struttura dei calcolatori viene stravolta dalla sostituzione dei rele, usati per i primi calcolatori elettromeccanici, con le valvole termoioniche o tubi elettronici. Nel 1946 nasce ENIAC (Electronic Numerical Integrator And Calculator), concepito come calcolatore moderno nel 1945 da John von Neumann: eseguiva l'elaborazione a lotti (batch) nell'ordine di migliaia di informazioni al minuto. La programmazione avveniva comunque tramite schede. La seconda generazione di computer si ha negli anni sessanta, The time sharing, sistemi basati sulla divisione di tempo e quindi piu veloci; piu terminali, soprattutto telescriventi, sono collegati a un calcolatore centrale. L'innovazione in questo periodo sta nel passaggio dalle valvole termoioniche ai transistor. A quell'epoca i programmi erano fortemente condizionati dai limiti dei linguaggi di programmazione, oltre che dai limiti di velocita e memoria degli elaboratori. La svolta si ha proprio tra gli anni '50 e '60, con linguaggi di manipolazione simbolica come l'ILP, il Lisp e il POP.   === Il test di Turing === Un punto di svolta della materia si ha con un articolo di Alan Turing sulla rivista Mind nel 1950. Nell'articolo viene indicata la possibilita di creare un programma al fine di far comportare un computer in maniera intelligente. Il test di Turing - cosi viene chiamata la condizione che la macchina dovrebbe superare per essere considerata intelligente - e stato piu volte superato da programmi (chatterbot) e piu volte riformulato, tanto che queste teorie hanno ricevuto diverse confutazioni. Il filosofo Searle ne espose una famosa, chiamata la stanza cinese. Nello stesso anno dell'articolo di Turing sull'omonimo test per le macchine pensanti, Arthur Samuel presenta il primo programma capace di giocare a Dama, un risultato molto importante perche dimostra la possibilita di superare i limiti tecnici (il programma era scritto in Assembly e girava su un IBM 704) per realizzare sistemi capaci di risolvere problemi tradizionalmente legati all'intelligenza umana. Per di piu, l'abilita di gioco viene appresa dal programma giocando contro avversari umani. Nel 1956, alla conferenza di Dartmouth (la stessa conferenza a cui l'IA deve il suo nome), viene mostrato un programma che segna un'altra importante tappa dello sviluppo dell'IA. Il programma LT di Allen Newell, J. Clifford Shaw e Herbert Simon rappresenta il primo dimostratore automatico di teoremi. La linea seguita dalla giovane IA si basa quindi sulla ricerca di un automatismo nella creazione di un'intelligenza meccanica. L'approccio segue essenzialmente un'euristica di ricerca basata su ""tentativi ed errori"" (trial and error), oltre che investigare su tecniche di apprendimento efficaci.   === Verso l'IA moderna === Secondo le parole di Minsky, dopo il 1962 l'IA cambia le sue priorita: essa da minore importanza all'apprendimento, mentre pone l'accento sulla rappresentazione della conoscenza e sul problema a essa connesso del superamento del formalismo finora a disposizione e liberarsi dalle costrizioni dei vecchi sistemi. Il problema della ricerca efficace con euristiche rimane un presupposto soggiacente, ma non e piu il problema a quale pensare, per quanto siamo immersi in sotto-problemi piu sofisticati, ossia la rappresentazione e modifica di piani (Minsky, 1968). I punti cardine di questa ricerca sono gli studi di Minsky sulla rappresentazione distribuita della conoscenza, quella che viene chiamata la ""societa delle menti"", e il lavoro di John McCarthy sulla rappresentazione dichiarativa della conoscenza. Quest'ultima viene espressa formalmente mediante estensioni della logica dei predicati e puo quindi essere manipolata facilmente. Con i suoi studi sul ""ragionamento non monotono"" e ""di default"", McCarthy contribuisce a porre gran parte delle basi teoriche dell'IA. Il punto di vista psicologico non viene trascurato. Ad esempio, il programma EPAM (Feigenbaum e Feldman, 1963) esplora la relazione tra memoria associativa e l'atto di dimenticare. Alla Carnegie Mellon University vengono sperimentati programmi per riprodurre i passi del ragionamento, inclusi eventuali errori. L'elaborazione del linguaggio naturale sembra essere un campo destinato a un rapido sviluppo. La traduzione diretta di testi porta pero a insuccessi che influenzeranno per molti anni i finanziamenti in tale campo. Malgrado cio, viene dimostrato abbastanza presto che si possono ottenere buoni risultati in contesti limitati. I primi anni settanta vedono lo sviluppo dei sistemi di produzione, ossia dei programmi che sfruttano un insieme di conoscenze organizzate in base di dati, attraverso l'applicazione di regole di produzione, per ottenere risposte a domande precise. I sistemi esperti hanno sostituito i sistemi di produzione per via delle difficolta incontrate da questi ultimi, con particolare riferimento alla necessita di fornire inizialmente la conoscenza in forma esplicita e la poca flessibilita delle regole di produzione. Questi sistemi, di cui Dendral e il piu rappresentativo, mostrano le enormi possibilita offerte da un efficace sfruttamento di (relativamente) poche basi di conoscenza per programmi capaci di prendere decisioni o fornire avvisi in molte aree diverse. In pratica l'analisi dei dati e stata razionalizzata e generalizzata. Si pone ora il problema del trattamento dell'incertezza, che e parte costituente della realta e delle problematiche piu comuni. Mycin introduce l'uso di ""valori di certezza"": un numero associato a ciascun dato e che viene calcolato per la nuova conoscenza inferita. Malgrado cio, le difficolta nel trattare correttamente l'incertezza portano ad abbandonare l'uso di sistemi a regole per avvicinarsi a quella che e la moderna IA. Nell'anno 2006 si e celebrato il cinquantesimo anniversario dell'Intelligenza artificiale con due congressi: AI@50 ""Dartmouth Artificial Intelligence Conference: The Next Fifty Years"", e il congresso 50 anni di Intelligenza Artificiale - Campus Multidisciplinare in Percezione e Intelligenza 2006 o CMPI, un congresso di referenza multidisciplinare, nel quale cento esperti si sono riuniti ad Albacete (Spagna) per celebrare il cinquantesimo anniversario dell'intelligenza artificiale, con la Conferenza di Dartmouth.   == Intelligenza artificiale e tecnologia informatica ==   === Formulazioni === Risolvere un compito di IA richiede il trattamento algoritmico del problema in questione e la produzione di una soluzione. La forma di ottenere questa soluzione -frutto di un processo di ragionamento automatico e di deduzioni logiche capaci anche di reagire opportunamente ai cambiamenti ambientali- varia da approccio ad approccio; tre sono le formulazioni piu correnti dell'IA moderna: codifica della soluzione ""a mano"", per apprendimento e per modelli. Preprogrammare un agente intelligente e una forma di ottenere una risposta desiderata ad input diversi. Questo approccio porta il limite di non includere soluzioni per problemi inattesi; cio e anche un vantaggio, visto che tale sistema non reagisce in modo imprevisto dai programmatori. La soluzione ad un problema si puo anche apprendere quando numerosi esempi sono disponibili (generalmente ottenuti per simulazione). Questo approccio e tipico dell'apprendimento per rinforzo o del ragionamento basato su casi. L'approccio basato su ""modelli"" mira a generare la soluzione al problema di IA automaticamente a partire dalla descrizione del problema da risolvere e grazie a procedure effettive per risolvere il modello. La pianificazione automatica e, per esempio, l'approccio basato su modelli al problema del controllo (la generazione dell'azione da intraprendere per un agente autonomo).   === Campi di applicazione === Attualmente queste sono le principali branche dell'intelligenza artificiale Miglioramento delle proprie condizioni e condizioni ambientali per tempo e risorse Rappresentazione della conoscenza Apprendimento automatico (Machine Learning) Apprendimento non supervisionato Clustering Regole di associazione  Apprendimento supervisionato Albero di decisione Regole di decisione Apprendimento bayesiano Sistemi Esperti  Apprendimento per rinforzo Reti neurali Algoritmi genetici o evolutivi (Particle Swarm Optimization) Sistemi a classificatori  Programmazione Logica Induttiva (ILP) Elaborazione del linguaggio naturale Visual retrieval Visione artificiale Problema di soddisfacimento di vincoli   === Software noti === Cleverbot 20q Boids   == Caratteristiche e dibattiti filosofici ==   === Creare un computer pensante === La domanda al centro del dibattito sull'intelligenza artificiale e fondamentalmente una sola: ""Fino a che punto i computer possono esibire un comportamento intelligente?"". Nonostante tutti siano d'accordo che gli esseri umani sono intelligenti, non esiste una definizione operativa di intelligenza universalmente riconosciuta; a riflesso di questo dibattito ancora in corso, lo studio dell'IA si divide in due correnti: la prima, detta intelligenza artificiale forte, sostenuta dai funzionalisti, ritiene che un computer correttamente programmato possa essere veramente dotato di una intelligenza pura, non distinguibile in nessun aspetto significativo dall'intelligenza umana. L'idea alla base di questa teoria e il concetto che risale al filosofo empirista inglese Thomas Hobbes, il quale sosteneva che ragionare non e nient'altro che calcolare: la mente umana sarebbe dunque il prodotto di un complesso insieme di calcoli eseguiti dal cervello; la seconda, detta intelligenza artificiale debole, sostiene che un computer non sara mai in grado di eguagliare la mente umana, ma potra solo arrivare a simulare alcuni processi cognitivi umani senza riuscire a riprodurli nella loro totale complessita. A difesa dell'intelligenza artificiale debole, l'improbabile raggiungimento da parte di un computer di una capacita di pensiero che riproduce in tutto e per tutto l'intelligenza umana, compresa nella forma e nell'autonomia, e sostenuto dall'isolamento della macchina dal mondo, al massimo collegata ad esso tramite una rete informatica, in grado di trasmetterle solo informazioni provenienti da altri computer. La vera ""intelligenza artificiale"", percio, potrebbe essere raggiungibile solo da robot (non necessariamente di forma umanoide) in grado di muoversi e interagire con l'ambiente che li circonda grazie a sensori e bracci meccanici. Spesso infatti anche nell'uomo l'applicazione dell'intelligenza deriva da qualche esigenza corporea, percio e improbabile riuscire a svilupparne un'imitazione senza un corpo. Questa visione prevede quindi che prima di insegnare a un robot a giocare a scacchi, e necessario insegnargli a muoversi, a vedere, a sentire. Insomma, anche nel robot intelligente sarebbe necessario creare un'""infanzia"", che gli consenta di mettere a punto autonomi processi di apprendimento e di adattamento all'ambiente in cui si trovera ad agire. Questo modo di procedere e sintetizzato nella Artificial Life - A.I., la cui prima proposta si deve a Chris Langton. Comprendendo in tale disciplina la robotica avanzata si puo anche introdurre lo studio della robotica evolutiva. Il tutto fa uso di simulazioni software e hardware di quello che potrebbe essere l'ambiente e gli organismi primitivi che in tale ambiente interagiscono, si riproducono ed evolvono verso popolazioni sempre piu complesse e sofisticate ma senza necessita dell'intervento umano. L'intelligenza artificiale forte scarta la domanda se una macchina possa pensare, dedicandosi piuttosto ad identificare i limiti fisici di una macchina pensante. Il livello di sofisticazione di un programma intelligente potrebbe venire misurato da un opportuno test capace di definire un criterio per determinare se una macchina sia in grado di pensare nel senso umano del termine. Un'intelligenza artificiale dovrebbe esibire stati mentali simili a quelli dell'uomo e definiti dai fisicalisti. Uno stato mentale non e altro, per la visione funzionalista, che una configurazione dello stato interno del computer che rappresenta la sua visione dell'ambiente in base agli input e output ricevuti ed emessi. Sotto una tale ottica, sarebbe possibile rimpiazzare la mente di una macchina con un'altra, come tendono a suggerire i test di robotica di Moravec, estendendosi fino ad un'esperienza transumanista da parte dei robot che superano i limiti della fisiologia umana.   === Caratteristiche di un'intelligenza artificiale === Le attivita e le capacita dell'Intelligenza Artificiale dal punto di vista sia filosofico che tecnologico comprendono: l'apprendimento automatico (machine learning), utile in contesti quale il gioco degli scacchi; la rappresentazione della conoscenza e il ragionamento automatico in maniera simile a quanto fatto dalla mente umana; la pianificazione (planning); la cooperazione tra agenti intelligenti, sia software sia hardware (robot); l'elaborazione del linguaggio naturale (Natural Language Processing); la simulazione della visione e dell'interpretazione di immagini, come nel caso dell'OCR o del riconoscimento facciale.   == Fantascienza ==  Nelle opere di fantascienza l'intelligenza artificiale e un tema ricorrente, come semplice elemento narrativo o come argomento centrale della storia. Generalmente e presentata sotto forma di computer avanzati, robot o androide. Il tema e spesso legato a quello classico della ribellione della macchina, in cui un computer (spesso senziente) si rivolta contro gli esseri umani che l'avevano costruito. Tra i computer senzienti rientrano ad esempio Multivac, presente in alcuni racconti di Isaac Asimov, paragonabile ai moderni sistemi di grid computing, e HAL 9000 del film 2001: Odissea nello spazio (1968) di Stanley Kubrick. Invece Pensiero Profondo, nella Guida galattica per autostoppisti, e un'intelligenza artificiale capace di fornire la risposta alla ""domanda fondamentale sulla vita, l'universo e tutto quanto"". Nella serie cinematografica di Terminator, il supercomputer Skynet e presentato come un sofisticatissimo insieme di network che, costruiti dal Dipartimento della difesa degli Stati Uniti verso la fine della guerra fredda, finiranno per divenire un insieme autocosciente ed intraprendere, al comando di un esercito di robot e cyborg, una spietata guerra per lo sterminio della specie umana. Nel film Matrix le macchine intelligenti tengono in schiavitu miliardi di esseri umani, per trarre da essi energia elettrica. Oltre a quello del cinema e della televisione, anche il mondo dei cartoni animati e dei videogiochi ha sfruttato il tema dell'AI. I robot o androidi senzienti sono anch'essi un classico. Nell'ipotesi che le macchine possano man mano diventare piu simili agli esseri umani, gli autori hanno ipotizzato macchine dalla enorme capacita di calcolo e dotate di personalita. I ""robot positronici"" come il robot R. Daneel Olivaw del romanzo Fondazione, Marvin l'androide paranoico, R2-D2 e C-3PO di Guerre stellari , Data di Star Trek: The Next Generation e Chappie di Humandroid sono solo alcuni esempi tra i piu noti. Queste macchine si distinguono dai semplici robot per una personalita spiccata e ""umanizzata"", resa possibile da un'intelligenza artificiale estremamente evoluta.   == Note ==   == Bibliografia == Nils J. Nilsson, Intelligenza artificiale, a cura di Salvatore Gaglio, Apogeo, 2002, ISBN 978-88-7303-746-0. Stuart J. Russell, Peter Norvig, Intelligenza artificiale. Un approccio moderno, a cura di S. Gaburri, 2a edizione, Pearson Education Italia, 2005, ISBN 978-88-7192-228-7. Anna Ludovico, Cervello e Computer O Metodo Per Utilizzare Tecnologia E Ragione, Roma: Lithos 1997, ISBN 88-86584-20-2. AA.VV., 50 anni di intelligenza artificiale, a cura di Massimiliano Cappuccio, Milano: AlboVersorio, 2005. Melindo, Flavio (a cura di): Tecnologie di elaborazione e intelligenza artificiale nelle Telecomunicazioni, Ed. CSELT, ISBN 978888540401.   == Voci correlate == Affective computing Agente intelligente Calcolatore della quinta generazione Cognizione Filosofia della mente Intelligenza artificiale nella fantascienza Scienze cognitive Transumanesimo Visione artificiale Vita artificiale   == Altri progetti ==   Wikiquote contiene citazioni sull'intelligenza artificiale  Wikibooks contiene testi o manuali sull'intelligenza artificiale  Wikimedia Commons contiene immagini o altri file sull'intelligenza artificiale   == Collegamenti esterni == Intelligenza artificiale, in Tesauro del Nuovo soggettario, BNCF, marzo 2013. Intelligenza artificiale, su Open Directory Project, Netscape Communications. (Segnala su DMoz un collegamento pertinente all'argomento ""Intelligenza artificiale"")"
"A.I. - Intelligenza artificiale (A.I. Artificial Intelligence) e un film del 2001 diretto da Steven Spielberg, basato su un progetto di Stanley Kubrick.   == Trama == Anno 2125. Il mondo e stato devastato dall'effetto serra e dall'innalzamento degli oceani, che hanno sommerso molte delle piu belle e importanti citta del mondo. La tecnologia si e evoluta a tal punto da poter creare robot incredibilmente sofisticati e simili agli esseri umani, i Mecha, creati da molteplici compagnie tra cui la Cybertronics, un'importante azienda produttrice di automi, che e riuscita a sviluppare dal professor Allen Hobby, un Mecha con le fattezze e il comportamento di un bambino che si presume abbia la capacita di amare veramente qualcuno. Tale robot e stato costruito per colmare il dolore delle coppie che in base alle nuove sanzioni legali dei governi non e possibile per loro avere figli. Tuttavia molti sono preoccupati e dubbiosi per tale cosa, poiche non e saputo come un umano reagira a tale cosa, e invece di provare affetto per lui potrebbe arrivare a odiarlo. A complicare le cose soprattutto sono le ""Fiere della Carne""; feste organizzate dagli uomini che distruggono i robot per paura che essi un giorno possano prendere il loro posto. Nonostante i dubbi, il progetto viene mandato avanti, e dopo venti mesi il primo bambino robot viene completato. Il piccolo robot viene chiamato ""David"", e il primo esemplare viene assegnato dalla Cybertronics ai coniugi Swinton, Monica e Henry, il quale e dipendente della medesima azienda. I due hanno gia un figlio, Martin, che e stato pero ibernato a causa di una grave malattia di cui e affetto. Dopo le prime perplessita, Monica, psicologicamente debole anche a causa della momentanea perdita del figlio naturale, decide di eseguire su di David un protocollo di imprinting che faccia in modo che il Mecha la consideri sua madre e proietti verso di lei lo stesso amore che un bambino umano ha verso un suo genitore, e di trattare David come se fosse suo figlio. A David viene regalato ""Teddy"", un piccolo robot dalle fattezze di un orso di peluche originariamente appartenuto a Martin, perche gli faccia compagnia. Tutto sembra andare bene per la famiglia, che pare aver ritrovato la serenita, fino a quando viene trovata una cura per il figlio ibernato, che guarisce e torna quindi a vivere in famiglia. Abituato a vedere i Mecha come nient'altro che oggetti, Martin non riesce a considerare David come un fratello e lo tratta con l'incosciente crudelta dei bambini, spingendolo a fare brutte figure e dispetti, come tagliare una ciocca di capelli a Monica nel cuore della notte. La goccia che fa traboccare il vaso e quando, durante una festa a bordo della piscina, David si spaventa perche gli amici di Martin gli attivano il protocollo di auto-difesa stuzzicandolo con un coltello e si aggrappa a Martin, facendo cosi cadere entrambi nella piscina dove David sprofonda, trascinando con se Martin che per poco non annega. Dopo questo incidente, Monica e Henry decidono di sbarazzarsi di David. Purtroppo l'imprinting eseguito su David e irreversibile, quindi l'unico modo per la famiglia di liberarsene sarebbe riportarlo alla Cybertronics e farlo distruggere. Essendosi profondamente affezionata a David, Monica non vuole che sia distrutto e decide di abbandonarlo in una foresta con Teddy, come Mecha non registrato. Tutta via, questa scelta non si rivela meno terribile. David, in quanto ha l'imprinting attivato soffre tremedamente per l'abbandono di Moncica che considerava orami sua madre. David, devastato dall'abbandono di Monica, cerca di tornare a casa e comincia a camminare, senza sapere dove sta andando. Incontra molti altri Mecha e finisce per imbattersi in una ""Fiera della carne"", un grande raduno di gente che celebra la vera vita umana e si intrattiene distruggendo brutalmente i Mecha e i robot abbandonati, e qui riesce a sfuggire alla demolizione grazie alle sue fattezze di bambino, grazie alle quali viene creduto un bambino umano. David e Teddy fanno amicizia con Gigolo Joe, un ""Mecha amante"" in fuga per essere stato incastrato in un omicidio da un suo cliente. Convinto che Monica lo abbia abbandonato solo perche e un robot, David decide di provare a diventare un bambino umano e parte alla ricerca della Fata Turchina, di cui ricorda di aver sentito parlare quando Monica gli aveva letto Le Avventure di Pinocchio. I tre robot giungono alla variopinta e decadente metropoli di Rouge City, dove, grazie al ""Dr. Know"", un'intelligenza artificiale che somiglia ad un Albert Einstein caricaturale e risponde ad ogni domanda dietro pagamento, David ottiene informazioni sulla Fata, che si trova a Manhattan. Gigolo Joe, preoccupato, avverte David che molti Mecha si sono diretti a Manhattan e non sono mai ritornati, ma David, per nulla intimorito, decide di partire ugualmente. Con la speranza di aver trovato il luogo in cui si trova la Fata, il trio ruba un anfibicottero della polizia e lo usa per raggiungere l'ormai sommersa e disabitata citta di Manhattan, dove atterrano sulla cima del Rockefeller Center. Qui David scopre la verita sulla sua natura di oggetto, parlando con il suo creatore (che lo ha progettato ispirandosi alle fattezze del figlio morto, mostrando tutta via dei segni di squilibrio mentale dovuti alla perdita del figlio) e vedendo centinaia di copie identiche di se stesso gia inscatolate e pronte per essere vendute. Desolato e senza piu speranze di ritrovare Monica, si lascia cadere in acqua dalla cima del grattacielo nel tentativo di distruggersi. Gigolo Joe pero riesce a salvarlo con l'anfibicottero. Dopo il salvataggio, David gli dice di aver visto la Fata Turchina sott'acqua e vorrebbe reimmergersi, ma proprio in quel momento Gigolo Joe viene catturato dalla polizia con un elettromagnete. David e Teddy allora si immergono da soli a bordo dell'anfibicottero e lo usano per raggiungere la Fata Turchina, che e in realta una statua che fa parte di una riproduzione della storia di Pinocchio presente nel luna park della sommersa Coney Island, ma rimangono bloccati sott'acqua da una ruota panoramica. Incastrato per sempre con Teddy, David passa il tempo a chiedere alla Fata Turchina di trasformarlo in un bambino vero, senza mai smettere. L'anfibicottero esaurisce le energie, diventando totalmente inutilizzabile, mentre il tempo continua a passare, finche non avviene un'altra era glaciale; nonostante cio David continua a chiedere alla Fata di esaudire il suo desiderio, finche non si congela bloccandosi. Cosi passano 2000 anni. Nell'anno 4125, l'anfibicottero di David e Teddy viene recuperato da dei Mecha evoluti e dall'aspetto alieno, che hanno preso il posto degli umani, ormai estinti completamente. I Mecha evoluti riescono a riattivare David e Teddy semplicemente toccandoli, e ad ottenere dalle loro memorie informazioni sulla specie umana, che i discendenti Mecha non hanno mai conosciuto e con cui bramano di ricongiungersi. David raggiunge la statua della Fata Turchina, che collassa in mille pezzi quando la tocca. Usando un ologramma a forma di Fata Turchina, i Mecha evoluti spiegano a David che e impossibile renderlo un bambino vero. Tuttavia le speranze non sono finite: usando il DNA di Monica contenuto in una ciocca di capelli che Teddy ha conservato, i Mecha evoluti possono clonare la donna e inserire le memorie di Monica nella mente dell'essere clonato, cosa che le permettera di rivivere solo per un giorno. Dopo millenni di immenso dolore, David ritrova la sua mamma che lo ama, con la quale trascorre un giorno felicissimo per poi spegnersi lietamente, questa volta per sempre, insieme a lei, andando infine nel luogo dove nascono i sogni.   == Personaggi == David: protagonista del film. David e un bambino robot primo del suo genere costruito con la capacita di amare qualcuno. Dopo il suo completamento viene effettuato un progetto di selezione per trovare la coppia piu idonea a provarlo. Venendo assegnato infine dalla Cybertronics ai coniugi Swinton, Monica e Henry, il quale sono dipendenti della medesima azienda. La coppia pero ha gia un figlio; Martin ibernato da 5 anni per una malattia di cui ancora non c'e cura. Teddy: orso robot amico di David. Era prima un gioccattolo di Martin, che poi e stato regalato a David che lo segue nel suo viaggio alla ricerca della fata turchina. Nonostante le apparenze di giocattolo si rivela una guida per David, cercando di tenerelo lontano dai pericoli avendolo anche tratto in salvo dalla Fiera della Carne. Monica: moglie di Henry a cui stato dato il primo prototipo di David. Psicologicamente fragile a causa che il suo vero figlio Martin e stato ibernato per una malattia incurabile. Nonostante i dubbi iniziali, Monica inizia ad affezzionarsi a David. La situazione si fa particolarmente difficile col ritorno di Martin a cui e stata trovata una cura, e che prova invidia verso David per le attenzione che Monica ha su di lui. a cusa delle presseioni del marito e gli incidenti causati per l'ingenuita di David ordinatigli da Martin, convincono Monica a riportarlo alla Cybertronics per farlo distruggere. Lei tutta via non ne ha la forza e lo abbandona in un bosco. Tutta via questa scelta non si rivelera meno terribile. In quanto David a cui ha attivato l'imprinting soffre tremendamente per il suo abbandono. Viene clonata dopo 2000 anni da dei Mecha evoluti da una ciocca di capelli datagli da David, anche se tutta via, la sua vita durera solo un giorno. Monica e David passano cosi un giorno pieno di felicita senza piu alcuna preoccupazione. giunta la sera monica inizia lentamente a spegnersi dicendo infine a David di avergli sempre voluto bene. Henry: marito di Monica. E' preoccupato per le condizioni mentali di sua moglie poiche il loro figlio Martin e ibernato gia da 5 anni per una malattia. Viene scelto dalle alte sfere della Cybertronics che gli offrono il primo prototipo di bambino robot: David per provare a palcare il dolore della perdita del loro figlio. Inizialmente rilluttante, Henry decide di acconsentire per il bene della moglie, sperando di aiutarla. Dopo alcune titubanze, Monica si affezziona inifne a David. Henry tutta via continua a considerarlo solo un'oggetto insipensabile per la salute mentale di Monica. Con il ritorno del figlio Martin a casa, la situazione non migliora, poiche invidioso, spinge David a compiere alcune azioni fraintese dai genitori. Henry si convince che David e pericoloso, presumendo che se sappia amare, potrebbe anche odiare. Gigolo joe: mecha amante di ultima generazione. Viene incastrato per omicidio da un suo cliente per vendicarsi della moglie. Durante la fuga incontra David, e i due infine diventano amici. Sentendo la storia di David che e alla ricarca dalla fata turchina (storia sentita dalla fiaba pinocchio) decide di aiutarlo nella ricerca. Giunti alla variopinta e decadente metropoli di Rouge City. dove, grazie al ""Dr. Know"", un'intelligenza artificiale che somiglia ad un Albert Einstein virtuale, risponde ad ogni domanda dietro pagamento, ottenendo informazioni sulla Fata, che si trova alla fine del mondo: Manhattan. Gigolo joe e consapevole che gli uomini odiano i mecha ed essi soffrono per i loro sbagli, perche entrambe le razze sono consapevoli che quando giungera la fine, saranno i mecha a rimanere. Allen Hobby: sceinziato cha ha idetato e costruito David. Poiche vige la legge dei governi che impedisce ah un certo numero di coppie sposate di avere dei figli, insieme al suo gruppo di ricerca, Allen Hobby, crea un robot bambino che ha la capacita di amare davvero una persona. Tutta via questa cosa e mal vista dagli altri scienziati, poiche nessuno sa, se un mecha possa amare davvero un'umano egli possa fare altrettanto con lui, oh arrivvare adirittura ad odiarlo. Nonostante gli avvertimenti, Allen Hobby decide comunque di portare aventi il progetto insieme alla sua troupe. Allen Hobby soffre di instabilita mentale dovuta alla perdita del suo vero figlio a cui poi si e ispirato per costruire David. Infatti David alla rivelzione delle sue origini come oggetto e che il professore vuole vendere molte altre coppie come lui, ne rimane distrutto.   == Produzione == Stanley Kubrick, ideatore del progetto, voleva girare il film a meta degli anni novanta. Tuttavia, rendendosi conto che la tecnologia digitale (che all'epoca stava entrando prepotentemente nel mondo del cinema) poteva consentirgli di realizzare il film in modo migliore scelse di rimandarlo, concentrandosi sulla produzione di Eyes Wide Shut. Nel 1999 il regista mori lasciando incompiuto il progetto, che fu realizzato qualche anno dopo dal suo amico Steven Spielberg. L'idea base del film, il bambino artificiale, rimanda alla trama del manga, poi anime, di successo Astroboy, di Osamu Tezuka. Quest'ultima opera fu infatti trasmessa negli Stati Uniti gia dal 1963, riscuotendo grande successo, e secondo Luca Raffaelli, esperto di fumetti, l'opera di Spielberg e Kubrick ha dei chiari rimandi al personaggio dell'immaginario nipponico. La storia futuristica di un androide bambino capace di provare sentimenti si avvale di effetti speciali innovativi, ma non si e rivelata un blockbuster come sperato.   == Distribuzione ==   == Slogan promozionali == David is 11 years old. He weighs 27.22 kilograms. He is 1.21 metres tall. He has brown hair. His love is real. But he is not. David ha undici anni. Pesa 27.22 kg. E alto 1.37 m. Ha i capelli castani. Il suo amore e reale. Ma lui non lo e.  Journey to a world where robots dream and desire. Viaggia in un mondo in cui i robot hanno sogni e desideri.   == Note ==   == Voci correlate == Intelligenza artificiale Robot Androide D.A.R.Y.L.   == Collegamenti esterni == (EN) A.I. - Intelligenza artificiale, in Internet Movie Database, IMDb.com."
"Lisp (List Processor) e una famiglia di linguaggi di programmazione con implementazioni sia compilate sia interpretate, associata nel passato ai progetti di intelligenza artificiale. E stato ideato nel 1958 da John McCarthy come linguaggio formale per studiare la computabilita di funzioni ricorsive (nel senso di Skolem) su espressioni simboliche. E stato anche il primo linguaggio a facilitare uno stile di programmazione funzionale.   == Descrizione == Il primo software libero (free software) con un core LISP e stato emacs, diffuso editor di testo per terminale progettato negli anni ottanta da Richard Stallman sulle LISP machine dell'epoca e portato successivamente su tutti i sistemi operativi. Commercialmente, la diffusione piu rilevante del linguaggio e avvenuta con la sua integrazione in programmi di uso comune, come nel CAD AutoCAD (Autodesk inc.) o come nel publisher Interleaf (Interleaf Inc.), che utilizza una versione personalizzata di Lisp e strettamente integrata con le funzioni di programmazione dell'ambiente grafico. La Symbolics Technology Inc. ha realizzato negli anni ottanta delle workstation e server con sistema operativo multitasking e orientato agli oggetti con una potentissima interfaccia grafica di programmazione simbolica, tutto interamente programmato in LISP anche il microcodice del processore LISP: foto. Le prime LISPM (LISP Machine) erano state implementate al MIT. Anche la Xerox produsse delle macchine LISPM (Dandylion, Dandytiger) come pure la Texas Instrument (TI Explorer). Complessi software LISP restano ancora in servizio presso enti governativi, militari, aerospaziali, compagnie aeree, compagnie petrolifere, ecc. per complessi giochi di simulazione e valutazione di strategie operative. Data la grande versatilita del linguaggio e quindi la facilita di estensione e personalizzazione da parte del programmatore, sono fioriti molti dialetti di LISP, tra cui, il piu diffuso, e quello a cui solitamente ci si riferisce parlando di LISP, e il Common LISP. Altri sono lo Scheme e l'Arc.   == Programma di esempio == Gli esempi qui riportati sono scritti in Common LISP  Es: con Cmucl lisp GPL interprete e compilatore di codice macchina e/o bytecode provate a digitare:       * (format t ""~&Hello, world!~%"")      Hello, world!      NIL      *  Per compilare quanto sopra scrivere in un file di testo dal nome ""test.lisp"" quanto segue:  (defun miotest ()   (format t ""~&Hello, world!~%""))  Lanciate Cmucl e da linea comandi del lisp interprete digitare:    # lisp   ....   * (compile-file ""..../test.lisp"")  Il comando trasforma e compila il file in test.x86 (codice macchina X86), quindi basta digitare:       * (require:test)      * (miotest)      Hello, world!      NIL      *  ...   == Dialetti del LISP == AutoLISP Clojure Common LISP Scheme Nyquist   == Note ==   == Bibliografia == D. Touretzky, Common Lisp - Un'introduzione graduale all'elaborazione simbolica, Ed. Zanichelli, ISBN 88-08-12248-4   == Voci correlate == car cdr e cons: le funzioni fondamentali del Lisp per operare sulle liste Common LISP - Il principale dialetto Lisp Steel Bank Common Lisp - Interprete e compilatore Common ModLisp Lisp Toolkit per la creazione di interfacce grafiche multipiattaforma   == Altri progetti ==   Wikibooks contiene testi o manuali su Lisp  Wikimedia Commons contiene immagini o altri file su Lisp   == Collegamenti esterni == Italian Lisp User Group, lisp.it. ""Il Mio Lisp"", libro italiano sul linguaggio Lisp utilizzato nei software CAD, redchar.net. Common Lisp e Tools + manuali con distribuzione Knoppix pronta per l'uso, (Lisp Live CD)"
"Il bot (abbreviazione di robot) in terminologia informatica in generale e un programma che accede alla rete attraverso lo stesso tipo di canali utilizzati dagli utenti umani (per esempio che accede alle pagine Web, invia messaggi in una chat, si muove nei videogiochi, e cosi via). Programmi di questo tipo sono diffusi in relazione a molti diversi servizi in rete, con scopi vari ma in genere legati all'automazione di compiti che sarebbero troppo gravosi o complessi per gli utenti umani. Nei paesi anglosassoni, con Bot s'intende un programma autonomo che nei social network fa credere all'utente di comunicare con un'altra persona umana. Questi bot migliorano di anno in anno ed e sempre piu difficile distinguere un bot da una persona umana.   == Esempi ==   === World Wide Web === Il tipo piu diffuso di bot programmato per navigare sul World Wide Web e quello dei web crawler (traducibile grossolanamente con ""arrampicatore della rete""), detti anche spider (""ragni""). Questi programmi attraversano le pagine Web ""seguendo"" i link ipertestuali che trovano nel testo per passare dall'una all'altra, e nel frattempo raccolgono informazioni sui contenuti delle pagine allo scopo di indicizzarle opportunamente nel database principale del motore di ricerca.   === Internet Relay Chat === Sui canali IRC i bot svolgono svariati compiti; dallo spamming rivolto automaticamente a tutti gli utenti che entrano in chat, all'offerta di servizi di file sharing integrati nel sistema di chat, fino ad arrivare a svolgere il ruolo di ""maggiordomi"" delle stanze virtuali piu sofisticate.   === Videogiochi === Nei videogiochi, soprattutto di genere sparatutto in prima persona, i bot sono personaggi controllati dal computer e che partecipano all'azione al posto di giocatori umani. L'utilizzo piu comune e come avversari virtuali con cui allenarsi e fare pratica in assenza di avversari umani. I bot vengono talvolta utilizzati anche per controllare, del tutto o in parte, il personaggio del giocatore stesso. Alcuni giochi (ad esempio Timesplitters e Half-Life 2) integrano un aimbot per chi soffre di handicap che fornisce un certo grado di aiuto nel prendere la mira. Un bot non previsto dal gioco ma installato a parte puo essere usato dal giocatore per imbrogliare; ad esempio nei giochi online multiplayer i bot possono essere sfruttati per giocare al posto della persona quando non e al computer, accumulando punti esperienza e dando un vantaggio sui giocatori normali.   === Progetti wiki === Su progetti di tipo wiki, i bot svolgono soprattutto (ma non solo) compiti di riordino automatico delle pagine, come compilazione dei collegamenti, correzione di reindirizzamenti, creazione di pagine speciali di sintesi, e cosi via.   == Note ==   == Voci correlate == Personaggio non giocante Aimbot Bot IRC   == Collegamenti esterni == (EN) Bot a sorgente aperto di Microsoft per l'intelligenza artificiale, microsoft.com."
"Nelle opere di fantascienza, l'intelligenza artificiale e un tema ricorrente, come semplice elemento narrativo o come argomento centrale della storia. In generale e presentata sotto forma di computer avanzati o robot. Il tema e spesso legato a quello classico della ribellione del computer, in cui una macchina (di solito senziente) si rivolge contro gli esseri umani che l'avevano costruita. Tra i computer senzienti rientrano ad esempio Multivac, presente in alcuni racconti di Isaac Asimov, paragonabile ai moderni sistemi di grid computing, e HAL 9000 del film 2001: Odissea nello spazio. Pensiero Profondo nella Guida galattica per autostoppisti e una intelligenza artificiale capace di fornire la risposta alla domanda fondamentale sulla vita, l'universo e tutto quanto. Nella serie cinematografica di Terminator, il supercomputer Skynet e presentato come un sofisticatissimo insieme di network costruiti dal Dipartimento della difesa degli Stati Uniti verso la fine della guerra fredda, destinato a divenire autocosciente e intraprendere nel futuro una spietata guerra contro la specie umana al comando di un esercito di robot e cyborg. I robot o androidi senzienti sono anch'essi un classico. Nell'ipotesi che le macchine possano man mano diventare piu simili agli esseri umani, gli autori hanno ipotizzato macchine dalla enorme capacita di calcolo e dotate di personalita: i ""robot positronici"" di Asimov, Robby il robot del film Il pianeta proibito, Marvin l'androide paranoico, i droidi C1-P8 e D-3BO di Guerre stellari e l'androide Data di Star Trek: The Next Generation sono solo alcuni esempi piu noti. Queste macchine si distinguono dai semplici robot per una personalita spiccata, resa possibile da un'intelligenza artificiale estremamente evoluta. Nel ciclo di Dune di Frank Herbert, l'uso delle intelligenze artificiali e vietato ed e legato ad un vero e proprio tabu: migliaia di anni prima degli avvenimenti narrati nel romanzo Dune, le macchine pensanti avevano ridotto alla schiavitu l'umanita, e a seguito della Jihad Butleriana il primo comandamento della nuova religione del nascente impero e: ""Non costruirai mai una macchina somigliante a una mente umana.""   == Esempi ==  Elenco (non esaustivo), in ordine alfabetico, delle intelligenze artificiali protagoniste di opere di fantascienza. Andrew Martin dal film L'uomo bicentenario Antrax dal romanzo ""Il labirinto"" di Terry Brooks AM dal racconto Non ho bocca, e devo urlare di Harlan Ellison AVA dal film Ex Machina Bender dalla serie televisiva Futurama Chappie dal film Humandroid i cylone dalla serie televisiva Battlestar Galactica D.A.R.Y.L. dall'omonimo film. l androide femmina Eva,nel fim Eva il comandante Data dal telefilm Star Trek: The Next Generation David dal film A.I. - Intelligenza Artificiale GLaDOS dalla serie di videogames Portal HAL 9000 dal film 2001: Odissea nello spazio e omonimo romanzo di Arthur C. Clarke Invernomuto e Neuromante dal romanzo Neuromante di William Gibson Jarvis, di Iron Man Joshua dal film Wargames - Giochi di guerra John Henry, del serial TV Terminator: The Sarah Connor Chronicles Juiz, nell'anime Eden of the East KITT e KARR dal telefilm Supercar il Magi System dall'anime Neon Genesis Evangelion Marvin l'androide paranoico e Pensiero Profondo dal romanzo Guida galattica per gli autostoppisti Gli agenti di Matrix dall'omonimo film. Naomi Armitage, dall'anime OVA Armitage III Numero 5 dal film Corto circuito R2-D2 e C-3PO dalla saga di Guerre stellari Rosie la domestica dal cartone animato I Pronipoti Roy Batty, Pris, Leon e Rachel in Blade Runner Samantha, il sistema operativo del film Lei Il Signore dei Pupazzi e i Tachikoma dal film Ghost in the Shell Il supercomputer Skynet e i cyborg T-800, T-1000 e T-X dalla serie cinematografica di Terminator. Synergy, della serie animata Jem Solo dal film Nirvana Sonny e V.I.K.I. dal film Io, Robot R. Daneel Olivaw nei romanzi Abissi d'acciaio, Il sole nudo, I robot dell'alba, Io Robot e ancora nei cicli dell'Impero e della fondazione di Isaac Asimov. TARS, CASE e KIPP dal film Interstellar Ummon, Nansen e Albedo, IA del TecnoNucleo dalla serie di romanzi dei Canti di Hyperion Uno, aiutante di Paperinik in PKNA Ultron, potente robot nemico dei Vendicatori nei fumetti Marvel Comics. V'ger dal film Star Trek (1979) Anche in molti videogiochi sono presenti intelligenze artificiali, talvolta maligne (SHODAN nella saga di System Shock) o benigne (Cortana in Halo).   == Bibliografia == Emily E. Auger, Tech-Noir Film: A Theory of the Development of Popular Genres, Intellect Books, 2011, ISBN 978-1-84150-424-7.   == Voci correlate == Androide Cyborg Ginoide Intelligenza artificiale forte Ribellione della macchina Stanza cinese Test di Turing Categoria:Androidi e robot immaginari   == Altri progetti ==   Wikimedia Commons contiene immagini o altri file su robot nella fantascienza   Wikimedia Commons contiene immagini o altri file su robot nella fantascienza   == Collegamenti esterni == (EN) Science Fiction: Views of the Future Involving AI at the Association for the Advancement of Artificial Intelligence (AAAI) (EN) Can a Machine Ever Become Self-aware? by Giorgio Buttazzo 2000 (EN) AI and Sci-Fi: My, Oh, My!:Keynote Address by Robert J. Sawyer 2002 (EN) AI and Cinema - Does artificial insanity rule? by Robert B. Fisher"
Un grafo concettuale e una notazione logica basata sui grafi esistenziali di Charles Sanders Peirce e le reti semantiche usate in intelligenza artificiale. Nel primo articolo pubblicato sull'argomento, John F. Sowa uso i grafi concettuali per rappresentare gli schemi concettuali utilizzati nei sistemi di database. Il primo libro sui grafi concettuali (Sowa, 1984) forni applicazioni a un'ampia gamma di argomenti in intelligenza artificiale, informatica e scienze cognitive.   == Voci correlate == Rete semantica   == Bibliografia == Sowa, John F. (1984), Conceptual Structures: Information Processing in Mind and Machine, Addison-Wesley, Reading, MA, 1984.
"Nella filosofia dell'intelligenza artificiale l'intelligenza artificiale forte e l'idea che opportune forme di intelligenza artificiale possano veramente ragionare e risolvere problemi; l'intelligenza artificiale forte sostiene che e possibile per le macchine diventare sapienti o coscienti di se, senza necessariamente mostrare processi di pensiero simili a quelli umani. Il termine intelligenza artificiale forte (AI forte, in inglese strong AI) fu originalmente coniato da John Searle per confutarne la teoria : Il termine ""intelligenza artificiale"" dovrebbe equivalere allo stesso concetto di cio che chiamiamo ""IA forte"", basandoci sul significato letterale di ""artificiale"" e ""intelligenza"". L'attivita di ricerca iniziale sull'intelligenza artificiale, comunque, si concentro su alcuni campi ristretti, quali pattern recognition e scheduling automatico, nella speranza di poter ricavare cosi una comprensione della vera intelligenza. Il termine ""intelligenza artificiale"" venne in questo modo ad indicare, oltre all'idea dell'IA forte, anche il lavoro svolto in questi settori limitati (""IA debole"").   == Intelligenza artificiale debole == In contrasto con l'intelligenza artificiale forte, l'intelligenza artificiale debole si riferisce all'uso di programmi per studiare o risolvere specifici problemi o ragionamenti che non possono essere compresi pienamente (o in alcuni casi, sono completamente al di fuori) nei limiti delle capacita cognitive umane. Un esempio di programma di intelligenza artificiale debole e un algoritmo per il gioco degli scacchi (si ricordi, ad esempio, Deep Blue). Diversamente dall'intelligenza artificiale forte, quella debole non realizza un'auto-consapevolezza e non dimostra il largo intervallo di livelli di abilita cognitive proprio dell'uomo, ma e esclusivamente un problem-solver (risolutore di problemi) specifico e, parzialmente, intelligente. Alcuni sostengono che i programmi di intelligenza artificiale debole non possano essere chiamati propriamente ""intelligenti"", in quanto non possono realmente pensare. Rispondendo alla tesi secondo cui programmi come Deep Blue non siano realmente pensanti, Drew McDermott scrisse: Egli sostenne che Deep Blue possieda un'intelligenza che difetta riguardo all'ampiezza stessa del suo intelletto. Altri notano invece che Deep Blue e meramente un potente albero di ricerca euristico, e che affermare che esso ""pensi"" agli scacchi e come affermare che gli organismi unicellulari ""pensino"" al processo di sintesi proteica; entrambi sono ignari di tutto, ed entrambi seguono un programma codificato al loro interno. Molti fra coloro che avanzano queste critiche riconoscono l'IA debole come l'unica possibile, affermando che le macchine non potranno mai divenire realmente intelligenti. Al contrario, i sostenitori della IA forte teorizzano la vera coscienza di se ed il ""pensiero"" per come lo intendiamo ora possano richiedere uno speciale algoritmo progettato per osservare e prendere in considerazione i processi della propria stessa mente. Secondo alcuni psicologi dell'evoluzione gli umani potrebbero aver sviluppato un algoritmo di questo tipo, particolarmente avanzato, specificamente per l'interazione sociale o la mistificazione, due attivita in cui il genere umano si dimostra nettamente superiore rispetto ad altre specie.   == Intelligenza artificiale generale == La ricerca sull'intelligenza artificiale generale ha come obiettivo la creazione di una IA capace di replicare completamente l'intelligenza umana, solitamente chiamata Intelligenza Artificiale Generale (""Artificial General Intelligence"", AGI) per distinguerla da progetti di IA meno ambiziosi. Ad oggi i ricercatori hanno mostrato poco interesse verso l'AGI, perlopiu seguendo la teoria per cui un'intelligenza umana e troppo complessa per essere replicata completamente. In ogni caso, alcuni gruppi indipendenti di informatici stanno portando avanti progetti di ricerca in questo campo. Tra le organizzazioni che perseguono ricerche sull'AGI sono presenti l'Adaptive AI, Artificial General Intelligence Research Institute (AGIRI), CCortex, Novamente LLC e il Singularity Institute for Artificial Intelligence. Una recentemente aggiuntasi e Numenta, il cui progetto e basato sulle teorie di Jeff Hawkins, creatore del Palm Pilot. Mentre Numenta si basa su un approccio computazionale verso l'intelligenza artificiale, Hawkins e inoltre il fondatore del RedWood Neuroscience Institute, che esplora il pensiero cosciente da una prospettiva biologica. John Searle e molti altri di coloro che sono coinvolti in questo dibattito discutono sul se una macchina che lavora tramite la sola trasformazione di dati codificati possa essere considerata una mente, mentre non considerano la piu ampia questione del monismo opposto al dualismo, e cioe il problema del se una macchina di qualsiasi genere, includendo quelle biologiche, possa contenere una mente. Searle sostiene nella sua argomentazione nota come la ""Stanza Cinese"" che gli elaboratori di informazione portino dati codificati che descrivono cose. I dati codificati in quanto tali risultano essere senza significato alcuno qualora venga a mancare un riferimento incrociato alle cose che essi descrivono. Questo porta Searle a dire che non c'e alcuna comprensione e significato nello stesso elaboratore di informazione. Come risultato egli dichiara che anche una macchina che superi il Test di Turing non debba essere necessariamente intelligente in senso umano. Alcuni filosofi ritengono che, se l'IA debole e possibile, allora debba essere possibile anche l'IA forte. Daniel C. Dennett, nel suo ""Consciousness Explained"", sostiene che, se non c'e nessuna scintilla magica o anima, allora l'Uomo non sia altro che una macchina, e si chiede perche questo Uomo-macchina debba avere la posizione privilegiata su tutte le altre macchine possibili per quanto riguardi l'intelligenza o l'avere una ""mente"". Nello stesso lavoro propone il suo Modello a bozze multiple di coscienza. Simon Blackburn, nella sua introduzione alla filosofia ""Think"", fa notare che, sebbene una entita possa apparire intelligente, non vi e alcun modo per stabilire se quella intelligenza sia effettivamente reale (e cioe una ""mente""). Comunque, se la discussione e limitata alla sola intelligenza artificiale forte, piuttosto che alla coscienza artificiale, e possibile identificare caratteristiche della mente umana che non occorrono nell'elaborazione delle informazioni in un computer. Molti dei propositori dell'IA forte credono che la mente sia soggetta alla Tesi di Church-Turing. Questa teoria e tuttavia reputata da molti problematica e anti-intuitiva, in quanto un elaboratore di informazioni dovrebbe poter essere costruito anche basandosi solo su sfere e legnetti (si intenda per questo un meccanismo completamente analogico). Sebbene un tale dispositivo sarebbe alquanto lento e facile agli errori, dovrebbe essere in grado di svolgere qualsiasi cosa possa essere fatta da un moderno computer. Se la mente e Turing-compatibile, almeno in principio, un dispositivo fatto interamente di sfere rotanti e canali di legno puo allora contenere una mente cosciente. Roger Penrose ha attaccato l'applicabilita della tesi di Church-Turing direttamente, portando l'attenzione sull'halting problem, secondo cui certi tipi di computazione non possono essere eseguiti da sistemi informativi, sebbene possano essere risolti dalla mente umana. La possibilita di creare una intelligenza artificiale forte dipende in definitiva dalla possibilita da parte di un elaboratore di informazioni artificiale di includere tutte le caratteristiche di una mente, fra cui la coscienza. Da questo punto di vista, l'intelligenza artificiale debole risulta essere slegata dal problema dell'IA forte. Basti pensare, ad esempio, che molti dei sistemi informativi utilizzati oggi sarebbero stati definiti ""intelligenti"" solo un secolo fa.   == Metodi di realizzazione ==   === Simulazione computerizzata del modello cerebrale umano === Questa sembra essere la via piu veloce per realizzare un'intelligenza artificiale forte, dal momento che non richiede una comprensione totale della mente umana. Necessita tre cose: Hardware. Per realizzare questo modello sarebbe necessario un calcolatore estremamente potente: per il futurista Ray Kurzweil 1 milione MIPS. Seguendo la Legge di Moore, tale macchina sara disponibile nel 2020 al costo di 1500. Software. Questa e considerata la parte difficile. Bisogna assumere che la mente umana sia data dal sistema nervoso centrale ed esso sia governato dalle leggi fisiche. Comprensione. Infine, richiederebbe sufficiente conoscenza dei meccanismi mentali da essere in grado di riprodurli matematicamente. Cio si potrebbe fare studiando il funzionamento del sistema nervoso centrale, o mappandolo e copiandolo. Le tecniche di neuroimaging migliorano rapidamente, Kurzweil prevede che una mappa di sufficiente qualita verra creata all'incirca per lo stesso periodo in cui sara disponibile la necessaria velocita di calcolo. Una volta messo a punto, un tale modello potra essere facilmente modificato e sperimentato, facendo progredire la ricerca sulla psiche umana, che a sua volta permettera di migliorare il modello.   == Future applicazioni ==   === Intelligenza artificiale a seme/Singolarita tecnologica === Un'intelligenza artificiale forte potrebbe a questo punto migliorare ricorsivamente, ossia, partendo dal livello umano, migliorare autonomamente se stessa, producendo tecnologie molto piu velocemente degli scienziati umani. Sarebbe impossibile prevedere gli sviluppi di una tale intelligenza. Assumendo di prendere l'approccio del modello funzionale umano, sono necessarie alcune modifiche perche cio avvenga. Le piu significative sarebbero le modifiche alle motivazioni. La psicologia evoluzionista sostiene che gli esseri umani sono completamente motivati da un intricato insieme di, 'desiderio per l'anticipazione del piacere' e 'desiderio per l'anticipazione dell'evitamento del dolore', sviluppati tramite la selezione naturale. Da cio derivano tutti i desideri umani (compresi quelli che portano tutta l'intelligenza artificiale romanzata ad essere maligna, ovvero potere, auto conservazione, disgusto per l'inferiore, ecc). Con la comprensione del modello, tutti i desideri del modello possono essere rimossi e possono esserne aggiunti di nuovi - essendo l'auto-miglioramento ricorsivo necessario per una singolarita tecnologica. Si puo sostenere che la cosa piu importante sarebbe di equipaggiare l'Intelligenza artificiale a seme solo con il desiderio di servire l'umanita - implicito in questo e l'auto-miglioramento. per questo motivo e stato istituito il Singularity Institute for Artificial Intelligence. Nota: se la psicologia evolutiva ha torto, sarebbe possibile scoprirlo con questo modello.   === Le arti === Un'intelligenza artificiale piu brillante di quella umana sarebbe (presumendo il funzionalismo) superiore in campo artistico oltre a quello scientifico. Quindi (in particolare se originariamente un'Intelligenza artificiale a seme) sarebbe in grado di produrre le migliori opere di musica, arte, letteratura e filosofia che il mondo abbia mai visto, e potrebbe anche inventare nuove forme d'arte.   === Robotica cognitiva === La robotica cognitiva prevede l'applicazione di diversi campi dell'intelligenza artificiale alla robotica. L'intelligenza artificiale forte sarebbe in particolare una risorsa preziosa per questo campo.   == Confronto tra i calcolatori e il cervello umano ==   === Parallelismo vs velocita === La potenza del cervello umano sta nell'eseguire piu operazioni contemporaneamente, mentre quella di una macchina nella velocita con cui sono eseguite queste operazioni. Il cervello umano puo effettuare un gran numero di operazioni al secondo, in virtu del fatto che possiede all'incirca 100 miliardi di neuroni che operano simultaneamente, collegati da un centinaio di trilioni di sinapsi. Un moderno computer desktop ha al massimo dodici unita di calcolo. Tuttavia, si stima che un neurone emetta 200 pulsazioni al secondo e questo limita il numero di operazioni. Tra loro i segnali sono trasmessi ad una velocita massima di 150 metri al secondo. Un moderno processore da 2 GHz esegue 2 miliardi di operazioni al secondo, e i segnali nelle componenti elettroniche viaggiano quasi alla velocita della luce (300.000 chilometri al secondo). Se la nanotecnologia permettesse di costruire dispositivi di dimensioni pari a quelle di un cervello umano e veloci quanto un moderno computer, un modello umano avvertirebbe lo scorrere del tempo piu lentamente rispetto ad un uomo. Per questo un minuto potrebbe essere percepito molto piu lungo da un cervello artificiale, probabilmente come se durasse qualche ora. Comunque, dal momento che la percezione della durata di un arco di tempo e differente dalla durata stessa, il modo in cui un'intelligenza artificiale tratta il tempo dipenderebbe dai calcoli e dal tipo specifico di cognizione durante quel periodo di tempo.   == Note ==   == Bibliografia == Goertzel, Ben; Pennachin, Cassio (Eds.) Artificial General Intelligence. Springer: 2006. ISBN 354023733X. John Searle: Minds, Brains and Programs Behavioral and Brain Sciences 3 (3): 417-457 1980., bbsonline.org. Jose Maria de Espona: TUE: Tridimensional Understanding Engines, A method for artificial understanding and consciousness based on computer graphics tools and an euclidean reference system 2004., inteligencia-artificial.com. Kurzweil, Ray; The Singularity is Near. ISBN 0670033847. Expanding Frontiers of Humanoid Robots (PDF), inl.gov. How Intelligent is Deep Blue? di Drew McDermott. New York Times, 14 maggio 1997 Kurzweil, Ray, (with contributions of George Gilder, John Searle, William Dembski, Michael Dento, Thomas Ray), Are We Spiritual Machines?, Discovery Institute, 2002, Seattle   == Voci correlate == Intelligenza artificiale Scienze cognitive Filosofia della mente Vita artificiale Transumanesimo Affective computing Calcolatore della quinta generazione Intelligenza artificiale nella fantascienza   == Collegamenti esterni == Artificial General Intelligence Research Institute, agiri.org. The Genesis Group at MIT's CSAIL, studio di ricerca sul processo di computazione che sottosta all'intelligenza umana Essentials of general intelligence, articolo sull'IA Adattiva. Levels of Organization in General Intelligence, singinst.org. Problems with Thinking Robots, inl.gov."
"John McCarthy, chiamato a volte Zio John McCarthy (Boston, 4 settembre 1927  Stanford, 24 ottobre 2011), e stato un informatico statunitense che ha vinto il Premio Turing nel 1971 per i suoi contributi nel campo dell'intelligenza artificiale. E stato infatti l'inventore del termine ""Intelligenza Artificiale"" nel 1955 (in una proposta per creare un gruppo di lavoro che avrebbe dovuto incontrarsi al Dartmouth College nell'estate '56).    == Biografia == McCarthy si distingueva per le sue conoscenze di logica matematica in relazione all'Intelligenza Artificiale. Una scuola di pensiero diversa, nata al MIT, propone l'""inclusione procedurale del sapere"" usando piani di alto livello, asserzioni, e ponendo il primo traguardo nel linguaggio Planner ed in seguito nella Scientific Community Metaphor. La controversia che ne risulto e ancora attuale ed oggetto di ricerca. McCarthy invento il linguaggio di programmazione Lisp e pubblico i suoi progetti sul Communications of the ACM nel 1960. Motivo inoltre la creazione del Progetto MAC al MIT, ma lascio tale universita preferendo Stanford University nel 1962. Li creo il Laboratorio di Intelligenza Artificiale, che fu per molti anni amico-rivale del Progetto MAC. Nel 1961, fu il primo a dire (in un discorso fatto durante le celebrazioni del centenario del MIT) che il metodo time-sharing (condivisione a tempo) dei computer puo condurre verso un futuro dove la potenza dei calcolatori ed anche specifiche applicazioni possono essere vendute secondo il modello economico dell'utilita (come succede per l'acqua ed elettricita). Quest'idea era molto popolare alla fine degli anni sessanta, ma scompari intorno alla meta degli anni settanta, quando divenne chiaro che l'hardware, il software e le telecomunicazioni del tempo non erano pronte. Ad ogni modo, a partire dal 2000, l'idea e tornata in superficie in nuove forme. McCarthy ottenne il suo Bachelor of Science in Matematica al California Institute of Technology nel 1948 ed il Ph.D. (Dottorato di Ricerca) in Matematica alla Princeton University nel 1951. Dopo alcuni brevi lavori a Princeton, Stanford, Dartmouth, e MIT, divenne professore a Stanford nel 1962, dove rimase fino al suo pensionamento avvenuto alla fine del 2000. Da allora e diventato Professore Emerito. John McCarthy commentava spesso affari mondiali su forum in Internet con una prospettiva di destra. Alcune sue idee possono essere trovate sulla sua web page, che e ""mirata a mostrare che il progresso materiale umano e desiderabile e sostenibile"". E morto il 24 ottobre 2011 all'eta di 84 anni.   == Note ==   == Voci correlate == Funzione 91 di McCarthy   == Altri progetti ==   Wikimedia Commons contiene immagini o altri file su John McCarthy   == Collegamenti esterni == (EN) Homepage di John McCarthy a Stanford, www-formal.stanford.edu."
"Il test di Turing e un criterio per determinare se una macchina sia in grado di pensare. Tale criterio e stato suggerito da Alan Turing nell'articolo Computing machinery and intelligence, apparso nel 1950 sulla rivista Mind.   == Descrizione == Nell'articolo Turing prende spunto da un gioco, chiamato ""gioco dell'imitazione"", a tre partecipanti: un uomo A, una donna B, e una terza persona C. Quest'ultimo e tenuto separato dagli altri due e tramite una serie di domande deve stabilire qual e l'uomo e quale la donna. Dal canto loro anche A e B hanno dei compiti: A deve ingannare C e portarlo a fare un'identificazione errata, mentre B deve aiutarlo. Affinche C non possa disporre di alcun indizio (come l'analisi della grafia o della voce), le risposte alle domande di C devono essere dattiloscritte o similarmente trasmesse. Il test di Turing si basa sul presupposto che una macchina si sostituisca ad A. Se la percentuale di volte in cui C indovina chi sia l'uomo e chi la donna e simile prima e dopo la sostituzione di A con la macchina, allora la macchina stessa dovrebbe essere considerata intelligente, dal momento che - in questa situazione - sarebbe indistinguibile da un essere umano. Per macchina intelligente Turing ne intende una in grado di pensare, ossia capace di concatenare idee e di esprimerle. Per Turing, quindi, tutto si limita alla produzione di espressioni non prive di significato. Nell'articolo, riprendendo il Cogito cartesiano, si legge: Le macchine di Turing sono macchine a stati finiti in grado di simulare altre macchine a stati discreti. Una macchina per sostenere il test dev'essere programmata considerando la descrizione di un uomo in termini discreti (stati interni, segnali, simboli). Dalla complessita del software, si legge tra le righe dell'articolo, emergeranno le funzioni intellettuali. Su questa aspettativa si fonda una disciplina nota come intelligenza artificiale il cui scopo e la costruzione di una macchina in grado di riprodurre le funzioni cognitive umane.   == Prove a confutazione del test == Il test di Turing e stato via via riformulato durante gli anni. Le ragioni sono varie e passano dall'imprecisione della formulazione originale, al sorgere di nuovi problemi relativi alla definizione di macchina intelligente. A volte semplici programmi, come ad esempio ELIZA (un programma che emula un terapista rogersiano), hanno costretto a riformulare i criteri del test perche inadeguati o troppo facilmente soddisfatti da programmi evidentemente non pensanti. Il filosofo John Rogers Searle ha proposto una modifica al test di Turing, che ha preso il nome di stanza cinese, sostenendo l'inattendibilita del test di Turing come prova sufficiente a dimostrare che una macchina o un qualsiasi sistema informatico siano sistemi dotati di vera intelligenza, sia che questi abbiano superato o no tale test.   == Note ==   == Voci correlate == CAPTCHA Intelligenze artificiali nella fantascienza Bot   == Altri progetti ==   Wikimedia Commons contiene immagini o altri file su Test di Turing   == Collegamenti esterni == Ipotesi, problemi e soluzioni dell'Intelligenza Artificiale - Una rilettura in prospettiva fenomenologica, tesi di laurea di Manuela Viezzer CYBUGS - Possono le macchine pensare?, mostra tenutasi presso la Triennale di Milano nel 2002 A.L.I.C.E. (Artificial Linguistic Internet Computer Entity) MAD, geocities.com. (archiviato dall'url originale il ). (seconda copia archiviata il ). di Umberto Aliotta Esempio di conversazione, nemesi.net. Voce Test di Turing in Nicola Ubaldo, Atlante illustrato di filosofia, Firenze, Giunti Editore, p. 560, 2000. ISBN 88-440-0927-7; ISBN 978-88-440-0927-4. Nuova ed.: 2005. ISBN 88-09-04192-5; ISBN 978-88-09-04192-9. Dibattito su Test di Turing, proversi.it"
"La psicologia cognitiva e una branca della psicologia che ha come obiettivo lo studio dei processi mentali mediante i quali le informazioni vengono acquisite dal sistema cognitivo, elaborate, memorizzate e recuperate.   == Descrizione == Essa studia il funzionamento della mente come elemento intermedio tra il comportamento e l'attivita cerebrale prettamente neurofisiologica. Il modello di funzionamento e assimilato (metaforicamente) a quello di un software che elabora informazioni provenienti dall'esterno (input), restituendo a sua volta informazioni (output) sotto forma di rappresentazione della conoscenza, organizzata in reti semantiche e cognitive. La percezione, la sensazione, l'impressione, il pensiero, l'apprendimento, il ragionamento, la risoluzione dei problemi, la memoria, l'attenzione, il linguaggio e le emozioni sono processi mentali studiati dalla psicologia cognitiva. Il costruttivismo e stato spesso considerato come una corrente del cognitivismo, pur mantenendo una sua autonomia; alcuni dei suoi assunti epistemologici di base sembrano pero significativamente differenti da quelli tradizionali del cognitivismo (George Kelly, fondatore della psicologia dei costrutti personali, amava ripetere: ""sfatiamo il mito che il costruttivismo sia collegato al cognitivismo"").   == Cenni storici == La psicologia cognitiva nasce verso la fine degli anni cinquanta in parziale contrapposizione al comportamentismo. Quest'ultimo aveva gettato le basi per una psicologia fondata empiricamente. Il cognitivismo accetta il rigore metodologico del comportamentismo. Entrambe le discipline, infatti, si basano su una scientificita di tipo naturalistico, nel comune intento di assimilare lo studio della mente umana alle scienze naturali. La seconda meta degli anni cinquanta vide non solo il fiorire di nuove impostazioni teoriche e procedure sperimentali, ma anche la diffusione di una prospettiva differente da quella comportamentista dominante negli Stati Uniti: la prospettiva della psicologia cognitiva o del cognitivismo. Vi confluirono i contributi di discipline diverse: oltre alla psicologia sperimentale di impronta neocomportamentista, la linguistica, la teoria dell'informazione e la cibernetica, le neuroscienze e la filosofia della mente. Si considera abitualmente come ""data di nascita"" del movimento cognitivista il Convegno di Boulder (Colorado) del 1955, anche se alcuni fanno retrocedere questa data al lavoro di Claude Shannon sulla teoria dell'informazione del 1948. Oltre all'impostazione interdisciplinare, la psicologia cognitiva aveva altri suoi aspetti caratteristici. In primo luogo, si interessava dei processi cognitivi (la percezione, l'attenzione, la memoria, il linguaggio, il pensiero, la creativita), che erano stati trascurati dai comportamentisti o considerati come dei prodotti dell'apprendimento. A questi processi veniva riconosciuta sia un'autonomia strutturale sia una interrelazione e interdipendenza reciproche. Un'altra importante caratteristica della psicologia cognitiva e che la mente e concepita come un elaboratore di informazione, avente un'organizzazione prefissata di tipo sequenziale e una capacita limitata di elaborazione lungo i propri canali di trasmissione. L'analogia tra mente e calcolatore era basata sulle nozioni di informazione, canale, sequenza di trasmissione ed elaborazione dell'informazione, strutture di entrata (input) e uscita (output) dell'informazione dell'elaboratore, strutture di memoria. Per spiegare tale organizzazione strutturale e funzionale si diffuse l'uso di diagrammi di flusso, formati da unita (scatole) e aventi ciascuna compiti definiti (percezione, attenzione, ecc.) e da vie di comunicazione.   === Modelli cognitivi ===  Nei primi modelli cognitivistici, l'elaborazione dell'informazione era concepita come un processo che avviene per stadi consecutivi: terminate le operazioni proprie di uno stadio si passa al successivo, e cosi via. Negli anni '70 furono presentati nuovi modelli che mettevano in evidenza sia la possibilita di retroazione di uno stadio di elaborazione su quelli precedenti, sia la possibilita che si attivassero le operazioni di uno stadio successivo senza che quelli precedenti avessero gia elaborato l'informazione per quanto li riguardava. Un altro aspetto importante fu l'accentuazione del carattere finalizzato dei processi mentali. Il comportamento veniva ora concepito come una serie di atti guidati dai processi cognitivi ai fini della soluzione di un problema, con continui aggiustamenti per garantire la migliore soluzione. La nozione di retroazione, feedback, sviluppata dalla cibernetica divenne centrale in questa concezione del comportamento orientato verso una meta. Lo psicologo sperimentale del linguaggio George Armitage Miller, con le sue opere determino un'autentica svolta nella rappresentazione del comportamento: il comportamento era visto come il prodotto di una elaborazione dell'informazione, quale e compiuta da un calcolatore, per lo svolgimento di un piano utile alla soluzione del problema. Il comportamento non era quindi l'epifenomeno di un arco riflesso (input sensoriale, elaborazione, output motorio), ma il risultato di un processo di continua verifica retroattiva del piano di comportamento secondo l'unita TOTE (test, operate, test, exit): l'atto finale (exit) non consegue direttamente ad un input sensoriale o a un comando motorio, ma e il risultato di precedenti operazioni di verifica (test) delle condizioni ambientali, di esecuzione (operate) intermedie e di nuove verifiche (test). Nel 1967 usci il libro Cognitive Psychology dello psicologo statunitense Ulric Neisser nel quale venivano sintetizzate le ricerche condotte nei dieci anni precedenti secondo la prospettiva che fu definitivamente chiamata appunto cognitivistica. La letteratura sperimentale sui processi cognitivi crebbe a dismisura sostituendo le prospettive passate con la nuova prospettiva che si diffuse anche in campo della psicologia sociale e della psicopatologia. E comprensibile quindi che nei primi anni '70 si parlasse ormai di rivoluzione cognitivistica nella ricerca psicologica.   === La revisione degli anni '70 === A partire dalla seconda meta degli anni settanta ebbe inizio un'opera di revisione teorica e metodologica all'interno del cognitivismo, che arrivo fino ad una parziale autocritica su quanto era stato acquisito nel decennio precedente. Fu ancora Neisser a riassumere in un testo del 1976 gli aspetti problematici essenziali emersi nella letteratura psicologica cognitivistica. Neisser affermava che il cognitivismo aveva apportato nuovi e importanti contributi alla comprensione dei processi cognitivi, ma allo stesso tempo era degenerato in una miriade di esperimenti e di mode, spesso privi di effettivo valore euristico. Si trattava di modelli generalmente relativi a situazioni di laboratorio e non estrapolabili a situazioni di concreto funzionamento della mente nella vita quotidiana (""wild cognition""); inoltre, avevano un interesse piu teorico che realmente applicativo. Neisser faceva un continuo riferimento all'impostazione teorica di James Jerome Gibson (approccio ecologico), che aveva una concezione cognitivistica di una costruzione della realta esterna da parte della mente, secondo un'organizzazione sequenziale dell'elaborazione dell'informazione, stadio per stadio, ora invece criticata in base all'assunto che l'organismo nel corso dell'evoluzione si e dotato di sistemi sempre piu economici e adeguati che consentono un'analisi diretta e immediata della realta. Il richiamo alla validita ecologica degli esperimenti cognitivistici; la critica alla modellistica dei microprocessi e micromodelli all'infinito (le unita di elaborazione contenevano delle sotto-unita di elaborazione, e queste a loro volta delle altre, e cosi via: si trattava dei temi classicamente analizzati negli studi di HIP - Human Information Processing); l'esigenza di introdurre nel flusso dell'elaborazione dell'informazione processi relativamente trascurati, come la coscienza e la produzione di immagini; le innovazioni nel campo dell'informatica e della simulazione su calcolatore dei processi mentali; le nuove acquisizioni nel campo delle neuroscienze; tutti questi furono elementi fondamentali che attenuarono l'interesse per il cognitivismo ""classico"", o primo cognitivismo, gia a partire da meta degli anni ottanta.   === Il nuovo orientamento === Non vedendo realizzata effettivamente una vera e propria rivoluzione paradigmatica, nei primi anni '80 molti psicologi finirono con lo sminuire la rilevanza teorica e metodologica del cognitivismo, arrivando fino a ritenerlo una continuazione, anche se in forma piu sofisticata, del comportamentismo. Si diceva che aveva solo aggiunto dei processi intermedi tra lo stimolo e la risposta, ma il paradigma rimaneva sempre quello comportamentista. In questo contesto di riflessioni autocritiche da una parte, e di nuove acquisizioni in discipline di confine dall'altra, si sviluppo il nuovo orientamento della Scienza Cognitiva.   === Il cognitivismo oggi === La psicologia cognitiva e oggi una scienza fortemente multidisciplinare, che si avvale dei metodi, degli apparati teorici e dei dati empirici di numerose altre discipline, tra le quali: la psicologia, la linguistica, le neuroscienze, le scienze sociali e della comunicazione, la biologia, l'intelligenza artificiale e l'informatica, la matematica, la filosofia e la fisica. Dal punto di vista filosofico, la psicologia cognitiva assume la posizione ontologica del realismo critico, secondo la quale viene accettata l'esistenza di una realta esterna strutturata, ma allo stesso tempo viene rifiutata la possibilita di conoscerla completamente. Questa premessa teorica lo distingue nettamente dal movimento comportamentista: l'oggetto di studio non e piu (soltanto) il comportamento umano, bensi gli stati o processi mentali, precedentemente considerati interni ad una black box (o scatola nera) insondabile e non conoscibile scientificamente. Tale presa di posizione nei confronti dello studio dell'attivita mentale si traduce concretamente nell'affermarsi della concezione di comportamento umano come risultato di un processo cognitivo di elaborazione delle informazioni articolato e variamente strutturato (information processing). Gli esiti piu recenti dell'analisi dei processi cognitivi, incentrano queste dinamiche nei contesti sociali in cui si sviluppa il pensiero. Questo approccio basato sul cognitivismo, definito come teoria sociale cognitiva, studia infatti l'interazione tra cognizione e contesto sociale. La teoria sociale cognitiva riveste un ruolo molto importante sul versante di studio della personalita. Una elevata importanza in questo nucleo teorico e attribuita alle riflessioni di Albert Bandura. Dai concetti elaborati da Bandura, hanno preso il via numerosi altri ricercatori, costituendo una corrente di pensiero che prende le mosse dal cognitivismo, costruendo un'analisi dei processi cognitivo-emotivi, incentrata sui contesti sociali che vedono tali processi esprimersi attraverso le condotte. Un altro punto di riferimento nel panorama del cognitivismo contemporaneo e, nel campo della psicologia e della psicoterapia, il cognitivismo post-razionalista di Vittorio Guidano. Egli, rielaborando i contributi teorici e sperimentali offerti da numerose altre discipline, apporta importanti contributi allo studio dell'evoluzione della mente umana, con risvolti innovativi nei campi dell'epistemologia, della psicologia sperimentale e della psicopatologia.   == Bibliografia == Ulric Neisser (1967) Cognitive Psychology, Appleton-Century-Crofts, New York.   == Voci correlate == Cognitivismo post-razionalista Cognitivismo psicoanalitico Cognizione Correnti e protagonisti del pensiero psicologico Economia cognitiva Epistemologia evoluzionistica Ergonomia Filosofia della mente Intelligenza artificiale Interfaccia utente Mente Reti Neurali Scienze cognitive Storia della psicologia Teoria sociale cognitiva Terapia cognitiva Trappola cognitiva Usabilita   == Altri progetti ==   Wikimedia Commons contiene immagini o altri file su psicologia cognitiva"
"Il data mining e l'insieme di tecniche e metodologie che hanno per oggetto l'estrazione di un sapere o di una conoscenza a partire da grandi quantita di dati (attraverso metodi automatici o semi-automatici) e l'utilizzo scientifico, industriale o operativo di questo sapere.   == Concetti di base == La statistica puo essere definita altrimenti come ""estrazione di informazione utile da insiemi di dati"". Il concetto di data mining e simile ma con una sostanziale differenza: la statistica permette di elaborare informazioni generali riguardo ad una popolazione (es. percentuali di disoccupazione, nascite) mentre il data mining viene utilizzato per cercare correlazioni tra piu variabili relativamente ai singoli individui; ad esempio sapendo il comportamento di un cliente in una compagnia telefonica cerco di prevedere quanto spendera nell'immediato futuro. In sostanza il data mining e "" l'analisi, da un punto di vista matematico, eseguita su database di grandi dimensioni"". Il termine data mining e diventato popolare nei tardi anni '90 come versione abbreviata della definizione appena esposta. Oggi il data mining (letteralmente: estrazione di dati) ha una duplice valenza: estrazione, con tecniche analitiche all'avanguardia, di informazione implicita, nascosta, da dati gia strutturati, per renderla disponibile e direttamente utilizzabile; esplorazione ed analisi, eseguita in modo automatico o semiautomatico, su grandi quantita di dati allo scopo di scoprire pattern (schemi) significativi. In entrambi i casi i concetti di informazione e di significato sono legati strettamente al dominio applicativo in cui si esegue data mining, in altre parole un dato puo essere interessante o trascurabile a seconda del tipo di applicazione in cui si vuole operare. Questo tipo di attivita e cruciale in molti ambiti della ricerca scientifica, ma anche in altri settori (per esempio in quello delle ricerche di mercato). Nel mondo professionale e utilizzata per risolvere problematiche diverse tra loro, che vanno dalla gestione delle relazioni con i clienti (CRM), all'individuazione di comportamenti fraudolenti, fino all'ottimizzazione di siti web. Esempi Che cosa ""non e"" data mining? cercare un numero di telefono nell'elenco; fare una ricerca in Internet su ""vacanze alle Maldive"". Che cosa ""e"" data mining? fare una ricerca nel web su una parola chiave e classificare i documenti trovati secondo un criterio semantico (per esempio ""corriere"": nome di giornale, professione, ecc.); scoprire chi sono i clienti che hanno maggiore propensione di acquisto su certi prodotti o campagne pubblicitarie.   == Applicazioni nella ricerca scientifica == I fattori principali che hanno contribuito allo sviluppo del data mining sono: le grandi accumulazioni di dati in formato elettronico, il data storage poco costoso, i nuovi metodi e tecniche di analisi (apprendimento automatico, riconoscimento di pattern). Le tecniche di data mining sono fondate su specifici algoritmi. I pattern identificati possono essere, a loro volta, il punto di partenza per ipotizzare e quindi verificare nuove relazioni di tipo causale fra fenomeni; in generale, possono servire in senso statistico per formulare previsioni su nuovi insiemi di dati. Un concetto correlato al data mining e quello di apprendimento automatico (Machine learning); infatti, l'identificazione di pattern puo paragonarsi all'apprendimento, da parte del sistema di data mining, di una relazione causale precedentemente ignota, cosa che trova applicazione in ambiti come quello degli algoritmi euristici e dell'intelligenza artificiale. Tuttavia, occorre notare che il processo di data mining e sempre sottoposto al rischio di rivelare relazioni causali che poi si rivelano inesistenti. Tra le tecniche maggiormente utilizzate in questo ambito vi sono: Clustering; Reti neurali; Alberi di decisione; Analisi delle associazioni (individuazione dei prodotti acquistati congiuntamente). Un'altra tecnica molto diffusa per il data mining e l'apprendimento mediante classificazione. Questo schema di apprendimento parte da un insieme ben definito di esempi di classificazione per casi noti, dai quali ci si aspetta di dedurre un modo per classificare esempi non noti. Tale approccio viene anche detto ""con supervisione"" (supervised), nel senso che lo schema di apprendimento opera sotto la supervisione fornita implicitamente dagli esempi di classificazione per i casi noti; tali esempi, per questo motivo, vengono anche detti training examples, ovvero ""esempi per l'addestramento"". La conoscenza acquisita per apprendimento mediante classificazione puo essere rappresentata con un albero di decisione. L'estrazione dei dati vera e propria giunge quindi al termine di un processo che comporta numerose fasi: si individuano le fonti di dati; si crea un unico set di dati aggregati; si effettua una pre-elaborazione (data cleaning, analisi esplorative, selezione, ecc.); si estraggono i dati con l'algoritmo scelto; si interpretano e valutano i pattern; l'ultimo passaggio va dai pattern alla nuova conoscenza cosi acquisita.   == Applicazioni nella ricerca di mercato == L'utilizzo del data mining nella ricerca di mercato e volto ad ampliare la conoscenza su cui basare i processi decisionali. Nel contesto aziendale il data mining e considerato parte del processo che porta alla creazione di un data warehouse. E efficace soprattutto per la valorizzazione delle informazioni aziendali residenti in questi grandi depositi di dati. Affinche l'informazione estratta dai dati esistenti sia significativa, e quindi potenzialmente utile, deve essere: valida (cioe puo agire anche sui nuovi dati); precedentemente sconosciuta; comprensibile. In questo contesto, un pattern (schema) non e altro che la rappresentazione delle relazioni chiave che vengono scoperte durante il processo di estrazione dati: sequenze ripetute, omogeneita, emergenza di regole, ecc. Per esempio, se un pattern mostra che i clienti di una certa area demografica sono molto propensi ad acquistare uno specifico prodotto, allora un'interrogazione (query) selettiva ad un data warehouse di probabili compratori puo essere usata per generare un elenco di indirizzi promozionali.   == Il text mining == E una forma particolare di data mining nella quale i dati consistono in testi in lingua naturale, in altre parole, documenti ""destrutturati"". Il text mining unisce la tecnologia della lingua con gli algoritmi del data mining. L'obiettivo e sempre lo stesso: l'estrazione di informazione implicita contenuta in un insieme di documenti. Negli ultimi anni ha avuto un notevole sviluppo, grazie ai progressi delle tecniche di elaborazione del linguaggio naturale (NLP in inglese), della disponibilita di applicazioni complesse attraverso gli Application service provider (ASP) e dell'interesse verso le tecniche automatiche di gestione della lingua mostrato sia dagli accademici, sia dai produttori di software, sia dai gestori dei motori di ricerca.   == Tecniche di Data Mining (cenni) == Vi sono diverse proposte e tecniche aventi ognuna specifiche caratteristiche e vantaggi. Alberi di Decisione: classificazione, sommatorizzazione (es. mediante gli algoritmi C4.5, CART, ID3, Entropia, CHAID) Analisi logica e programmazione intera: classificazione, apprendimento di regole (es. LAD) Teoria dei grafi: clustering, classificazione (es. B&C) Reti neurali (ANN): classificazione (es. Perceptron, a singolo strato, multi-strato, backpropagation, radial-basis function R&F networks come SNNS e Nevprop) Metodi Bayesiani: regressione, classificazione, bayesian learning, bayesian belif network, bayesian classifiers, maximum likelihood Support Vector Machines (SVM): classificazione, pattern recognition (es. RSVM) Association/pattern discovery: regole di associazione e dipendenze, partner sequenziali (es. CN2)   == Sviluppi recenti == Una delle evoluzioni piu recenti del data mining e la data visualisation. Settore specialistico dell'infografica, la data visualisation si occupa non solamente di rendere graficamente intelligibile un testo ma entra in relazione piu diretta con la strutturazione dei database e l'esportazione di grafici dai dati. Un'altra nuova frontiera e il social data mining: l'analisi di informazioni generate dalle reti sociali online.   == Software di data mining == SPSS: SPSS Clementine SAS: SAS Enterprise Miner e SAS Text Miner R Oracle Data Miner Microsoft SQL Server: strumenti di data mining del DBMS prodotto da Microsoft Weka, datamining in Java   == Note ==   == Bibliografia == P. Cabena; P. Hadjinian; R. Stadler; J. Verhees; A. Zanasi. Discovering data mining from concept to implementation, Prentice Hall PTR 1997 Dulli Susi; Furini Sara; Peron Edmondo. Data Mining, Springer Verlag, 2009   == Voci correlate == Clustering Data cleaning Data warehouse Geodata warehouse Algoritmo Base di conoscenza Bonifica (informatica) Business intelligence Process mining Elaborazione dati Infografica Information retrieval Intelligenza competitiva Overfitting Thesaurus Web invisibile   == Altri progetti ==   Wikimedia Commons contiene immagini o altri file su data mining   == Collegamenti esterni == Archivio UCI: Archivio di dati di pubblico dominio per esperimenti di data mining Data Mining Group: Consorzio di produttori di software per lo sviluppo di standard per il data mining Data Base & Data Mining Group website, dbdmg.polito.it. (IT) Articolo divulgativo su Data Mining e Clustering, matematicamente.it. (IT)One Minute Dictionary: Il data mining in un video di un minuto"
Emporis e una societa di data mining fondata nel 2000 da Michael Wutze, con sede ad Amburgo. Raccoglie dati su edifici di tutto il mondo, in particolare grattacieli ed altre strutture di grande altezza, con i quali ha costruito un database consultabile pubblicamente sul sito web Emporis.com. Il database comprende oltre 400.000 edifici distribuiti in 190 paesi, e 160.000 imprese di costruzione e urbanistica. . Nel 2005 Emporis ha formato una partnership con il Council on Tall Buildings and Urban Habitat (CTBUH) di Chicago. Da allora le due societa collaborano per stabilire l'altezza e altri dati sui grattacieli. Il sito Emporis.com e in genere considerato attendibile ed e citato spesso nelle statistiche sui grattacieli, ma si ritiene che per alcuni paesi asiatici, tra cui la Cina, la Corea del Sud, il Giappone e Taiwan, non sia del tutto aggiornato per i grattacieli di recente costruzione.   == Note ==   == Collegamenti esterni == (EN) Sito ufficiale, emporis.com.   == Voci correlate == Lista dei grattacieli piu alti del mondo Lista di citta per numero di grattacieli
"SAS e un complesso di prodotti software integrati (sviluppati dal SAS Institute) che permettono ad un programmatore: inserimento, ricerca e gestione di dati; generazione di report e grafici analisi statistica e matematica pianificazione, previsione e supporto alle decisioni ricerca operativa e project management gestione di qualita sviluppo di applicazioni Inoltre numerosi sviluppatori realizzano molte soluzioni che permettono funzioni quali data warehousing e data mining, gestione delle risorse umane e supporto alle decisioni, gestione finanziaria...   == Base SAS == Il nocciolo del sistema SAS e basato su un pool di applicazioni: Base SAS Software, utilizzato per la gestione dei dati SAS procedures software per l'analisi ed il reporting Macro facility, un tool per estendere e personalizzare le applicazioni DATA step debugger un tool per individuare gli eventuali problemi nelle applicazioni sviluppate. Output Delivery System (ODS), un modulo che tratta i risultati per restituirli in formati standard e facilmente gestibili, quali SAS data sets, listing file, o Hypertext Markup Language (HTML) SAS windowing environment un'interfaccia grafica ed interattiva per eseguire e testare le applicazioni sviluppate nell'ambiente SAS.   == SAS: una descrizione == Cosi come altri linguaggi di programmazione di quarta generazione orientati ai dati quali SQL e Focus, SAS assume una struttura dei file predefinita e lascia al Sistema operativo l'identificazione dei file. Questo permette al programmatore e all'utente di concentrarsi sulla gestione del dato trovandosi all'interno di una sorta di loop. Altre funzioni permettono la generazione di statistiche o report con la semplice definizione del dataset corretto. Al confronto di altri linguaggi di programmazione generici, questo approccio permette all'utente di preoccuparsi meno di come i dati siano conservati per concentrarsi maggiormente sulle informazioni immagazzinate. Questo permette di sfumare il concetto di programmazione permettendo ad utenti, che non ricadono nel concetto di programmatori quanto in quello del marketing, di sviluppare agilmente applicazioni.   == Collegamenti esterni == (EN) SAS support webpage, support.sas.com. SAS Italia, sas.com."
Nel data mining, le regole di associazione sono uno dei metodi per estrarre relazioni nascoste tra i dati. Agrawal et al. introdussero le regole di associazione per la scoperta di regolarita all'interno delle transazioni registrate nelle vendite dei supermercati. Per esempio, la regola                         {                    c           i           p           o           l           l           e           ,           p           a           t           a           t           e                  }                  {                    h           a           m           b           u           r           g           e           r                  }                 {\displaystyle \{\mathrm {cipolle,patate} \}\Rightarrow \{\mathrm {hamburger} \}}    individuata nell'analisi degli scontrini di un supermercato indica che il se il cliente compra insieme cipolle e patate e probabile che acquisti anche della carne per hamburger. Tale informazione puo essere utilizzata come base per le decisioni riguardanti le attivita di marketing, come ad esempio le offerte promozionali o il posizionamento dei prodotti negli scaffali. Le regole di associazione sono anche usate in molte altre aree, quali il Web mining, la scoperta di anomalie e la bioinformatica.   == Storia == Il concetto di regola di associazione divenne popolare a causa di un articolo del 1993 di Agrawal et al.. Secondo Google Scholar esso possiede piu di 9500 citazioni (Settembre 2010) ed e uno degli articoli piu citati nel campo del data mining. Tuttavia e possibile che quella che viene chiamata come regola di associazione sia simile a un approccio di data mining presentato nel 1966 e sviluppato da Hajek et al..   == Definizione == Seguendo la definizione originale di Agrawal et al. il problema della scoperta di regole di associazione e rappresentato come segue. Consideriamo l'insieme di                         n                 {\displaystyle n}    attributi binari (oggetti o item)                         I         =         {                    i                        1                             ,                    i                        2                             ,         ...         ,                    i                        n                             }                 {\displaystyle I=\{i_{1},i_{2},\ldots ,i_{n}\}}    e l'insieme di transazioni (database)                        D         =         {                    t                        1                             ,                    t                        2                             ,         ...         ,                    t                        m                             }                 {\displaystyle D=\{t_{1},t_{2},\ldots ,t_{m}\}}   . Ciascuna transazione appartenente a                         D                 {\displaystyle D}    possiede un codice identificativo (ID) e contiene un sottoinsieme degli oggetti contenuti in                         I                 {\displaystyle I}   . Una regola e definita come un'implicazione nella forma                         X                  Y                 {\displaystyle X\Rightarrow Y}    dove                         X         ,         Y                  I                 {\displaystyle X,Y\subseteq I}    e                         X                  Y         =                          {\displaystyle X\cap Y=\emptyset }   . L'insieme di oggetti (o itemsets)                         X                 {\displaystyle X}    e                         Y                 {\displaystyle Y}    vengono chiamati rispettivamente antecendente e conseguente della regola. Per illustrare questo concetto, e possibile usare un esempio giocattolo riguardante un supermercato. L'insieme di oggetti e                         I         =         {                    l           a           t           t           e           ,           p           a           n           e           ,           b           u           r           r           o           ,           b           i           r           r           a                  }                 {\displaystyle I=\{\mathrm {latte,pane,burro,birra} \}}    e il database contenente gli oggetti e rappresentato nella tabella a destra, dove 1 indica la presenza di un oggetto in una transazione e 0 l'assenza. Un esempio di regola di associazione potrebbe essere:                         {                    b           u           r           r           o           ,           p           a           n           e                  }                  {                    l           a           t           t           e                  }                 {\displaystyle \{\mathrm {burro,pane} \}\Rightarrow \{\mathrm {latte} \}}   . Essa indica che se il cliente acquista pane e burro, comprera anche il latte. Attenzione: questo esempio e estremamente piccolo. In un'applicazione reale una regola necessita di un supporto di diverse centinaia di transazioni perche sia considerata statisticamente significativa e il database deve contenere migliaia (o milioni) di transazioni.   == Note ==
"Nella teoria delle decisioni (per esempio nella gestione dei rischi), un albero di decisione e un grado di decisioni e delle loro possibili conseguenze, (incluso i relativi costi, risorse e rischi) utilizzato per creare un 'piano di azioni' (plan) mirato ad uno scopo (goal). Un albero di decisione e costruito al fine di supportare l'azione decisionale (decision making). Nel machine learning un albero di decisione e un modello predittivo, dove ogni nodo interno rappresenta una variabile, un arco verso un nodo figlio rappresenta un possibile valore per quella proprieta e una foglia il valore predetto per la variabile obiettivo a partire da i valori delle altre proprieta, che nell'albero e rappresentato dal cammino (path) dal nodo radice (root) al nodo foglia. Normalmente un albero di decisione viene costruito utilizzando tecniche di apprendimento a partire dall'insieme dei dati iniziali (data set), il quale puo essere diviso in due sottoinsiemi: il training set sulla base del quale si crea la struttura dell'albero e il test set che viene utilizzato per testare l'accuratezza del modello predittivo cosi creato. Nel data mining un albero di decisione viene utilizzato per classificare le istanze di grandi quantita di dati (per questo viene anche chiamato albero di classificazione). In questo ambito un albero di decisione descrive una struttura ad albero dove i nodi foglia rappresentano le classificazioni e le ramificazioni l'insieme delle proprieta che portano a quelle classificazioni. Di conseguenza ogni nodo interno risulta essere una macro-classe costituita dall'unione delle classi associate ai suoi nodi figli. Il predicato che si associa ad ogni nodo interno (sulla base del quale avviene la ripartizione dei dati) e chiamato condizione di split. In molte situazioni e utile definire un criterio di arresto (halting), o anche criterio di potatura (pruning) al fine di determinarne la profondita massima. Questo perche il crescere della profondita di un albero (ovvero della sua dimensione) non influisce direttamente sulla bonta del modello. Infatti, una crescita eccessiva della dimensione dell'albero potrebbe portare solo ad aumento sproporzionato della complessita computazionale rispetto ai benefici riguardanti l'accuratezza delle previsioni/classificazioni.   == Cenni sui parametri di split e pruning == I parametri piu largamente usati per le condizioni di split sono: Tasso d'errore nella classificazione (misclassification error). Indice di Gini (Gini index): utilizzato da CART (Classification and Regression Trees)                                    I                        G                             (         i         )         =         1                                                     j             =             1                                   m                             f         (         i         ,         j                    )                        2                                     {\displaystyle I_{G}(i)=1-\sum _{j=1}^{m}f(i,j)^{2}}    L'indice di Gini raggiunge il suo minimo (zero) quando il nodo appartiene ad una singola categoria. Variazione di entropia (nota anche come entropy deviance): utilizzata da C4.5 e C5.0, e basata sul concetto di entropia definito in teoria dell'informazione.                                    I                        E                             (         i         )         =                                                     j             =             1                                   m                             f         (         i         ,         j         )         log                  f         (         i         ,         j         )                 {\displaystyle I_{E}(i)=-\sum _{j=1}^{m}f(i,j)\log f(i,j)}    In entrambe le formule f rappresenta la frequenza del valore j nel nodo i. L'indice di Gini e la variazione di entropia sono i parametri che vengono usualmente utilizzati per guidare la costruzione dell'albero, mentre la valutazione del tasso di errore nella classificazione viene utilizzato per effettuare una ottimizzazione dell'albero nota come processo di pruning (""potatura"" dei nodi superflui). Poiche, in generale, in un buon albero di decisione i nodi foglia dovrebbero essere il piu possibile puri (ovvero contenere solo istanze di dati che appartengono ad una sola classe), un'ottimizzazione dell'albero consiste nel cercare di minimizzare il livello di entropia man mano che si scende dalla radice verso le foglie. In tal senso, la valutazione dell'entropia determina quali sono, fra le varie scelte a disposizione, le condizioni di split ottimali per l'albero di classificazione.   == Voci correlate == Data mining Algoritmo ID3   == Altri progetti ==   Wikimedia Commons contiene immagini o altri file su Albero di decisione   == Collegamenti esterni == Teoria delle decisioni sull'enciclopedia Treccani, treccani.it."
Environment for DeveLoping KDD-Applications Supported by Index-Structures (in italiano: Ambiente per lo sviluppo di applicazioni KDD per strutture ad indice) in sigla ELKI e un programma-framework di Data mining usato per la ricerca e l'insegnamento dall'unita di ricerca in sistemi di basi di dati dell'Universita di Monaco in Germania. Ha lo scopo di permettere lo sviluppo e la valutazione di algoritmi avanzati di data mining e la loro interazione con le basi di dati con indice. La prima versione, la 0.1 e uscita nel luglio 2008. L'ultima ad aprile 2012, la versione 0.5.   == Algoritmi inclusi == Algoritmi inclusi: Analisi Cluster: K-means Expectation-maximization algorithm Single-linkage clustering Dbscan (Density-Based Spatial Clustering of Applications with Noise) OPTICS (Ordering Points To Identify the Clustering Structure),incluse le estensioni OPTICS-OF, DeLi-Clu, HiSC, HiCO e DiSH SUBCLU (Density-Connected Subspace Clustering for High-Dimensional Data)  Rilevamento anomalo: LOF (Local outlier factor) OPTICS-OF DB-Outlier (Distance-Based Outliers) LOCI (Local Correlation Integral) LDOF (Local Distance-Based Outlier Factor) EM-Outlier  Strutture con Indice spaziale: R-tree R*-tree M-tree  Valutazione: Receiver operating characteristic (ROC curve) Scatter plot Histogram Parallel coordinates  Altri: Apriori algorithm Dynamic time warping Analisi delle componenti principali   == Note ==   == Voci correlate == Indicizzazione   == Altri progetti ==   Wikimedia Commons contiene immagini o altri file su Environment for DeveLoping KDD-Applications Supported by Index-Structures   == Collegamenti esterni == (DE) Pagina ufficiale di ELKI, elki.dbs.ifi.lmu.de.
L'analisi dei dati e un processo di ispezione, pulizia, trasformazione e modellazione di dati con il fine di evidenziare informazioni che suggeriscano conclusioni e supportino le decisioni strategiche aziendali. L'analisi di dati ha molti approcci e sfaccettature, il che comprende tecniche diversissime tra loro che si riconoscono con una serie di definizioni varie nel commercio, le scienze naturali e sociali. Il data mining e una tecnica particolare di analisi dei dati che si focalizza nella modellazione e scoperta di conoscenza per scopi predittivi piuttosto che descrittivi. Il business intelligence identifica l'analisi di dati che si basa fondamentalmente sull'aggregazione, focalizzandosi sulle informazioni aziendali. Nelle applicazioni statistiche, gli studiosi dividono l'analisi dei dati in statistica descrittiva, analisi dei dati esplorativa (ADE) e analisi dei dati di conferma (ADC). L'ADE si concentra sullo scoprire nuove caratteristiche presenti nei dati, mentre l'ADC nel confermare o falsificare le ipotesi esistenti. L'analisi predittiva si concentra sull'applicazione di modelli statistici o strutturali per classificazione o il forecasting predittivo, mentre l'analisi testuale applica tecniche statistiche, linguistiche e strutturali per estrarre e classificare informazioni da fonti testuali, una categoria di dati non-strutturati. L'integrazione di dati e un precursore dell'analisi dei dati, la quale e collegata alla visualizzazione di dati.   == Collegamenti esterni == Analisi dei dati, in Tesauro del Nuovo soggettario, BNCF, marzo 2013.
"Nella teoria delle decisioni, le curve ROC (Receiver Operating Characteristic o anche note come Relative Operating Characteristic) sono degli schemi grafici per un classificatore binario. Lungo i due assi si possono rappresentare la sensibilita e (1-specificita), come True Positive Rate (vero positivo) e False Positive Rate (falso positivo). In altre parole, si studiano i rapporti fra allarmi veri (hit rate) e falsi allarmi. Le curve ROC furono utilizzate per la prima volta da alcuni ingegneri elettrici durante la seconda guerra mondiale, che volevano scovare i nemici utilizzando il radar durante le battaglie. Recentemente invece le curve ROC sono utilizzate anche in medicina, radiologia, psicologia, veterinaria, fisica e altri ambiti, come il machine learning e data mining.   == Concetto basilare == Se si considera un problema di predizione a 2 classi (classificatore binario come da figura: distribuzione rossa e azzurra), scelto un valore di soglia (threshold o cut-off), in cui e possibile andare a decidere il risultato, ovvero se la classe e positiva (p) o negativa (n), dato che le due curve risultano in parte sovrapposte, sono possibili quattro risultati a seconda della posizione del valore di cut-off: se il risultato della predizione e positivo p e il valore vero e anche positivo p, viene chiamato vero positivo (true positive - TP); se invece il valore vero e negativo, viene chiamato falso positivo (false positive - FP); contrariamente un vero negativo (true negative - TN) occorre quando entrambi, il risultato e il valore vero, sono negativi; un falso negativo (false negative - FN) invece e quando il risultato e negativo e il valore vero e positivo. E inoltre possibile rappresentare questo tipo di situazione anche andando a utilizzare una tabella di contingenza di tipo 22, dove le colonne rappresentano la distinzione tra soggetti sani e malati; le righe invece rappresentano il risultato del test sui pazienti. Un risultato qualitativo del test potrebbe essere quello di andare a valutare il numero di falsi positivi e negativi, meno ve ne saranno e tanto il test sara maggiormente valido. Una curva ROC e il grafico dell'insieme delle coppie (FP, TP) al variare di un parametro del classificatore. Per esempio, in un classificatore a soglia, si calcola la frazione di veri positivi e quella di falsi positivi per ogni possibile valore della soglia; tutti i punti cosi ottenuti nello spazio FP-TP descrivono la curva ROC. Il test che si effettua attraverso l'analisi delle curve ROC ha la capacita di discernere, ad esempio, tra un insieme di popolazione sana e malata, andando ad analizzare l'area sottesa dalla curva ROC (Area Under Curve, AUC). Cio equivale alla probabilita che il risultato del test effettuato su un individuo estratto a caso dal gruppo dei malati sia superiore a quello estratto a caso dal gruppo dei sani. Solitamente si ha che le curve ROC passano per i punti (0,0) e (1,1), avendo inoltre due condizioni che rappresentano due curve limite: una che taglia il grafico a 45, passando per l'origine. Questa retta rappresenta il caso del classificatore randomico (linea di nessun beneficio), e l'area sottesa e pari a 0,5. la seconda curva e rappresentata dall'insieme di segmenti che dall'origine sale al punto (0,1) e da quello che congiunge il punto (0,1) a (1,1), avendo un'area sottesa di valore pari a 1, ovvero rappresenta il classificatore perfetto.   == Alcuni concetti ==                         T         P         R         =         T         P                    /                  P         =         T         P                    /                  (         T         P         +         F         N         )                 {\displaystyle TPR=TP/P=TP/(TP+FN)}                            F         P         R         =         F         P                    /                  N         =         F         P                    /                  (         F         P         +         T         N         )                 {\displaystyle FPR=FP/N=FP/(FP+TN)}    accuratezza                         A         C         C         =         (         T         P         +         T         N         )                    /                  (         P         +         N         )                 {\displaystyle ACC=(TP+TN)/(P+N)}      == Note ==   == Altri progetti ==   Wikimedia Commons contiene immagini o altri file su Receiver operating characteristic"
"Il Predictive Model Markup Language (PMML) e un linguaggio di markup aperto basato su XML, sviluppato dal Data Mining Group (DMG), concepito per permettere la descrizione di modelli di analisi predittiva che possano essere condivisi tra sistemi ed applicazioni diversi. PMML e uno standard de facto, che ha avuto origine nel 1997. Da quando PMML e uno standard basato su XML, le specifiche sono XML Schema.   == Componenti PMML == PMML segue una struttura intuitiva per descrivere un modello di data mining, che sia esso un modello di rete neurale o un modello di regressione logistica. La struttura puo essere descritta dai seguenti componenti: Header: contiene informazioni generali circa il documento PMML, come informazioni sul copyright del modello, sua descrizione e informazioni riguardo l'applicazione (nome e versione) usata per generarlo. Contiene anche un attributo di tipo timestamp il quale puo essere usato per specificare la data della creazione del modello. Data Dictionary: contiene le definizioni di tutti i possibili campi usati dal modello. Qui e definito il campo come continuo, categorico o ordinale (attributo optype). Da questa definizione dipende l'appropriata valutazione del range che e definito dopo il tipo di dato (come string e double). Data Transformations: trasformazioni che consentono il mappaggio di dati in diverse forme, per essere usate dal modello di mining. PMML definisce cinque trasformazioni: Normalization: mappa i valori a numeri, l'input puo essere continuo o discreto. Discretization: mappa valori continui in valori discreti. Value mapping: mappa valori discreti in valori discreti. Functions: deriva un valore dall'applicazione di una funzione con uno o piu parametri. Aggregation: usata per sintetizzare o collezionare gruppi di valori.  Model: contiene la definizione del modello di data mining. La multi-layered feedforward neural network e la piu comune rappresentazione rete neurale nelle odierne applicazioni, che ha conquistando la popolarita grazie all'efficienza data dall'algoritmo di training conosciuto come backpropagation. Una rete e rappresentata in PMML da un elemento ""NeuralNetwork"" il quale contiene attributi come: Nome del modello (attributo modelName) Nome funzione (attributo functionName) Nome algoritmo (attributo algorithmName) Funzione di attivazione (attributo activationFunction) Numero di strati (attributo numberOfLayers)  Queste informazioni sono seguite da un albero che modella gli strati neurali i quali specificano l'architettura del modello di rete neurale. Questi attributi sono NeuralInputs, NeuralLayer, e NeuralOutputs. Accanto alla rete neurale, PMML consente la rappresentazione di altri tipi di modelli di data mining come: macchine a vettori di supporto, regole di associazione, classificatore bayesiano, clustering models, text models, alberi di decisione e differenti modelli di regressione. Mining Schema: lo schema di mining elenca tutti i campi usati nel modello. Questo puo essere un sottoinsieme dei campi definiti nel dizionario. Contiene informazioni specifiche di ogni campo, come: Nome (attributo name): deve riferirsi a un campo del dizionario Tipo d'uso (attributo usageType): definisce il modo di utilizzo di un campo nel modello. Tipicamente i valori sono: active, predicted, e supplementary. I campi Predicted sono quei valori interi predetti dal modello. Trattamento estremo (attributo outliers): definisce i trattamenti estremi che possono essere utilizzati. In PMML, gli estremi (outliers) possono essere trattati come valori mancanti, come valori estremi (basati sulla definizione di massimo e minimo valore del particolare campo, o lasciandoli inalterati). Politica di rimpiazzamento del valore (attributo missingValueReplacement): se questo attributo e specificato dopo un valore mancante e automaticamente rimpiazzato da un valore calcolato. Trattamento valore mancante (attributo missingValueTreatment): indica come il valore di rimpiazzamento e derivato (es. come valore, media o mediana).  Targets: consente nel post-processing dei valori predetti di fare operazioni di scalatura se l'output del modello e continuo. Targets possono essere anche usati per classificare compiti. In questo caso l'attributo priorProbability specifica una probabilita di default per la categoria target corrispondente. Esso e usato se la predizione logica non produce un risultato. Questo puo accadere, per esempio, se un valore di input e mancante e questo e non e presente un metodo di trattamento dei valori mancanti. Output: Questo elemento puo essere usato per nominare tutti i campi di output desiderati aspettati dal modello. Le caratteristiche del campo predetto sono tipicamente i valori predetti, la probabilita, affinita cluster (per modelli clustering), errore standard, etc.   == Note =="
"L'apprendimento approfondito (in inglese deep learning) e quel campo di ricerca dell'apprendimento automatico e dell'intelligenza artificiale che si basa su diversi livelli di rappresentazione, corrispondenti a gerarchie di caratteristiche di fattori o concetti, dove i concetti di alto livello sono definiti sulla base di quelli di basso. Tra le architetture di apprendimento approfondito si annoverano le reti neurali profonde, la convoluzione di reti neurali profonde, le Deep belief network, e reti neurali ricorrenti, che sono state applicati nella computer vision, nel riconoscimento automatico del discorso, nell'elaborazione del linguaggio naturale, nel riconoscimento audio e nella bioinformatica. ""Deep learning"" e un'espressione oggi famosa che rida lustro al concetto di rete neurale.   == Storia ==   == Architetture ==   === Reti neurali profonde ===   === Reti neurali convoluzionali === La Rete neurale convoluzionale (Convolution Neural Network CNN) e un metodo di scelta per elaborare dati visuali e dati di tipo 2D. Una CNN e composta da uno piu strati convoluzionali con strati completamente connessi verso l'alto. Usa anche pesi e strati comuni (pooling layers). In particolare il ""max-pooling"" e spesso usato nell'architettura convoluzionale di Fukushima. Quest'architettura permette alle CNN di avedere dei vantaggi dalle strutture 2D di ingresso. Sono particolarmente efficaci nell'area delle immagini e di riconoscimento del discorso. Possono essere allenate anche con la backpropagation standard. Sono inoltre facili da allenare rispetto ad altre reti neurali profonde o feed-forward ed hanno molti meno parametri da stimare. Un programma di CNN e il DeepDream di Google.   === Reti neurali ricorsive ===   === Compressore di storia neurale ===   === Reti Deep Belief ===   === Autoencoder impilato ===   === Rete di impilamento profondo ===   === Rete di impilamento profondo di tensore ===   === Spike-and-slab RBM ===   === Macchine di Boltzmann profonde ===   === Macchine kernel multilivello ===   === Strutture di memoria differenziabile LSTM correlata ===   === Reti deep-q === Questa e una classe di modelli d'apprendimento profondi usando il Q-learning, una forma di apprendimento con rinforzo, del Google DeepMind. Risultati preliminari presentati nel 2014 con un articolo pubblicato su Nature nel febbraio 2015. L'applicazione di cui si fa riferimento e un gioco dell'Atari 2600.   === Hashing semantico ===   == Applicazione == Riconoscimento automatico del discorso Riconoscimento di immagini Elaborazione del linguaggio naturale Scoperta di farmaci e tossicologia Customer relationship management Sistema di raccomandazione Bioinformatica   == Librerie software == Torch  Libreria software open source di machine learning in Lua Theano  Libreria open source di machine learning in Python. Deeplearning4j  Libreria open source di deep learning in Java. Fornisce parallelizzazione di CPU e GPU. [1] OpenNN  Libreria open source in C++ che impementa reti neurali profonde e fornisce parallelizazzioni con CPU. Gensim  Libreria di elaborazione del linguaggio naturale in Python. Apache SINGA  A deep learning platform developed for scalability, usability and extensibility. TensorFlow  Libreria open source di machine learning in C++ e Python con API per entrambe le versioni di Google. Fornisce parallelizzazione con CPU e GPU.   == Note ==   == Collegamenti esterni == (EN) Deep learning, deeplearning.net. (EN) Video on Recent Developments in Deep Learning, di Geoff Hinton"
"Google Traduttore (Google Translate nella versione inglese) e un servizio di traduzione automatica offerto dalla societa Google Inc., per tradurre una sezione di testo, o un'intera pagina web, in un'altra lingua. Mentre altri servizi di traduzione, come Babel Fish, AOL e Yahoo!, usano come software di base SYSTRAN, Google Traduttore usa un software di traduzione proprio dal 2007.   == Funzioni == Il servizio include anche la funzionalita di traduzione di un'intera pagina web. Questo tipo di traduzione e limitato nel numero di paragrafi per pagina web (un paragrafo e indicato dal tag html <p>); comunque, se un testo in una pagina web e separato orizzontalmente in altri modi (come per esempio utilizzando un'immagine rappresentante una linea bianca orizzontale) possono essere tradotte anche pagina web che contengono migliaia di parole. Google Traduttore, come gli altri servizi di traduzione automatica, ha le sue limitazioni. Mentre puo essere utile per capire il contenuto generale di un testo in un linguaggio sconosciuto, non e utile per creare traduzioni automatiche corrette di testi (per esempio, non e conveniente utilizzarlo per tradurre automaticamente un articolo di Wikipedia da una lingua ad un'altra) dato che non fornisce traduzioni accurate: spesso traduce alcune parole/frasi (che magari possono avere piu significati) con risultati completamente fuori dal contesto generale ed inoltre non applica regole grammaticali. Un altro limite consiste nel fatto che il software effettua traduzioni soltanto da o verso l'inglese, ne consegue che la traduzione da una lingua all'altra richiesta dall'utente viene effettuata traducendo prima la lingua iniziale in inglese e poi traducendo la versione inglese nella lingua richiesta. Ne consegue che la traduzione e meno fedele al testo originale e che si ha un maggiore rischio di traduzione scorretta. Eventuali omografi inglesi, ad esempio, potrebbero venire tradotti scorrettamente, anche se non lo sono nella lingua originale.   == Approccio == Google Traduttore e basato su un approccio di traduzione chiamato traduzione automatica statistica e, piu precisamente, sulla ricerca di Franz-Josef Och, che vinse il concorso DARPA per la velocita di traduzione automatica nel 2003. Och e ora a capo del dipartimento di Google per la traduzione automatica. Och sostiene che una solida base per sviluppare un sistema di traduzione automatica in grado di tradurre da una lingua ad un'altra, debba avere almeno un milione di corrispondenze di parole della prima lingua con l'altra, ed il significato di almeno un miliardo di parole per ognuna delle due lingue. I modelli statistici di questi dati vengono poi utilizzati per creare la traduzione. Per acquisire questa enorme mole di dati linguistici, Google ha usato documenti delle Nazioni Unite, e questo e probabilmente uno dei principali motivi del perche Google si e concentrata inizialmente sulla traduzione dall'inglese verso le lingue ufficiali delle Nazioni unite (arabo, cinese, francese, russo e spagnolo) e non, per esempio, verso lingue come il giapponese o il tedesco. Dopo la vittoria di AlphaGo, l'intelligenza artificiale costruita da Google DeepMind, a Marzo 2016 BigG ha annunciato che per aumentare la qualita delle traduzioni implementera anche in Google Traduttore la tecnologia proprietaria del deep learning, gia ora utilizzato con successo in Google Foto, Google Maps e GMail.   == Stadi del servizio == (in ordine cronologico) Inizio Secondo stadio dall'inglese al portoghese dal portoghese all'Inglese dall'inglese all'olandese dall'olandese all'inglese  Terzo stadio dall'inglese all'italiano dall'italiano all'inglese  Quarto stadio Quinto stadio (lanciato nel dicembre 2006) dall'inglese al russo dal russo all'inglese  Sesto stadio (lanciato nell'aprile 2007) dall'inglese all'arabo dall'arabo all'inglese  Settimo stadio (lanciato nel febbraio 2007) Ottavo stadio (lanciato nell'ottobre 2007) Tutte le 25 coppie di lingue utilizzano il sistema di traduzione di Google  Nono stadio dall'inglese all'hindi dall'Hindi all'inglese  Decimo stadio (Da questo punto si possono fare traduzioni tra qualsiasi coppia di lingue, passando attraverso l'inglese, se necessario) (lanciato nel maggio 2008) Undicesimo stadio (lanciato il 25 settembre 2008) Dodicesimo stadio (lanciato il 30 gennaio 2009) Tredicesimo stadio (lanciato il 19 giugno 2009) Quattordicesimo stadio (lanciato il 24 agosto 2009) Quindicesimo stadio (lanciato il 19 novembre 2009) La beta e conclusa, e possibile la romanizzazione per: cinese, giapponese, coreano, russo, ucraino, bielorusso, bulgaro, greco, hindi e thailandese. Per la transiletterazione dall'arabo, dal persiano e dall'hindi e possibile la traslitterazione in altro modo. Il testo in lingua inglese, francese, italiana e tedesca tradotto puo essere eseguito con la sintesi vocale.  Sedicesimo stadio (lanciato il 30 gennaio 2010) Creolo haitiano  Diciassettesimo stadio (lanciato ad aprile 2010) Il testo in lingua spagnola e hindi tradotto puo essere eseguito con la sintesi vocale. Diciottesimo stadio (lanciato il 5 maggio 2010) Il testo in lingua afrikaans, albanese, catalana, ecea, cinese mandarina, croata, danese, finlandese, gallese, indonesiana, islandese, lettone, macedone, olandese, polacca, portoghese, rumena, russa, serba, slovacca, svedese, swahili, turca, ungherese, e vietnamita tradotto puo essere eseguito con la sintesi vocale. Diciannovesimo stadio (lanciato il 13 maggio 2010)   == Integrazioni per i browser == Esiste un certo numero di estensioni Firefox che, similmente a Google Traduttore, permettono l'accesso al servizio di traduzione con un clic del tasto destro del mouse.   == Diffusione == Google Traduttore viene usato ogni mese da 200 milioni di utenti.   == Note ==   == Voci correlate == Google Translator Toolkit   == Collegamenti esterni == Google Translate italiano, translate.google.it. Nel cartone web (su youTube)smilecom a seguito dell'invasione di meme appare l'""asteroide Google Traduttore"", dalla quale verra colpito Frank."
Theano e una libreria open source di computazione numerica per il linguaggio di programmazione Python sviluppata da un gruppo di machine learning della Universita di Montreal. In Theano i calcoli sono espressi usando una sintassi simile a NumPy e compilato per eseguire efficientemente sia su architetture CPU che GPU.   == Voci correlate == SciPy Torch   == Collegamenti esterni == (EN) Theano(GitHub) (EN) Theano presso Deep Learning, Universite de Montreal
Andrew Yan-Tak Ng (T, S, Wu EndaP) (1976) e un informatico statunitense. Professore associato all'Universita di Stanford, e cofondatore di Coursera. Ha lavorato presso Google e Baidu. Nato nel Regno Unito, vissuto ad Hong Kong e a Singapore, Andrew Ng ha studiato presso il Massachusetts Institute of Technology e l'Universita della California, Berkeley.   == Note ==   == Collegamenti esterni == (EN) Andrew Ng, andrewng.org. (EN) Andrew Ng, su Coursera.
Nel machine learning, una rete neurale convoluzionale (CNN o ConvNet dall'inglese convolutional neural network) e un tipo di rete neurale artificiale feed-forward in cui il pattern di connettivita tra i suoi neuroni e ispirato dall'organizzazione della corteccia visiva animale, i cui neuroni individuali sono disposti in maniera tale da rispondere alle regioni di sovrapposizione che tessellano il campo visivo. Le reti convoluzionali sono ispirate da processi biologici e sono variazioni di percettroni multistrato progettate per usare al minimo la pre-elaborazione. Hanno diverse applicazioni nel riconoscimento di immagini e video, nei sistemi di raccomandazione e nell'elaborazione del linguaggio naturale.   == Storia ==   == Costruzione dei blocchi == Strato convoluzionale Strato di Pooling Strato ReLu Strato completamente connesso Strato di perdita   == Scelta degli iperparmetri ==   == Metodi di regolarizzazione ==   == Applicazioni ==   == Librerie di programmazione == Caffe: Caffe (replacement of Decaf) Torch (www.torch.ch): neon: The fastest OverFeat: Cuda-convnet: MatConvnet Theano: Deeplearning4j: Deep learning in Java and Scala on GPU-enabled Spark deeplearning-hs: Deep learning in Haskell, supports computations with CUDA. TensorFlow Veles   == Note ==   == Voci correlate == Percettrone   == Collegamenti esterni == (EN) Feedforward neural networks tutorial (EN) Feedforward Neural Network: Example (EN) Feedforward Neural Networks: An Introduction
L'Analisi del sentiment o Sentiment analysis (ma anche opinion mining) e la maniera a cui ci si riferisce all'uso dell'elaborazione del linguaggio naturale, analisi testuale e linguistica computazionale per identificare ed estrarre informazioni soggettive da diverse fonti. L'analisi del sentiment e ampiamente applicato per analizzare social media per una varieta di applicazioni, dal marketing al servizio clienti.   == Metodi e caratteristiche == Gli approcci esistenti all'analisi del sentiment possono essere raggruppati in 4 categorie principali: Spotting di parole chiave Affinita lessicale Metodi statistici Tecniche di livello concettuale La prima classifica il testo da categorie influenti basata sulla presenza di paroli influenti ambigue come contento, triste, impaurito, annoiato . L'affinita lessicale non rileva solamente le parole influenzanti, ma anche assegna arbitariamente alle parole una probabile affinita a emozioni particolari. I metodi statistici fanno leva invece su elementi tratti dal machine learning come analisi semantica latente, macchine a vettori di supporto, bag of words e orientazione semantica. Per estrapolare l'opinione in un contesto e ottenerne delle caratteristiche, sono usate le relazioni grammaticale delle parole. Le relazioni sono ottenute da un'analisi sintattica profonda del testo. A differenza delle tecniche puramente sintattiche, gli approcci a livello concettuale fanno leva sugli elementi della rappresentazione della conoscenza come le ontologie e le reti semantiche,e quindi, sono capaci di rilevare semantiche che sono espresse in maniera sottile.   == Sentiment analysis e Web 2.0 ==   == Risorse di analisi del sentiment == VOcabolari sentiment e parole: Affective Norms for English Words (ANEW) SenticNet SentiWordNet WordNet-Affect Analizzatori di sentiment: AlchemyAPI (commercial) BitextAPI (commercial) Semantria (commercial) Sentiment140 (commercial, for Twitter) Stanford NLP (academic) Twinword (commercial, free / unlimited) Werfamous (free) WordStat (commercial) Buzzlogix (free and commercial versions) Documenti con annotazioni manuali di sentiment che possono essere usati per valutare gli algoritmi): Twitter dataset in 4 languages (12,500 tweet)   == Note ==   == Collegamenti esterni == (EN) 2008 Survey Article - Opinion mining and sentiment analysis (Pang & Lee) (EN) 2011 Survey Article - Comprehensive Review Of Opinion Summarization (Kim et al) (EN) 2013 Survey Article - New Avenues in Opinion Mining and Sentiment Analysis (Cambria et al) (EN) Sentiment Analysis Article - Sentiment Analysis 101
"La serie GeForce 900 e una famiglia di GPU sviluppata da Nvidia, usata in PC desktop e portatili. Serve come introduzione per la fascia alta dell'architettura Maxwell (il codename del chip inizia per GM-XXX), che prende nome dal fisico scozzese James Clerk Maxwell. La microarchitettura di Maxwell, il successore di Kepler, sara per la prima volta proprio una CPU ARM. Questo fa si che le GPU Maxwell siano molto indipendenti dalla CPU principale secondo il CEO di Nvidia Jen-Hsun Huang. Nvidia si aspetta tre principali caratteristiche con l'architettura Maxwell: miglioramento delle prestazioni grafiche, programmazione semplificata e una maggiore efficienza energetica rispetto alle serie GeForce 700 e GeForce 600. Maxwell e stata annunciata a settembre 2010. La prima scheda GeForce dedicata al consumatore e stata rilasciata ad inizio 2014. Nvidia sta programmando di rilasciare elaboratori ad alta velocita Tesla e schede grafiche professionali Quadro basata sull'architettura Maxwell verso fine 2014. Eventualmente, questa architettura verra usata per processori mobile che seguono la famiglia di prodotti Erista del SoC Tegra.   == Architettura ==   === Prima generazione Maxwell (GM10x) === La prima generazione Maxwell GM107/GM108 e stata rilasciata come GeForce GTX 745, GTX 750/750 Ti e GTX 850M/860M (GM107) e GTX 830M/840M (GM108). Questi nuovi chip forniscono poche nuove funzionalita; Nvidia si e voluta concentrare sull'efficienza e sul basso consumo energetico. Nvidia ha incrementato la memoria cache L2 da 256 KB di GK107 a 2 MB su GM107, riducendo l'ampiezza di banda per quanto riguarda la memoria necessaria. Di conseguenza Nvidia ha ridotto il bus della memoria da 192 bit su GK106 a 128 bit su GM107, risparmiando ulteriore energia. Nvidia ha inoltre modificato il design degli streaming multiprocessor rispetto a Kepler (SMX), chiamandoli SMM. La struttura del warp scheduler e stata ereditata da Kepler, che permette ad ogni schedule di emettere fino a due istruzioni indipendenti per ogni altra e che sono in ordine dallo stesso warp. Il layout dell unita SMM e diviso in modo tale che ognuna delle 4 warp schedula un SMM che controlla 1 di 32 FP32 CUDA cores, 1 di 8 load/store units, e 1 di 8 unita per funzioni speciali. Tutto cio e in contrasto con Kepler, dove ogni SMX posside 4 schedulers che controlano un gruppo condiviso di 6 su 32 FP32 CUDA cores, 2 di 16 load/store units, e 2 di 16 unita per funzioni speciali. Queste unita sono connesse da una traversa che usa corrente per permettere alle risorse di essere condivise. Questa traversa e stata rimossa in Maxwell. Texture units e FP64 CUDA cores rimangono condivisi. SMM permettono una allocazione piu fine delle risorse rispetto a SMX, si risparmia corrente quando il carico di lavoro non e ottimale per la condivisione di risorse. Nvidia dichiara che 128 CUDA core SMM hanno il 90% delle performance di 192 CUDA core SMX. Anche ogni Graphics Processing Cluster, o GPC, contiene fino a 4 unita SMX in Kepler, e fino a 5 unita SMM nella prima generazione di Maxwell. GM107 supporta CUDA Compute Capability 5.0 rispetto al 3.5 di GK110/GK208 e al 3.0 di GK10x. Dynamic Parallelism e HyperQ, due features di GK110/GK208, sono inoltre supportare in tutta la linea di prodotti Maxwell. Maxwell dispone inoltre di un supporto nativo a shared memory atomic operations for 32-bit integers e shared memory 32-bit and 64-bit compare-and-swap (CAS), che possono essere implementato di usare altre funzioni atomiche.   ==== NVENC ==== Le GPU basate su tecnologia Maxwell contengono inoltre il blocco NVENC SIP introdotto in Kepler. L'encoder video Nvidia, NVENC, e da 1.5 a 2 volte piu veloce rispetto alle schede video basate sull'architettura Kepler e questo significa che e in grado di decodificare video da 6 a 8 volte il tempo della riproduzione.   ==== PureVideo ==== Nvidia ha inoltre dichiarato un aumento di performance da 8 a 10 volte nella funzione PureVideo e video decoding grazue alla cache del video decoder cache accoppiate con l'incremento dell'efficienza della memoria. Tuttavia la condifica H.265 non e completamente supportata tramiche codifica hardware, creando un mix tra codifica hardware e software. Quando viene decodificato un video, un nuovo stato a basso consumo ""GC5"" e usato dalle GPU Maxwell per risparmiare corrente.   === Seconda generazione Maxwell (GM20x) === La seconda generazione di GPU Maxwell introduce una serie di nuove tecnologie: Dynamic Super Resolution, Third Generation Delta Color Compression, Multi-Pixel Programming Sampling, Nvidia VXGI (Real-Time-Voxel-Global Illumination), VR Direct, Multi-Projection Acceleration, e Multi-Frame Sampled Anti-Aliasing(MFAA) tuttavia e stato rimosso il supporto a Coverage-Sampling Anti-Aliasing(CSAA). E stato inoltre aggiunto il supporto a HDMI 2.0. La seconda generazione di Maxwell ha inoltre modificato il rapporto di ROP per controller di memoria da 8:1 a 16:1. Nonostante cio, alcuni di questi ROP sono generalmente inattivi nella GTX 970 perche non ci sono abbastanza SMM abilitati per assegnare ad essi lavoro e prima che venga ridotto il livello massimo di saturazione. La seconda generazione Maxwell ha inoltre fino a 4 unita SMM per GPC, al posto di 5 unita SMM per GPC. GM204 supporta CUDA Compute Capability 5.2 al posto del 5.0 presente nella GPU GM107/GM108 e al 3.5 presente nelle GPU GK110/GK208 e 3.0 sulle GPU GK10x. La seconda generazione di GPU Maxwell (GM20x) hanno un'unita NVENC aggiornata che supporta la codifica HEVC e H.264 a 1440p/60FPS e 4K/60FPS rispetto all'NVENC della prima generazione GM10x che supporta solamente la codifica H.264 a 1080p/60FPS. La GPU Maxwell GM206 supporta a pieno la codifica HEVC.   == Prodotti ==   == Futuro == Dopo Maxwell, la successiva architettura ha nome in codice Pascal. Nvidia ha annunciato che le GPU basate su Pascal avranno come caratteristiche: stacked DRAM, Unified Memory, NVLink. Pascal e atteso per il 2016.   == Note =="
"Burn e il primo singolo del gruppo rap statunitense Mobb Deep estratto dall'album ""Infamy"". E stato prodotto da Havoc e vi hanno partecipato Big Noyd e la rapper Vita (famosa per le sue varie partecipazioni a singoli di artisti della The Inc. Records).   == Informazioni == La canzone e presente nell'album con il titolo di ""The Learning (Burn)"" e il suo testo e stato scritto dagli stessi Havoc, Prodigy, Vita e Big Noyd. La prima strofa e rappata da Havoc, la seconda da Big Noyd e la terza da Prodigy, mentre Vita canta il ritornello. ""Burn"" ha raggiunto la posizione n.99 nella chart Billboard Hot 100 (rivelandosi qui un insuccesso), la n.56 nella Hot R&B/Hip-Hop Songs e la n.14 nella Hot Rap Tracks.   == Videoclip == Il videoclip e stato girato in bianco e nero e si svolge per la maggior parte della sua durata in un ampio salone in cui i Mobb Deep e Big Noyd, vestiti in abiti invernali, cantano su di un palco di fronte a molte persone.   == Tracce == LATO A: Burn [Clean Version] LATO B: Burn [Dirty Version] Burn [Instrumental]   == Posizioni in classifica ==   == Note ==   == Collegamenti esterni =="
"Ona Zee (Los Angeles, 3 marzo 1951) e un'attrice pornografica statunitense.    == Biografia == Tra le poche, autentiche leggende del porno, Ona Zimmerman, in arte Ona Zee, ha cominciato la propria carriera come modella per l'agenzia Wilhelmina Models, posando tra l'altro per la rivista Cosmopolitan. Non avendo il tipico fisico dell'attrice pornografica bionda e siliconata, Ona Zee si e subito distinta per le sue prestazioni hardcore senza limiti, sia nelle penetrazioni vaginali, anali o orali, sia nelle penetrazioni multiple. Ha attivamente percorso anche i filoni bondage, fetish e transessuale. ""Sono un'esibizionista ed esteta"" affermava nelle interviste che concedeva ""avere rapporti sessuali sapendo di avere un pubblico attento a cio che faccio mi gratifica come poche altre cose al mondo"". E stata sposata piu volte. Ha partecipato con Nina Hartley al talk-show The Oprah Winfrey Show per parlare dell'industria del porno. Nel 2007 ha lanciato la propria linea di gioielli a Los Angeles.   == Riconoscimenti == 1989 AVN Award  Migliore attrice (film)  Portrait of an Affair 1992 AVN Award  Migliore attrice (video)  Starlet 1993 AVN Award  Best Supporting Actress (film)  Secret Garden 1 e 2 2000 Hot d'Or  Hot d'Or d'Honneur   == Filmografia ==   === Attrice ===   === Regista ===   == Note ==   == Altri progetti ==   Wikimedia Commons contiene immagini o altri file su Ona Zee   == Collegamenti esterni == (EN) Profilo di Ona Zee, pornstarclassics.co.uk. (EN) Ona Zee, in Internet Movie Database, IMDb.com. (EN) Ona Zee, in Internet Adult Film Database. (EN) Ona Zee, in Adult Film Database."
"Infamy e il quinto album del duo hip-hop Mobb Deep. Uscito dopo il dissing di Jay-Z nei confronti di Prodigy e Nas, (il brano Takeover, da The Blueprint, album di Jay-Z del 2001) Infamy contiene ""Crawlin'"", la risposta di Prodigy a Jay-Z, in cui il rapper rivale e dipinto come un rapper omosessuale (in termini certamente meno edulcorati). "" Infamy raggiunse il disco d'oro, vendendo piu di 500,000 copie. L'album ebbe anche un modesto successo di critica e buone recensioni su The Source e HipHopDX, ma anche recensioni meno buone da parte di Allmusic e di Rolling Stone.   == Tracce =="
"Nelle neuroscienze, il termine rete neurale (o rete neuronale) viene utilizzato come riferimento a una rete o a un circuito di neuroni. Sono spesso identificati come gruppi di neuroni che svolgono una determinata funzione fisiologica nelle analisi di laboratorio. Le reti neurali hanno ispirato le reti neurali artificiali, utilizzate nel campo dell'apprendimento automatico.   == Fondamenti ==  In molti organismi viventi pluricellulari sono presenti complesse organizzazioni di cellule nervose, con compiti di riconoscimento delle configurazioni assunte dall'ambiente esterno, memorizzazione e reazione agli stimoli provenienti dallo stesso. Il cervello umano rappresenta probabilmente il piu mirabile frutto dell'evoluzione per le sue capacita di elaborare informazioni. Al fine di compiere tali operazioni, le reti biologiche si servono di un numero imponente di semplici elementi computazionali (neuroni) fittamente interconnessi in modo da variare la loro configurazione in risposta agli stimoli esterni: in questo senso puo parlarsi di apprendimento ed i modelli artificiali cercano di catturare questo tratto distintivo della biologia. Generalmente un neurone e costituito di 3 parti principali: il soma: corpo cellulare l'assone: linea di uscita del neurone unica ma che si dirama in migliaia di rami il dendrite: linea di entrata del neurone che riceve segnali in ingresso da altri assoni tramite le sinapsi Il corpo cellulare esegue una ""somma pesata"" (integrazione) dei segnali in ingresso. Se il risultato supera un certo valore di soglia allora il neurone si attiva ed e prodotto un ""potenziale di azione"" che e trasportato all'assone. Se il risultato non supera il valore di soglia, il neurone rimane in uno stato di riposo. Una rete neurale descrive una popolazione di neuroni fisicamente interconnessi tra loro, od un gruppo di neuroni cui diversi fattori di produzione o di segnalazione definiscono un circuito riconoscibile. La comunicazione tra i neuroni spesso comporta un processo elettrochimico. L'interfaccia attraverso la quale essi interagiscono con i neuroni circostanti e costituita, come precedentemente indicato, da diversi dendriti (ingresso della connessione), che sono collegati tramite sinapsi ad altri neuroni, ed un assone (output della connessione). Invece, un circuito neurale e un ente funzionale di neuroni interconnessi che si influenzano a vicenda (simile a quello di un loop di un controllo in cibernetica).   == Altri progetti ==   Wikimedia Commons contiene immagini o altri file su rete neurale"
La neurofisiologia e una branca della biologia ed in particolare della fisiologia umana che studia il funzionamento dei neuroni e delle reti neurali. Caratteristica peculiare della neurofisiologia e lo studio e il monitoraggio dell'attivita chemioelettrica delle singole cellule nervose e di strutture nervose piu complesse. Data l'estensione e la complessita della materia trattata, vi sono molti neurofisiologi che studiano anche i processi cognitivi da un punto di vista fisiologico. Da questo punto di vista la neurofisiologia e integrata con la psicofisiologia e la psicologia fisiologica come nucleo principale delle scienze cognitive. Queste due pero non studiano tanto il cervello in se, ma piuttosto cercano di capire a livello logico di funzionamento le relazioni tra fisiologia e processi cognitivi o comportamento. La neurofisiologia da qualche decennio e diventata, soprattutto negli Stati Uniti, una disciplina molto importante per i suoi contributi per lo studio della coscienza e del pensiero e non per caso numerosi neurofisiologi contemporanei si occupano anche di filosofia della mente.   == Collegamenti esterni == Neurofisiologia, in Tesauro del Nuovo soggettario, BNCF, marzo 2013.
"Nel campo dell'apprendimento automatico, una rete neurale artificiale e un modello matematico composto di ""neuroni"" artificiali, che si ispira a una rete neurale. Questi modelli matematici possono essere utilizzati sia per ottenere una comprensione delle reti neurali biologiche, ma ancor di piu per risolvere problemi ingegneristici di intelligenza artificiale come quelli che si pongono in diversi ambiti tecnologici (in elettronica, informatica, simulazione, e altre discipline). Una rete neurale artificiale puo essere realizzata sia da programmi software che da hardware dedicato (DSP, Digital Signal Processing). Questa branca puo essere utilizzata in congiunzione alla logica fuzzy.   == Fondamenti ==  Una rete neurale artificiale (ANN ""Artificial Neural Network"" in inglese), normalmente chiamata solo ""rete neurale"" (NN ""Neural Network"" in inglese), e un modello matematico/informatico di calcolo basato sulle reti neurali biologiche. Tale modello e costituito da un gruppo di interconnessioni di informazioni costituite da neuroni artificiali e processi che utilizzano un approccio di connessionismo di calcolo. Nella maggior parte dei casi una rete neurale artificiale e un sistema adattivo che cambia la sua struttura basata su informazioni esterne o interne che scorrono attraverso la rete durante la fase di apprendimento. In termini pratici le reti neurali sono strutture non-lineari di dati statistici organizzate come strumenti di modellazione. Esse possono essere utilizzate per simulare relazioni complesse tra ingressi e uscite che altre funzioni analitiche non riescono a rappresentare. Una rete neurale artificiale riceve segnali esterni su uno strato di nodi (unita di elaborazione) d'ingresso, ciascuno dei quali e collegato con numerosi nodi interni, organizzati in piu livelli. Ogni nodo elabora i segnali ricevuti e trasmette il risultato a nodi successivi.   == Storia == L'ampia varieta di modelli non puo prescindere dal costituente di base, il neurone artificiale proposto da W.S. McCulloch e Walter Pitts in un famoso lavoro del 1943: ""A logical calculus of the ideas immanent in nervous activity"", il quale schematizza un combinatore lineare a soglia, con dati binari multipli in entrata e un singolo dato binario in uscita: un numero opportuno di tali elementi, connessi in modo da formare una rete, e in grado di calcolare semplici funzioni booleane. Le prime ipotesi di apprendimento furono introdotte da D. O. Hebb nel libro del 1949: ""The organization of behavior"", nel quale vengono proposti collegamenti con i modelli complessi del cervello. Nel 1958, J. Von Neumann nella sua opera ""The computer and the brain"" esamina le soluzioni proposte dai precedenti autori sottolineando la scarsa precisione che queste strutture possedevano per potere svolgere operazioni complesse. Nello stesso anno, F. Rosenblatt nel libro ""Psychological review"" introduce il primo schema di rete neurale, detto Perceptron (percettrone), antesignano delle attuali reti neurali, per il riconoscimento e la classificazione di forme, allo scopo di fornire un'interpretazione dell'organizzazione generale dei sistemi biologici. Il modello probabilistico di Rosenblatt e quindi mirato all'analisi, in forma matematica, di funzioni quali l'immagazzinamento delle informazioni, e della loro influenza sul riconoscimento dei pattern; esso costituisce un progresso decisivo rispetto al modello binario di McCulloch e Pitts, perche i suoi pesi sinaptici sono variabili e quindi il percettrone e in grado di apprendere. L'opera di Rosenblatt stimola una quantita di studi e ricerche che dura per un decennio, e suscita un vivo interesse e notevoli aspettative nella comunita scientifica, destinate tuttavia ad essere notevolmente ridimensionate allorche nel 1969 Marvin Minsky e Seymour A. Papert, nell'opera ""An introduction to computational geometry"", mostrano i limiti operativi delle semplici reti a due strati basate sul percettrone, e dimostrano l'impossibilita di risolvere per questa via molte classi di problemi, ossia tutti quelli non caratterizzati da separabilita lineare delle soluzioni: questo tipo di rete neurale non e abbastanza potente: non e infatti neanche in grado di calcolare la funzione or esclusivo (XOR). A causa di queste limitazioni, al periodo di euforia dovuto ai primi risultati della cibernetica (come veniva chiamata negli anni sessanta) segue un periodo di diffidenza durante il quale tutte le ricerche in questo campo non ricevono piu alcun finanziamento dal governo degli Stati Uniti d'America; le ricerche sulle reti tendono, di fatto, a ristagnare per oltre un decennio, e l'entusiasmo iniziale risulta fortemente ridimensionato. Il contesto matematico per addestrare le reti MLP (Multi-Layers Perceptron, ossia percettrone multistrato) fu stabilito dal matematico americano Paul Werbos nella sua tesi di dottorato (Ph.D.) del 1974. Non fu dato molto peso al suo lavoro tanto fu forte la confutazione dimostrata da Minsky e Papert anni prima, e solo l'intervento di J. J. Hopfield, nel 1982, che in un suo lavoro studia dei modelli di riconoscimento di pattern molto generali, si oppose in modo diretto alla confutazione di Minsky riaprendo cosi degli spiragli per la ricerca in questo campo. Uno dei metodi piu noti ed efficaci per l'addestramento di tale classe di reti neurali e il cosiddetto algoritmo di retropropagazione dell'errore (error backpropagation), proposto nel 1986 da David E. Rumelhart, G. Hinton e R. J. Williams, il quale modifica sistematicamente i pesi delle connessioni tra i nodi, cosi che la risposta della rete si avvicini sempre di piu a quella desiderata. Tale lavoro fu prodotto riprendendo il modello creato da Werbos. L'algoritmo di backpropagation (BP) e una tecnica d'apprendimento tramite esempi, costituente una generalizzazione dell'algoritmo d'apprendimento per il percettrone sviluppato da Rosenblatt nei primi anni '60. Mediante questa tecnica era possibile, come detto, trattare unicamente applicazioni caratterizzabili come funzioni booleane linearmente separabili. L'algoritmo di apprendimento si basa sul metodo della discesa del gradiente che permette di trovare un minimo locale di una funzione in uno spazio a N dimensioni. I pesi associati ai collegamenti tra gli strati di neuroni si inizializzano a valori piccoli (ovvero molto inferiori ai valori reali che poi assumeranno) e casuali e poi si applica la regola di apprendimento presentando alla rete dei pattern di esempio. Queste reti neurali sono poi capaci di generalizzare in modo appropriato, cioe di dare risposte plausibili per input che non hanno mai visto. L'addestramento di une rete neurale di tipo BP avviene in due diversi stadi: forward-pass e backward-pass. Nella prima fase i vettori in input sono applicati ai nodi in ingresso con una propagazione in avanti dei segnali attraverso ciascun livello della rete (forward-pass). Durante questa fase i valori dei pesi sinaptici sono tutti fissati. Nella seconda fase la risposta della rete viene confrontata con l'uscita desiderata ottenendo il segnale d'errore. L'errore calcolato e propagato nella direzione inversa rispetto a quella delle connessioni sinaptiche. I pesi sinaptici infine sono modificati in modo da minimizzare la differenza tra l'uscita attuale e l'uscita desiderata (backward-pass). Tale algoritmo consente di superare le limitazioni del percettrone e di risolvere il problema della separabilita non lineare (e quindi di calcolare la funzione XOR), segnando il definitivo rilancio delle reti neurali, come testimoniato anche dall'ampia varieta d'applicazioni commerciali: attualmente la BP rappresenta un algoritmo di largo uso in molti campi applicativi.   == Teoria e paradigmi di apprendimento ==   === Analisi del sistema di apprendimento di una rete neurale === Il concetto di rete neurale si pone perche una funzione                         f         (         x         )                 {\displaystyle f(x)}    e definita come una composizione di altre funzioni                         G         (         x         )                 {\displaystyle G(x)}   , che possono a loro volta essere ulteriormente definite come composizione di altre funzioni. Questo puo essere convenientemente rappresentato come una struttura di reti, con le frecce raffiguranti le dipendenze tra variabili. Una rappresentazione ampiamente utilizzata e la somma ponderata non lineare, dove                         f         (         x         )         =         k                    (                                                    i                                                w                            i                                                g                            i                                   (           x           )           )                          {\displaystyle f(x)=k\left(\sum _{i}w_{i}g_{i}(x)\right)}   , dove                         k                 {\displaystyle k}    e una funzione predefinita, come ad esempio la tangente iperbolica. Sara conveniente per le seguenti far riferimento ad un insieme di funzioni come un vettore                         g         =         (                    g                        1                             ,                    g                        2                             ,         ...         ,                    g                        n                             )                 {\displaystyle g=(g_{1},g_{2},\ldots ,g_{n})}   .  La Figura 1 esemplifica una decomposizione della funzione                         f                 {\displaystyle f}   , con dipendenze tra le variabili indicate dalle frecce. Queste possono essere interpretate in due modi: Il primo punto di vista e la vista funzionale: l'ingresso                         x                 {\displaystyle x}    e trasformato in un vettore a 3-dimensioni, che viene poi trasformato in un vettore bi-dimensionale                         g                 {\displaystyle g}   , che e poi finalmente trasformato in                         f                 {\displaystyle f}   . Questo punto di vista e piu comunemente riscontrato nel contesto dell'ottimizzazione. Il secondo punto di vista e la vista probabilistica: la variabile casuale                         F         =         f         (         G         )                 {\displaystyle F=f(G)}    dipende dalla variabile casuale                         G         =         g         (         H         )                 {\displaystyle G=g(H)}   , che dipende da                         H         =         h         (         X         )                 {\displaystyle H=h(X)}   , che dipende a sua volta dalla variabile casuale                         X                 {\displaystyle X}   . Questo punto di vista e piu comunemente riscontrato nel contesto dei modelli grafici. I due punti di vista sono in gran parte equivalenti. In entrambi i casi, per questa particolare architettura di rete, i componenti dei singoli strati sono indipendenti l'uno dall'altro (ad esempio, le componenti di                         g                 {\displaystyle g}    sono indipendenti l'uno dall'altro, dato il loro ingresso                         h                 {\displaystyle h}   ). Questo, naturalmente, permette un certo grado di parallelismo nella costruzione del sistema.  Reti, come ad esempio quelle precedenti vengono comunemente chiamate ""feedforward"", perche il loro e un grafico aciclico diretto. Reti con cicli al loro interno sono comunemente chiamati reti ricorrenti. Tali reti sono comunemente raffigurate nel modo indicato nella parte superiore della Figura 2, dove la funzione                         f                 {\displaystyle f}    e mostrata come dipendente su se stessa. Tuttavia, vi e una dipendenza temporale implicita che non e possibile dimostrare. Questo significa in pratica che il valore di                         f                 {\displaystyle f}    ad un certo punto nel tempo                         t                 {\displaystyle t}    dipende dai valori di                         f                 {\displaystyle f}    al tempo zero o su uno o piu altri punti temporali. Il modello del grafico nella parte inferiore della Figura 2 illustra il caso in cui il valore di                         f                 {\displaystyle f}    al tempo                         t                 {\displaystyle t}    dipende solo dal suo valore finale. Tuttavia la funzionalita piu interessante di queste funzioni, cio che ha attirato l'interesse e lo studio per la maggior parte delle reti neurali, e la possibilita di apprendimento, che in pratica significa la seguente: dato un compito specifico da risolvere, ed una classe di funzioni                         F                 {\displaystyle F}   , apprendimento significa impiegare un set di osservazioni, al fine di trovare                                    f                                                              F                 {\displaystyle f^{*}\in F}    che risolve il problema in modo ottimale. Cio comporta la definizione di una funzione di costo                         C         :         F                             R                          {\displaystyle C:F\rightarrow \mathbb {R} }    tale che, per la soluzione ottimale                         C         (                    f                                                     )                  C         (         f         )                 {\displaystyle C(f^{*})\leq C(f)}                                     f                  F                 {\displaystyle \forall f\in F}    nessuna soluzione ha un costo inferiore al costo della soluzione ottimale. La funzione di costo                         C                 {\displaystyle C}    e un concetto importante nell'apprendimento, poiche si tratta di una misura di quanto e lontana da noi la soluzione ottimale del problema che vogliamo risolvere. Quindi vi sono una serie di algoritmi di apprendimento che cercano nello spazio delle soluzioni al fine di trovare una funzione che abbia il minor costo possibile. Per applicazioni in cui la soluzione dipende da alcuni dati, il costo deve essere necessariamente funzione delle osservazioni. Mentre e possibile definire per alcune reti una funzione di costo ad hoc, spesso si puo utilizzare una particolare funzione di costo poiche gode delle proprieta desiderate (ad esempio, la convessita), o perche proviene da una particolare formulazione del problema (vale a dire, in una formulazione probabilistica, la probabilita a posteriori del modello puo essere utilizzata come l'inverso del costo). In ultima analisi, la funzione di costo dipendera dal compito.   === Paradigmi di apprendimento === Vi sono tre grandi paradigmi di apprendimento, ciascuno corrispondente ad un particolare compito astratto di apprendimento. Si tratta dell'apprendimento supervisionato, apprendimento non supervisionato e l'apprendimento per rinforzo. Di solito un tipo di architettura di rete puo essere impiegato in qualsiasi di tali compiti. un apprendimento supervisionato (supervised learning), qualora si disponga di un insieme di dati per l'addestramento (o training set) comprendente esempi tipici d'ingressi con le relative uscite loro corrispondenti: in tal modo la rete puo imparare ad inferire la relazione che li lega. Successivamente, la rete e addestrata mediante un opportuno algoritmo (tipicamente, la backpropagation che e appunto un algoritmo d'apprendimento supervisionato), il quale usa tali dati allo scopo di modificare i pesi ed altri parametri della rete stessa in modo tale da minimizzare l'errore di previsione relativo all'insieme d'addestramento. Se l'addestramento ha successo, la rete impara a riconoscere la relazione incognita che lega le variabili d'ingresso a quelle d'uscita, ed e quindi in grado di fare previsioni anche laddove l'uscita non e nota a priori; in altri termini, l'obiettivo finale dell'apprendimento supervisionato e la previsione del valore dell'uscita per ogni valore valido dell'ingresso, basandosi soltanto su un numero limitato di esempi di corrispondenza (vale a dire, coppie di valori input-output). Per fare cio, la rete deve essere infine dotata di un'adeguata capacita di generalizzazione, con riferimento a casi ad essa ignoti. Cio consente di risolvere problemi di regressione o classificazione. un apprendimento non supervisionato (unsupervised learning), basato su algoritmi d'addestramento che modificano i pesi della rete facendo esclusivamente riferimento ad un insieme di dati che include le sole variabili d'ingresso. Tali algoritmi tentano di raggruppare i dati d'ingresso e di individuare pertanto degli opportuni cluster rappresentativi dei dati stessi, facendo uso tipicamente di metodi topologici o probabilistici. L'apprendimento non supervisionato e anche impiegato per sviluppare tecniche di compressione dei dati. un apprendimento per rinforzo (reinforcement learning), nel quale un opportuno algoritmo si prefigge lo scopo di individuare un certo modus operandi, a partire da un processo d'osservazione dell'ambiente esterno; ogni azione ha un impatto sull'ambiente, e l'ambiente produce una retroazione che guida l'algoritmo stesso nel processo d'apprendimento. Tale classe di problemi postula un agente, dotato di capacita di percezione, che esplora un ambiente nel quale intraprende una serie di azioni. L'ambiente stesso fornisce in risposta un incentivo o un disincentivo, secondo i casi. Gli algoritmi per il reinforcement learning tentano in definitiva di determinare una politica tesa a massimizzare gli incentivi cumulati ricevuti dall'agente nel corso della sua esplorazione del problema. L'apprendimento con rinforzo differisce da quello supervisionato poiche non sono mai presentate delle coppie input-output di esempi noti, ne si procede alla correzione esplicita di azioni subottimali. Inoltre, l'algoritmo e focalizzato sulla prestazione in linea, la quale implica un bilanciamento tra esplorazione di situazioni ignote e sfruttamento della conoscenza corrente.   === Apprendimento hebbiano (1984) === L'algoritmo di apprendimento Hebbiano si basa sul semplice principio che se due neuroni si attivano contemporaneamente, la loro interconnessione deve essere rafforzata.                                             w                        i                             =                             x                        i             n             ,             i                                        x                        o             u             t                                     {\displaystyle \Delta w_{i}=\eta x_{in,i}x_{out}}    dove                                    x                        i             n             ,             i                                     {\displaystyle x_{in,i}}   , dove                         i                 {\displaystyle i}    e l'                                   i                        m             o                                     {\displaystyle i^{mo}}    ingresso e                                          {\displaystyle \eta }    e il tasso di apprendimento                         (         0         <                           1         )                 {\displaystyle (0<\eta \leq 1)}   . La regola di Hebb e la seguente: l'efficacia di una particolare sinapsi cambia se e solo se c'e un'intensa attivita simultanea dei due neuroni, con un'alta trasmissione di input nella sinapsi in questione. Esempio di procedura: Inizializza i pesi a zero. Prepara un pattern d'ingresso a cui corrisponde un pattern d'uscita noto. Calcola                                             w                        i                             =                             x                        i             n             ,             i                                        x                        o             u             t                                     {\displaystyle \Delta w_{i}=\eta x_{in,i}x_{out}}    e quindi aggiorna                                    w                        i                             =                    w                        i                             +                             w                        i                                     {\displaystyle w_{i}=w_{i}+\Delta w_{i}}   . Ripeti i passi 2 e 3 per ogni pattern                         j                 {\displaystyle j}    noto                                    w                        i                             =                                            j                                        (                                   w                            i                                   )           j                          {\displaystyle w_{i}=\sum _{j}{(\Delta w_{i})j}}    In questo modo le connessioni possono solo irrobustirsi. Le connessioni si considerano irrobustite quando le unita presinaptica e postsinaptica sono d'accordo, altrimenti si indeboliscono. Si considerano funzioni bipolari (-1,1) invece che booleane (0,1).   == Teoria e funzionamento ==   === Funzionamento di una rete neurale feedforward === Le reti neurali si basano principalmente sulla simulazione di neuroni artificiali opportunamente collegati. Il modello rappresentato in figura e quello proposto da McCulloch e Pitts.  I suddetti neuroni ricevono in ingresso degli stimoli e li elaborano. L'elaborazione puo essere anche molto sofisticata ma in un caso semplice si puo pensare che i singoli ingressi vengano moltiplicati per un opportuno valore detto peso, il risultato delle moltiplicazioni viene sommato e se la somma supera una certa soglia il neurone si attiva attivando la sua uscita. Il peso indica l'efficacia sinaptica della linea di ingresso e serve a quantificarne l'importanza, un ingresso molto importante avra un peso elevato, mentre un ingresso poco utile all'elaborazione avra un peso inferiore. Si puo pensare che se due neuroni comunicano fra loro utilizzando maggiormente alcune connessioni allora tali connessioni avranno un peso maggiore, fino a che non si creeranno delle connessioni tra l'ingresso e l'uscita della rete che sfruttano ""percorsi preferenziali"". Tuttavia e sbagliato pensare che la rete finisca col produrre un unico percorso di connessione: tutte le combinazioni infatti avranno un certo peso, e quindi contribuiscono al collegamento ingresso/uscita. Il modello in figura rappresenta una classica rete neurale pienamente connessa.  I singoli neuroni vengono collegati alla schiera di neuroni successivi, in modo da formare una rete di neuroni. Normalmente una rete e formata da tre strati. Nel primo abbiamo gli ingressi (I), questo strato si preoccupa di trattare gli ingressi in modo da adeguarli alle richieste dei neuroni. Se i segnali in ingresso sono gia trattati puo anche non esserci. Il secondo strato e quello nascosto (H, hidden), si preoccupa dell'elaborazione vera e propria e puo essere composto anche da piu colonne di neuroni. Il terzo strato e quello di uscita (O) e si preoccupa di raccogliere i risultati ed adattarli alle richieste del blocco successivo della rete neurale. Queste reti possono essere anche molto complesse e coinvolgere migliaia di neuroni e decine di migliaia di connessioni. Per costruire la struttura di una rete neurale multistrato si possono inserire                         N                 {\displaystyle N}    strati Hidden; vi sono pero alcune dimostrazioni che mostrano che con 1 o 2 strati di Hidden si ottiene una stessa efficace generalizzazione da una rete rispetto a quella con piu strati Hidden. L'efficacia di generalizzare di una rete neurale multistrato dipende ovviamente dall'addestramento che ha ricevuto e dal fatto di essere riuscita o meno ad entrare in un minimo locale buono.   === Algoritmo di backpropagation === L'algoritmo di backpropagation e utilizzato nell'apprendimento con supervisione. Esso permette di modificare i pesi delle connessioni in modo tale che si minimizzi una certa funzione errore E. Tale funzione dipende dal vettore h-esimo di output                                                                                 o                 u                 t                                                                               h                                     {\displaystyle {\overline {out}}^{h}}    restituito dalla rete, dato il vettore h-esimo di ingresso                                                                x                                                                h                                     {\displaystyle {\overline {x}}^{h}}    e dal vettore h-esimo di output                                                                y                                                                h                                     {\displaystyle {\overline {y}}^{h}}   che noi desideriamo (che fa parte del training set). Il training set e dunque un insieme di N coppie di vettori                         (                                                x                                                                h                             ,                                                y                                                                h                             )                 {\displaystyle ({\overline {x}}^{h},{\overline {y}}^{h})}   , con                         h         =         1         ,         .         .         .         ,         N                 {\displaystyle h=1,...,N}   . La funzione errore che si deve minimizzare si puo scrivere come:                         E         (         w         )         =                                 1             2                                                                h                                                                k                             (         o         u                    t                        k                                   h                                                 y                        k                                   h                                        )                        2                                     {\displaystyle E(w)={\frac {1}{2}}\sum _{h}\sum _{k}(out_{k}^{h}-y_{k}^{h})^{2}}    dove l'indice k rappresenta il valore corrispondente al k-esimo neurone di output. E(w) e una funzione dipendente dai pesi (che in generale variano nel tempo), per minimizzarla si puo usare l'algoritmo della discesa del gradiente (gradient-descent). L'algoritmo parte da un punto generico                                                 x                                           (         0         )                 {\displaystyle {\overline {x}}(0)}    e calcola il gradiente                                  f         (                                                x                                                                0                             )                 {\displaystyle \nabla f({\overline {x}}^{0})}   . Il gradiente da la direzione verso cui muoversi lungo la quale si ha il massimo incremento (o decremento se considero                                                   {\displaystyle -\nabla }   ). Definita la direzione ci si muove di una distanza                                          {\displaystyle \eta }    predefinita a priori e si trova un nuovo punto                                                 x                                           (         1         )                 {\displaystyle {\overline {x}}(1)}    sul quale e calcolato nuovamente il gradiente. Si continua iterativamente finche il gradiente non e nullo. L'algoritmo di backpropagation puo essere diviso in due passi: Forward pass: l'input dato alla rete e propagato al livello successivo e cosi via ai livelli successivi (il flusso di informazioni si sposta in avanti, cioe forward). Si calcola dunque E(w), l'errore commesso. Backward pass: L'errore fatto dalla rete e propagato all'indietro (backward) e i pesi sono aggiornati in maniera appropriata. I passi logici per addestrare una rete neurale con apprendimento supervisionato sono i seguenti: Creare un insieme di pattern input ed il relativo insieme di pattern di output desiderati Inizializzare i pesi della rete neurale (le connessioni tra i neuroni) a dei valori casuali, piccoli rispetto ai valori futuri che assumeranno, ed a norma nulla. Ciclo di apprendimento (esce da questo ciclo solo quando l'errore generale e minore di quanto si e deciso oppure dopo un determinato numero di iterazioni) Ciclo feedforward (dallo strato di input a quello di output) estrarre un pattern di input a caso tra quelli a disposizione[nota] calcolare il valore di tutti i neuroni successivi (sommatorie di produttorie) detrarre dal risultato il valore di soglia di attivazione del neurone (se il valore di soglia non e gia stato simulato con l'aggiunta di un neurone ad ingresso fisso a valore 1.0) filtrare l'uscita del neurone applicando una funzione logistica per far diventare tale valore input del neurone successivo  Confrontare il risultato ottenuto della rete con il pattern di output relativo all'input inserito e ricavare l'errore attuale della rete Ciclo di backpropagation (dallo strato di output a quello di input) calcolare la correzione da apportare ai pesi secondo la regola di localizzazione del minimo scelta applicare la correzione ai pesi dello strato  (nota) al fine di avere un buon addestramento, le estrazioni vengono effettuate senza reinserimento: quando un pattern viene estratto, esso non partecipa alle estrazioni successive; dunque, di volta in volta, si pesca dall'insieme dei pattern non ancora estratti. Una volta che tutti i pattern vengono estratti, si puo eventualmente ripetere il processo da zero, ripartendo dall'intero insieme di pattern di input.   == Tipi di rete neurale ==   === Reti di Hopfield === Nel 1982, il fisico John J. Hopfield pubblica un articolo fondamentale in cui presenta un modello matematico comunemente noto appunto come rete di Hopfield: tale rete si distingue per ""l'emergere spontaneo di nuove capacita computazionali dal comportamento collettivo di un gran numero di semplici elementi d'elaborazione"". Le proprieta collettive del modello producono una memoria associativa per il riconoscimento di configurazioni corrotte e il recupero di informazioni mancanti. Inoltre, Hopfield ritiene che ogni sistema fisico possa essere considerato come un potenziale dispositivo di memoria, qualora esso disponga di un certo numero di stati stabili, i quali fungano da attrattore per il sistema stesso. Sulla base di tale considerazione, egli si spinge a formulare la tesi secondo cui la stabilita e la collocazione di tali attrattori sono proprieta spontanee di sistemi costituiti, come accennato, da considerevoli quantita di neuroni reciprocamente interagenti. Tra le nuove idee messe in luce da Hopfield, quella piu degna di menzione riguarda il capovolgimento del rapporto, fino allora esistente, tra calcolo e numeri: mentre era universalmente noto che il calcolo producesse numeri, assai meno banale era l'osservazione di Hopfield che, viceversa, anche i numeri potessero spontaneamente generare calcolo, e che questo potesse emergere quale attributo collettivo di sistemi interattivi siffatti. Le applicazioni delle reti di Hopfield riguardano principalmente la realizzazione di memorie associative, resistenti all'alterazione delle condizioni operative, e la soluzione di problemi d'ottimizzazione combinatoriale. Da un punto di vista strutturale, la rete di Hopfield costituisce una rete neurale ricorrente simmetrica, di cui e garantita la convergenza. Una rete ricorrente e un modello neurale in cui e presente un flusso bidirezionale d'informazioni; in altri termini, mentre nelle reti di tipo feedforward la propagazione dei segnali avviene unicamente, in maniera continua, nella direzione che conduce dagli ingressi alle uscite, nelle reti ricorrenti tale propagazione puo anche manifestarsi da uno strato neurale successivo ad uno precedente, oppure tra neuroni appartenenti ad uno stesso strato, e persino tra un neurone e se stesso.   === Reti di Elman === Un significativo e noto esempio di semplice rete ricorrente e dovuto a Jeffrey L. Elman (1990). Essa costituisce una variazione sul tema del percettrone multistrato, con esattamente tre strati e l'aggiunta di un insieme di neuroni ""contestuali"" nello strato d'ingresso. Le connessioni retroattive si propagano dallo strato intermedio (e nascosto) a tali unita contestuali, alle quali si assegna peso costante e pari all'unita. In ciascun istante, gli ingressi si propagano nel modo tradizionale e tipico delle reti feedforward, compresa l'applicazione dell'algoritmo d'apprendimento (solitamente la backpropagation). Le connessioni retroattive fisse hanno come effetto quello di mantenere una copia dei precedenti valori dei neuroni intermedi, dal momento che tale flusso avviene sempre prima della fase d'apprendimento. In questo modo la rete di Elman tiene conto del suo stato precedente, cosa che le consente di svolgere compiti di previsione di sequenze temporali che sono difficilmente alla portata dei percettroni multistrato convenzionali.   === Mappe auto-organizzanti o reti SOM (Self-Organizing Maps) === Infine, un ultimo interessante tipo di rete e costituita dalla cosiddetta mappa auto-organizzante o rete SOM (Self-Organizing Map). Tale innovativo tipo di rete neurale e stata elaborata da Teuvo Kohonen dell'Universita Tecnologica di Helsinki; il suo algoritmo d'apprendimento e senza dubbio una brillante formulazione di apprendimento non supervisionato, e ha dato luogo a un gran numero di applicazioni nell'ambito dei problemi di classificazione. Una mappa o rete SOM e basata essenzialmente su un reticolo o griglia di neuroni artificiali i cui pesi sono continuamente adattati ai vettori presentati in ingresso nel relativo insieme di addestramento. Tali vettori possono essere di dimensione generica, anche se nella maggior parte delle applicazioni essa e piuttosto alta. Per cio che riguarda le uscite della rete, al contrario, ci si limita di solito ad una dimensione massima pari a tre, il che consente di dare luogo a mappe 2D o 3D. In termini piu analitici, l'algoritmo puo essere agevolmente descritto, come accennato, nei termini di un insieme di neuroni artificiali, ciascuno con una precisa collocazione sulla mappa rappresentativa degli output, che prendono parte ad un processo noto come winner takes all (Il vincitore piglia tutto), al termine del quale il nodo avente un vettore di pesi piu vicino ad un certo input e dichiarato vincitore, mentre i pesi stessi sono aggiornati in modo da avvicinarli al vettore in ingresso. Ciascun nodo ha un certo numero di nodi adiacenti. Quando un nodo vince una competizione, anche i pesi dei nodi adiacenti sono modificati, secondo la regola generale che piu un nodo e lontano dal nodo vincitore, meno marcata deve essere la variazione dei suoi pesi. Il processo e quindi ripetuto per ogni vettore dell'insieme di training, per un certo numero, usualmente grande, di cicli. Va da se che ingressi diversi producono vincitori diversi. Operando in tal modo, la mappa riesce alfine ad associare i nodi d'uscita con i gruppi o schemi ricorrenti nell'insieme dei dati in ingresso. Se questi schemi sono riconoscibili, essi possono essere associati ai corrispondenti nodi della rete addestrata. In maniera analoga a quella della maggioranza delle reti neurali artificiali, anche la mappa o rete SOM puo operare in due distinte modalita: durante la fase di addestramento si costruisce la mappa, pertanto la rete si configura ed organizza tramite un processo competitivo. Alla rete deve essere fornito il numero piu grande possibile di vettori in ingresso, tali da rappresentare fedelmente il tipo di vettore che le sara eventualmente sottoposta nella seconda fase; nel corso della seconda fase ogni nuovo vettore d'ingresso puo essere velocemente classificato o categorizzato, collocandolo in automatico sulla mappa ottenuta nella fase precedente. Vi sara sempre un unico neurone vincente, quello il cui vettore dei pesi giace a minor distanza dal vettore appena sottoposto alla rete; tale neurone puo essere determinato semplicemente calcolando la distanza euclidea tra i due vettori in questione.   === Reti ad attrattori === In generale una ANN (Attractor Neural Network) e una rete di nodi (es: biologicamente ispirati), spesso interconnessi in modo ricorsivo, la cui dinamica nel tempo stabilisce un assestamento in un particolare modo di oscillazione. Questo modo di oscillazione puo essere stazionario, variante nel tempo o di tipo stocastico ed e chiamato il suo 'attrattore'. In neuroscienza teorica diversi tipi di reti ad attrattori sono state associate a differenti funzioni, come: memoria, attenzione, condotta del moto e classificazione. Piu precisamente, una rete ad attrattori e una rete di N nodi connessi in modo che la loro intera dinamica diventi stabile in uno spazio D dimensionale, dove usualmente N>>D. Cio assume che non vi sia piu input dall'esterno del sistema. La stabilita nello stato ad attrattore indica l'esistenza di uno stato stabile in una qualche varieta algebrica (es: linea, cerchio, piano, toroide).   == Applicazioni e proprieta == L'utilita dei modelli di rete neurale sta nel fatto che queste possono essere usate per comprendere una funzione utilizzando solo le osservazioni sui dati. Cio e particolarmente utile nelle applicazioni in cui la complessita dei dati o la difficolta di elaborazione rende la progettazione di una tale funzione impraticabile con i normali procedimenti di analisi manuale. I compiti a cui le reti neurali sono applicate possono essere classificate nelle seguenti grandi categorie di applicazioni: Funzioni di approssimazione, o di regressione, tra cui la previsione di serie temporali e la modellazione. Classificazione, compresa la struttura e la sequenza di generici riconoscimenti, l'individuazione delle novita ed il processo decisionale. L'elaborazione dei dati, compreso il ""filtraggio"" (eliminazione del rumore), il clustering, separazione di segnali e compressione. Le aree di applicazione includono i sistemi di controllo (controllo di veicoli, controllo di processi), simulatori di giochi e processi decisionali (backgammon, scacchi), riconoscimento di pattern (sistemi radar, identificazione di volti, riconoscimento di oggetti, ecc), riconoscimenti di sequenze (riconoscimento di gesti, riconoscimento vocale, OCR), diagnosi medica, applicazioni finanziarie, data mining, filtri spam per e-mail.   === Pregi === Le reti neurali per come sono costruite lavorano in parallelo e sono quindi in grado di trattare molti dati. Si tratta in sostanza di un sofisticato sistema di tipo statistico dotato di una buona immunita al rumore; se alcune unita del sistema dovessero funzionare male, la rete nel suo complesso avrebbe delle riduzioni di prestazioni ma difficilmente andrebbe incontro ad un blocco del sistema. I software di ultima generazione dedicati alle reti neurali richiedono comunque buone conoscenze statistiche; il grado di apparente utilizzabilita immediata non deve trarre in inganno, pur permettendo all'utente di effettuare subito previsioni o classificazioni, seppure con i limiti del caso. Da un punto di vista industriale, risultano efficaci quando si dispone di dati storici che possono essere trattati con gli algoritmi neurali. Cio e di interesse per la produzione perche permette di estrarre dati e modelli senza effettuare ulteriori prove e sperimentazioni.   === Difetti === I modelli prodotti dalle reti neurali, anche se molto efficienti, non sono spiegabili in linguaggio simbolico umano: i risultati vanno accettati ""cosi come sono"", da cui anche la definizione inglese delle reti neurali come ""black box"": in altre parole, a differenza di un sistema algoritmico, dove si puo esaminare passo-passo il percorso che dall'input genera l'output, una rete neurale e in grado di generare un risultato valido, o comunque con una alta probabilita di essere accettabile, ma non e possibile spiegare come e perche tale risultato sia stato generato. Come per qualsiasi algoritmo di modellazione, anche le reti neurali sono efficienti solo se le variabili predittive sono scelte con cura. Non sono in grado di trattare in modo efficiente variabili di tipo categorico (per esempio, il nome della citta) con molti valori diversi. Necessitano di una fase di addestramento del sistema che fissi i pesi dei singoli neuroni e questa fase puo richiedere molto tempo, se il numero dei record e delle variabili analizzate e molto grande. Non esistono teoremi o modelli che permettano di definire la rete ottima, quindi la riuscita di una rete dipende molto dall'esperienza del creatore.   === Utilizzi === Le reti neurali vengono solitamente usate in contesti dove i dati possono essere parzialmente errati oppure dove non esistano modelli analitici in grado di affrontare il problema. Un loro tipico utilizzo e nei software di OCR, nei sistemi di riconoscimento facciale e piu in generale nei sistemi che si occupano di trattare dati soggetti a errori o rumore. Esse sono anche uno degli strumenti maggiormente utilizzati nelle analisi di Data mining. Le reti neurali vengono anche utilizzate come mezzo per previsioni nell'analisi finanziaria o meteorologica. Negli ultimi anni e aumentata notevolmente la loro importanza anche nel campo della bioinformatica nel quale vengono utilizzate per la ricerca di pattern funzionali e/o strutturali in proteine e acidi nucleici. Mostrando opportunamente una lunga serie di input (fase di training o apprendimento), la rete e in grado di fornire l'output piu probabile. Negli ultimi anni inoltre sono in corso studi per il loro utilizzo nella previsione degli attacchi Epilettici (Analisi dei Dati provenienti dall' EEG). Recenti studi hanno dimostrato buone potenzialita delle reti neurali in sismologia per la localizzazione di epicentri di terremoti e predizione della loro intensita.   == Bibliografia == Ernesto Burattini e Roberto Cordeschi, Intelligenza Artificiale, Roma, Carocci, ISBN 88-430-2011-0 Patarnello S., Le reti neuronali, Milano, Franco Angeli, 1991. ISBN 978-88-204-6819-4 Giampiero Fabbri e Raimondello Orsini, Reti neurali per le scienze economiche, Franco Muzzio editore, 1993. ISBN 88-7021-656-X Meraviglia C., Le reti neurali nella ricerca sociale, Bologna, Il Mulino, 2001. ISBN 978-88-464-3044-1 Floreano D., Mattiussi C., Manuale sulle reti neurali, Bologna, Il Mulino, 2002. ISBN 978-88-15-08504-7 Pessa E., Statistica con le reti neurali, Roma, Di Renzo Editore, 2004. ISBN 978-88-8323-074-5 Amit, D. J., Modeling brain function, 1989 New York, NY: Cambridge University Press. ISBN 0-521-36100-1 Gallo C., Reti Neurali Artificiali: Teoria ed applicazioni finanziarie, 2007 Foggia, Universita di Foggia.   == Voci correlate == EDLUT Apprendimento automatico Rete neurale a base radiale   == Altri progetti ==   Wikimedia Commons contiene immagini o altri file su rete neurale artificiale   == Note ==   == Collegamenti esterni == Programma da scaricare e provare che mostra come una rete neurale apprende dagli input. (e disponibile anche un video), e-nuts.net. Esempio di rete neurale realizzata in Matlab, cash-cow.it. Descrizione del funzionamento di una rete neurale di tipo feed-forward, skenz.it. Esempio di un neurone e di una rete neurale realizzato in C#, xleox.somee.com. Rete neurale artificiale, in Tesauro del Nuovo soggettario, BNCF, marzo 2013."
"La funzione sigmoidea e una funzione matematica che produce una curva sigmoide; una curva avente un andamento ad ""S"". Spesso, la funzione sigmoide si riferisce ad uno speciale caso di funzione logistica mostrata a destra e definita dalla formula:                         P         (         t         )         =                                 1                            1               +                                e                                                       t                                                                                  {\displaystyle P(t)={\frac {1}{1+e^{-t}}}}      == Membri della famiglia sigmoidea == Generalmente, una funzione sigmoidea e una funzione continua e derivabile, avendo una derivata prima non negativa o non positiva e dotata di un minimo locale ed un massimo locale. Oltre alla funzione logistica, le funzioni sigmoidee includono la funzione arcotangente, tangente iperbolica e funzione di errore. Spesso inoltre e usata in statistica come funzione di distribuzione cumulata, infatti la forma ad ""S"" e per molti terreno comune per distribuzioni di probabilita. La funzione sigmoidea logistica e collegata con la tangente iperbolica, per esempio da:                         2                                 1                            1               +                                e                                                       x                                                                                   1         =         tanh                                          x             2                                     {\displaystyle 2{\frac {1}{1+e^{-x}}}-1=\tanh {\frac {x}{2}}}      == Funzioni sigmoidee nelle reti neurali == Le funzioni sigmoidee sono spesso usate nelle reti neurali per introdurre la non linearita nel modello e/o per assicurarsi che determinati segnali rimangano all'interno di specifici intervalli. Un popolare elemento neurale artificiale computa la combinazione lineare dei relativi segnali in ingresso ed applica una funzione sigmoidea limitata al risultato; questo modello puo essere visto come variante regolare del classico neurone soglia. Un motivo per la relativa popolarita nelle reti neurali e perche la funzione sigmoidea soddisfa questa proprieta:                                                 d                            d               t                                                                  s             i             g                             (         t         )         =                                 s             i             g                             (         t         )                    (           1                                                  s               i               g                                   (           t           )           )                          {\displaystyle {\frac {d}{dt}}{\rm {sig}}(t)={\rm {sig}}(t)\left(1-{\rm {sig}}(t)\right)}    Questa relazione polinomiale semplice fra la derivata e la funzione stessa e, dal punto di vista informatico, semplice da implementare.   == Doppia funzione sigmoidea == Il doppio sigmoideo e una funzione simile alla funzione sigmoidea con numerose applicazioni. La relativa formula generale e:                         y         =                    sign                  (         x                  d         )                                          {                             1                  exp                                          [                                                              (                                                                    x                              d                          s                                                                    )                                                2                                                     ]                                                     }                             ,                 {\displaystyle y={\mbox{sign}}(x-d)\,{\Bigg \{}1-\exp {\bigg [}-{\bigg (}{\frac {x-d}{s}}{\bigg )}^{2}{\bigg ]}{\Bigg \}},}    dove d e il centro e s e il fattore di steepness. Essa e basata sulla curva gaussiana ed e graficamente simile a due sigmoidi identiche legate insieme al punto x = d. Una delle relative applicazioni e la normalizzazione non lineare di un campione.   == Altri progetti ==   Wikimedia Commons contiene immagini o altri file su Funzione sigmoidea"
"La scienza olistica e un paradigma scientifico che enfatizza lo studio dei sistemi complessi. Non e una disciplina scientifica in se stessa, ma definisce piuttosto un approccio filosofico in cui viene considerato il principio di emergenza nell'applicare il metodo scientifico, spesso utilizzando un metodo ampiamente interdisciplinare o multidisciplinare. Questo approccio e in contrasto con la tradizione puramente analitica, che si propone di interpretare i sistemi complessi dividendoli nelle loro componenti e studiandone separatamente le proprieta.   == Aspetti centrali dell'approccio olistico == Il termine ""scienza olistica"" e stato usato come categoria per includere numerosi campi di ricerca scientifica. Questi campi, considerati potenzialmente olistici, hanno alcune caratteristiche in comune. In primo luogo, sono multidisciplinari. Secondo, sono incentrati sul comportamento dei sistemi complessi. Terzo, riconoscono il meccanismo del feedback tra sistemi come elemento cruciale per la comprensione del loro comportamento. Il Santa Fe Institute, un centro di ricerca olistica negli USA, esprime cosi questo concetto: Le due caratteristiche principali dello stile di ricerca del SFI sono l'indirizzo verso un approccio multidisciplinare e l'enfasi sullo studio di problemi che prevedono interazioni complesse tra le loro parti costituenti.   == Opposizione al riduzionismo == Alcuni sostenitori dell'olismo considerano la scienza ortodossa come scienza riduzionista ed il paradigma riduzionista come riduzionismo sfrenato. Questa definizione allude alla tendenza della scienza classica a procedere con un approccio modulare: a dividere, cioe, un sistema in parti piu semplici da studiare. La convinzione dell'olismo e che puo esistere una differenza qualitativa tra un sistema e la somma delle sue parti: la suddivisione in moduli puo portare all'errore. L'approccio quindi si diversifica non tanto per l'oggetto dello studio, quanto per i metodi e le basi scelte per studiarlo. Detto questo, i metodi olistici generalmente non sono in contrapposizione al metodo scientifico classico. In particolare nel caso in cui gli scienziati olistici provengano da un background scientifico standard, l'approccio olistico tende ad essere una sintesi dei due. Ad esempio, la psicologia della Gestalt nasce a partire dalla psicologia sperimentale classica.   == Esempi di campi di studio scientifico olistico == Molte discipline scientifiche sono influenzate dal paradigma olistico. In alcune l'olismo e ampiamente accettato come corrente principale, mentre in altre esso e considerato protoscientifico, se non pseudoscientifico.   === Dinamiche dei sistemi === Nello studio delle dinamiche dei sistemi, che nasce al MIT, il metodo scientifico e organizzato secondo un paradigma olistico, ma i risultati della scienza riduzionista vengono utilizzati per definire le relazioni tra variabili statiche nella procedura di modelling e quindi per consentire la simulazione delle dinamiche del sistema studiato.   === Teoria della complessita === La ricerca sulla teoria della complessita, fortemente improntata in senso olistico, e iniziata negli anni Ottanta al Santa Fe Institute, che e tuttora leader nel campo.   === Scienze cognitive === Il campo delle scienze cognitive, che hanno come oggetto di studio la mente e l'intelligenza, presenta alcune forme di approccio olistico. Questo e ad esempio il caso della teoria unificata della cognitivita di Allen Newell e di molte altre, che si basano sul concetto di emergenza, intesa come l'interrelazione di molte entita che vanno a costituire un insieme funzionale. Al contrario, gli approcci non olistici funzionalisti in questo campo includono ad esempio il paradigma della modularita della mente. Le scienze cognitive non si limitano solo a studiare la mente umana: esistono anche ricerche scientifiche olistiche sulla cognitivita animale (Mark Bekoff).   === Reti neurali e intelligenza artificiale === Un altro campo di ricerca olistica riguarda il tentativo di simulare il cervello umano e di costruire sistemi che funzionino alla stessa maniera. Questa disciplina viene chiamata intelligenza artificiale: in particolare il sotto-campo delle reti neurali viene considerato olistico, poiche si basa sull'assunto che le connessioni e i feedback tra nodi semplici collegati in un sistema possano dare origine ad un comportamento intelligente o comunque basato sulla cognitivita.   === Altri esempi === L'ecologia, o scienza ecologica, puo essere intesa come lo studio della biosfera come risultato delle interrelazioni tra popolazioni, comunita, ecosistemi. Lo studio dei cambiamenti climatici puo essere considerato uno studio olistico, poiche il clima (e la Terra stessa) e un sistema complesso. La quasi totalita dei climatologi intende questo nell'accezione della dinamica dei sistemi, ma alcuni studiosi ritengono che non si possa applicare al clima un metodo di studio scientifico con le tecnologie attualmente a disposizione. E in atto un progetto chiamato Progetto di Coscienza Globale (Global Consciousness Project) che utilizza una rete fisica di generatori di numeri casuali per registrare eventi di importanza globale, allo scopo di valutare l'ipotesi che esista una sorta di ""coscienza umana collettiva"" in azione nel mondo. Nel 1810, Johann Wolfgang von Goethe pubblico un libro, La Teoria dei Colori (Das Farbenlehre), che criticava radicalmente non solo i principi di ottica newtoniana dominanti a quel tempo, ma anche l'intera metodologia illuminista della scienza riduzionista. Nonostante la teoria non sia stata ben accettata dagli scienziati del tempo, Goethe, uno degli intellettuali piu importanti dell'Europa moderna, la considerava il suo risultato piu importante. I teorici e gli scienziati olistici di oggi come Rupert Sheldrake considerano La teoria dei Colori uno dei migliori esempi di scienza olistica.   == Scienza olistica in ambito accademico == Probabilmente a causa della natura multidisciplinare dell'approccio olistico, c'e voluto del tempo prima che le istituzioni accademiche si aprissero alle idee olistiche. Alcune universita hanno aperto centri dedicati a discipline in cui il paradigma olistico e predominante. Tra queste possiamo citare la University of Michigan (Center for the Study of Complex Systems), la Princeton University (il Global Consciousness Project), la Rice University (Cognitive Sciences Program), e la London Metropolitan University (Centre for Postsecular Studies). Lo Schumaker College, nel Regno Unito, offre un corso di laurea in Scienza Olistica. Esistono anche numerose istituzioni accademiche non universitarie dedicate alla scienza olistica o aperte alle idee olistiche, ad esempio il Santa Fe Institute e la Scientific and Medical Network in Europa.   == Opposizione alla scienza olistica == La scienza olistica e controversa. Secondo alcuni si tratta di pseudoscienza, poiche non applica rigorosamente il metodo scientifico nonostante usi un linguaggio apparentemente scientifico. Il giornalista scientifico John Horgan ha espresso questo punto di vista in un libro . Egli vede nella scienza olistica un modello di ""criticalita autoorganizzata"" che e ""meramente una descrizione, una delle tante, delle fluttuazioni casuali, del rumore di fondo che permea la natura."" Dal suo punto di vista questo modello ""non puo generare ne specifiche predizioni riguardo alla natura, ne risultati significativi"".   == Note ==   == Bibliografia == Alberto F. De Toni, Luca Comello. Prede o ragni. q:Prede o ragni Paul Davies and John Gribbin. The Matter Myth: Dramatic Discoveries That Challenge Our Understanding of Physical Reality. Amazon link. Article ""What is the Proper Relationship of Holistic and Reductionist Science?"" by Karl North, geocities.com. Article ""The Fine Line: (W)holism and Science"" by Annemarie Colbin, Ph.D., foodandhealing.com. Article ""A New Image of Cosmos & Anthropos: From Ancient Wisdom to a Philosophy of Wholeness"" by Michael R. Meyer, khaldea.com. Excerpts from Holistic Science - towards a second Renaissance by R.J.C. Wilding (unpublished book in process) Article ""Concerning the Spiritual in Art and Science"" by Mike King (available on-line) Article ""Patterns of Wholeness: Introducing Holistic Science"" by Brian Goodwin, from the journal Resurgence Article ""From Control to Participation"" by Brian Goodwin, from the journal Resurgence Introduction to Goethe's Way of Science: A Phenomenology of Nature, edited by David Seamon and Arthur Zajonc. State University of New York Press, 1998   == Voci correlate == Sistemi complessi Olismo Riduzionismo scientifico   == Collegamenti esterni == Santa Fe Institute, santafe.edu. International Society for the System Sciences, isss.org. Center for the Study of Complex Systems at the University of Michigan Rice Cognitive Sciences Program, ruf.rice.edu. Princeton University Global Consciousness Project, noosphere.princeton.edu. Centre for Postsecular Studies at the London Metropolitan University Massachusetts Institute of Technology, web.mit.edu."
"Il connessionismo e un modello delle scienze cognitive che per spiegare il funzionamento della mente si ispira alla struttura del cervello in quanto costituito da reti neurali. La sua diffusione si deve soprattutto al lavoro degli psicologi americani David Rumelhart e James McClelland. Il connessionismo nell'intelligenza artificiale propone un nuovo modello per la costruzione e programmazione di hardware e software ispirati al cervello umano che elabora le informazioni dei vari sensi in maniera parallela, evitando il cosiddetto ""Von Neumann bottleneck"" dei modelli contemporanei, dove tutte le informazioni devono passare per la CPU serialmente. Oltre a questo suggerisce un modello distribuito per la rappresentazione delle informazioni nella memoria. Le informazioni all'interno di una rete neurale (biologica o artificiale che sia) sono distribuite per tutti i vari nodi della rete e non in un ""posto"" singolo. Non si puo piu quindi puntare ad una parte determinata del sistema e dire che questa unita contiene una determinata informazione o svolge un determinato compito specifico. Il connessionismo suggerisce quindi un modello di ""Parallel Distributed Processing"" (PDP): Elaborazione a parallelismo distribuito delle informazioni.   == Reti Neurali == In una rete neurale artificiale ogni ""nodo"" funziona secondo un principio simile ad un neurone biologico. In un neurone biologico ogni connessione sinaptica di un neurone ha un certo ""peso"" che influenza la forza del segnale ricevuto. Nel neurone si sommano tutti i segnali ricevuti dalle varie sinapsi e se questa somma e piu grande di un certo 'valore di soglia', allora il neurone ""spara"", trasmettendo un segnale ad altri neuroni nella rete. Ogni nodo in una rete neurale artificiale simula questo comportamento tramite delle connessioni analoghe alle sinapsi di un neurone biologico e tramite una funzione di attivazione, che stabilisce quando il neurone spara. Nella forma piu semplice, questa funzione di attivazione puo essere di generare un ""1"" se l'input sommato e piu grande di un certo valore, o al contrario uno ""0"" se il segnale ricevuto rimane sotto la soglia. La funzione di attivazione, tuttavia, puo essere anche alquanto piu complessa.   == Simbolismo e Connessionismo == Molti vedono il connessionismo in opposizione al simbolismo. Il simbolismo e una forma specifica del cognitivismo che sostiene che l'attivita mentale sia solo calcolo, cioe che la mente funziona essenzialmente come una macchina di Turing. Le differenze di fondo sono le seguenti: I simbolisti presuppongono modelli di simboli che non assomigliano per niente alla struttura del cervello, mentre i connessionisti esigono che i loro modelli assomiglino alle strutture neurologiche. I simbolisti generalmente si interessano solo alla struttura dei simboli e delle regole sintattiche per la loro manipolazione, mentre i connessionisti guardano all'apprendimento da stimoli ambientali e alla memorizzazione di queste informazioni nei collegamenti fra neuroni. I simbolisti credono che l'attivita mentale interna consista nella manipolazione dei simboli (come nella teoria del linguaggio del pensiero di Jerry Fodor), mentre i connessionisti credono che la manipolazione di simboli sia un modello dell'attivita mentale molto povero e semplificato.   == Bibliografia == Rosenblatt, Frank (1958), The Perceptron: A Probabilistic Model for Information Storage and Organization in the Brain, Cornell Aeronautical Laboratory, Psychological Review, v65, No. 6, pp. 386408. Rumelhart, D.E., J.L. McClelland and the PDP Research Group (1986), Parallel Distributed Processing: Explorations in the Microstructure of Cognition. Volume 1: Foundations, Cambridge, MA: MIT Press McClelland, J.L., D.E. Rumelhart and the PDP Research Group (1986), Parallel Distributed Processing: Explorations in the Microstructure of Cognition. Volume 2: Psychological and Biological Models, Cambridge, MA: MIT Press in italiano David E. Rumelhart, James L. McClelland. PDP. Microstruttura dei processi cognitivi, Sistemi Intelligenti, Bologna, Il Mulino, 1991, Trad. di R. Luccio e M. Ricucci, ISBN 978-88-15-02883-9. Domenico Parisi, Intervista sulle reti neurali. Bologna, Il Mulino, 1989. ISBN 978-88-15-02301-8.   == Voci correlate == John Watson (psicologo) Frank Rosenblatt Neurone McCulloch-Pitts Percettrone Rete neurale artificiale (PDP = ""parallel distributed processing"")   == Collegamenti esterni == Introduzione al connessionismo (PDF), tulliotinti.net. Il connessionismo (PDF) (EN) Edward N. Zalta (a cura di), Connectionism, in Stanford Encyclopedia of Philosophy, Center for the Study of Language and Information (CSLI), Universita di Stanford."
"La neuropsicologia e la disciplina che ha come obiettivo lo studio dei processi cognitivi e comportamentali correlandoli con i meccanismi anatomo-fisiologici a livello di sistema nervoso che ne sottendono il funzionamento. Studia nell'uomo le alterazioni delle funzioni cognitive causate da lesioni o disfunzioni focali o diffuse del sistema nervoso centrale, acquisite, congenite, geneticamente determinate. Si basa sul metodo scientifico ed ha aree di sovrapposizione con altre discipline come la psicologia, la neurologia, la psichiatria e le reti neurali, condividendo il punto di vista del processamento dell'informazione della mente tipico della psicologia cognitiva (o cognitivismo). I neuropsicologi lavorano nelle universita (ricerca di base e applicata), in cliniche o ospedali (coinvolti nel trattamento di pazienti con problemi neurologici e neuropsicologici), nell'industria (es. farmaceutica) o in altre strutture ove sia richiesta una competenza scientifica sul funzionamento fisiologico e patologico del sistema nervoso.   == Oggetto di studio == Per meglio definirla rispetto alle altre neuroscienze, la neuropsicologia si occupa prevalentemente dello studio delle funzioni cognitive e delle loro correlazioni con le strutture encefaliche; in particolare, la neuropsicologia clinica focalizza le relative alterazioni derivanti a danni anatomo-patologici di varia eziologia. I pazienti tipici saranno quindi soggetti cerebrolesi da lesioni traumatiche, vascolari, tumori cerebrali e malattie degenerative. Una parte della neuropsicologia, la neuropsicologia dello sviluppo, e rivolta alla comprensione dello sviluppo del comportamento in relazione allo sviluppo cerebrale. La corrente prevalente nella neuropsicologia moderna si basa sul quadro teorico proposto dalla psicologia cognitiva, la quale studia la mente in termini di sistema cognitivo paragonabile a un ""elaboratore di informazioni"" suddiviso in diverse componenti funzionalmente interconnesse, per studiare le relazioni tra i diversi circuiti neurali e le funzioni cognitive. Il sistema cognitivo comprende quindi vari moduli, intesi come sottosistemi funzionali isolabili (secondo alcune ipotesi esistono anche processi ""centrali"" non suddivisibili in moduli) e il compito della neuropsicologia e associare a ogni modulo il circuito neuronale che lo rende possibile; questi circuiti neuronali possono estendersi in piu aree cerebrali. La maggior parte del lavoro riguarda lo studio clinico su soggetti cerebrolesi. Sono presenti anche studi in soggetti sani (meglio definiti come neurologicamente sani), utilizzati spesso come gruppo di controllo rispetto ai pazienti oppure per comprendere il funzionamento fisiologico della funzione indagata. Il fine ultimo della neuropsicologia e infatti la comprensione della relazione tra mente e cervello. Sebbene la neuropsicologia moderna sia improntata al cognitivismo, e giusto citare l'approccio teorico che ha caratterizzato la sua nascita e il suo sviluppo fino alla rivoluzione cognitivista: la neuropsicologia classica, la quale aveva come scopo quello di associare una localizzazione precisa e univoca ai processi mentali all'interno del cervello, osservando la correlazione tra sede precisa della lesione cerebrale e processo mentale alterato, ricavato dalla descrizione clinica del paziente. Il suo fine ultimo era dunque la stretta correlazione anatomo-clinica, la quale si e pero rivelata eccessivamente riduzionista e non basata su una cornice teorica che potesse collegare le conoscenze acquisite ai concetti della psicologia generale.   == Neuropsicologia clinica == La neuropsicologia clinica e l'applicazione delle conoscenze della neuropsicologia alla diagnosi, gestione e riabilitazione dei pazienti con deficit cognitivi successivi a malattie o danni cerebrali di tipo vascolare o traumatico. La pratica della neuropsicologia clinica e in costante aumento ed in continua evoluzione, attualmente le sue applicazioni si estendono dal settore clinico, alla ricerca, alla riabilitazione, sino all'ambito giuridico-forense e alla medicina legale. In particolare vengono esaminati i pazienti per diagnosticare e migliorare le funzioni specifiche lese come ad esempio linguaggio, attenzione, percezione, cognizione e comportamento. La valutazione delle funzioni cognitive e comportamentali richiede professionalita e competenza specifiche e rappresenta un momento delicato all'interno dell'intero processo diagnostico del deficit encefalico. Lo Specialista in Neuropsicologia ha sviluppato comprovata esperienza teorica e pratica nel campo dei disordini cognitivi associati a lesioni encefaliche. Egli e in grado di valutare il deficit, monitorarne l'evoluzione temporale, organizzare i programmi di riabilitazione e gli interventi atti a favorire il compenso funzionale. Lo Specialista in Neuropsicologia possiede una formazione di alto livello, laurea specialistica o magistrale e specializzazione post lauream. Il Decreto Ministeriale del 24/07/2006 (pubblicato sulla G.U. del 21/10/2006) ha, infatti, sancito che l'unico percorso formativo valido all'acquisizione del titolo di Specialista in Neuropsicologia sia quello offerto dalle scuole di specializzazione universitarie aperte ai soli psicologi. I neuropsicologi clinici lavorano tipicamente in un ambiente ospedaliero, in un team interdisciplinare composto da professionisti di diversa formazione come neurologi, psicologi, internisti, logopedisti, ortottisti, terapisti occupazionali e terapisti della neuro e della psicomotricita dell'eta evolutiva.   == Strumenti == Gli strumenti principali della neuropsicologia sia sperimentale che clinica sono i test psicometrici, che permettono di valutare i diversi processi cognitivi e le loro componenti, talora utilizzati in combinazione con tecniche di presentazione tachistoscopica e di ascolto dicotico. La neuropsicologia sperimentale si avvale anche di strumenti propri della psicofisiologia (EEG, potenziali evento-relati, ecc.) e della neuroradiologia. Le neuroimmagini sono di supporto sia allo studio delle lesioni successive a danno cerebrale sia per la localizzazione di specifiche aree (tomografia computerizzata e imaging a risonanza magnetica). Un'altra applicazione delle tecniche di neuroimaging e in soggetti sani sono le cosiddette tecniche di neuroimaging funzionali (fMRI, PET SPECT) che permettono di ottenere una rappresentazione dell'attivazione di aree specifiche del cervello durante l'esecuzione di determinati compiti. Tecniche recentemente sviluppate, sebbene di maggiore interesse neurofisiologico, sono la stimolazione magnetica transcranica (TMS), un metodo in grado di stimolare selettivamente alcune zone del cervello in modo tale da poterne osservare le reazioni corrispondenti, e la srimolazione transcranica a corrente diretta (tDCS). La ricerca di base e applicata utilizza comunque una combinazione di tutti questi approcci sia su soggetti patologici che sani.   == Tecnologie == Colloquio clinico Test neuropsicologici, psicometrici e comportamentali Neuroimaging Neuroimaging funzionale Misure elettrofisiologiche (EEG; PEV; MEP; magnetoencefalografia) Stimolazione magnetica transcranica Stimolazione transcranica a corrente diretta (tDCS) Ricerche comportamentali   == Metodi == Studi di casi singoli Studi di gruppo Dissociazione e doppia dissociazione Associazione di sintomi   == Note ==   == Bibliografia == Denes, G.; Pizzamiglio, L. (1996) Manuale di neuropsicologia, Bologna, Zanichelli, ISBN 9788808090966 Ladavas, E.; Berti, A. (2002) Neuropsicologia, Bologna, Il Mulino, ISBN 9788815088987 Mazzucchi, A. (1999) La riabilitazione neuropsicologica, Milano, Elsevier Masson, ISBN 9788821428999 Umilta, C. (1999) Manuale di neuroscienze, Bologna, Il Mulino, ISBN 9788815071521 Marini, A. Manuale di Neurolinguistica. Fondamenti teorici, tecniche di indagine, applicazioni. Roma: Carocci, 2008 Denes, G. (2009) Parlare con la testa, Bologna, Zanichelli Lurjia, A. R. Problemi fondamentali d neurolinguistica. Roma: Armando Editore, 1978. Marini A. e Carlomagno, S. Analisi del discorso e patologia del linguaggio. Milano: Springer, 2004. Marini A. e Nocentini, U. Comunicazione verbale e emisfero destro. Milano: Springer, 2003. Fabbro F. Concise Encyclopedia of Language Pathology. Oxford: Pergamon, 1999.   == Voci correlate == Neurologia Neuropsicologia clinica Psicologia fisiologica Neuroscienze   == Altri progetti ==   Wikimedia Commons contiene immagini o altri file su neuropsicologia   == Collegamenti esterni == Neuropsicologia, in Tesauro del Nuovo soggettario, BNCF, marzo 2013. http://www.aisn.pro La Neuropsicologia in Italia (PDF), ordpsicologier.it."
"L'apprendimento approfondito (in inglese deep learning) e quel campo di ricerca dell'apprendimento automatico e dell'intelligenza artificiale che si basa su diversi livelli di rappresentazione, corrispondenti a gerarchie di caratteristiche di fattori o concetti, dove i concetti di alto livello sono definiti sulla base di quelli di basso. Tra le architetture di apprendimento approfondito si annoverano le reti neurali profonde, la convoluzione di reti neurali profonde, le Deep belief network, e reti neurali ricorrenti, che sono state applicati nella computer vision, nel riconoscimento automatico del discorso, nell'elaborazione del linguaggio naturale, nel riconoscimento audio e nella bioinformatica. ""Deep learning"" e un'espressione oggi famosa che rida lustro al concetto di rete neurale.   == Storia ==   == Architetture ==   === Reti neurali profonde ===   === Reti neurali convoluzionali === La Rete neurale convoluzionale (Convolution Neural Network CNN) e un metodo di scelta per elaborare dati visuali e dati di tipo 2D. Una CNN e composta da uno piu strati convoluzionali con strati completamente connessi verso l'alto. Usa anche pesi e strati comuni (pooling layers). In particolare il ""max-pooling"" e spesso usato nell'architettura convoluzionale di Fukushima. Quest'architettura permette alle CNN di avedere dei vantaggi dalle strutture 2D di ingresso. Sono particolarmente efficaci nell'area delle immagini e di riconoscimento del discorso. Possono essere allenate anche con la backpropagation standard. Sono inoltre facili da allenare rispetto ad altre reti neurali profonde o feed-forward ed hanno molti meno parametri da stimare. Un programma di CNN e il DeepDream di Google.   === Reti neurali ricorsive ===   === Compressore di storia neurale ===   === Reti Deep Belief ===   === Autoencoder impilato ===   === Rete di impilamento profondo ===   === Rete di impilamento profondo di tensore ===   === Spike-and-slab RBM ===   === Macchine di Boltzmann profonde ===   === Macchine kernel multilivello ===   === Strutture di memoria differenziabile LSTM correlata ===   === Reti deep-q === Questa e una classe di modelli d'apprendimento profondi usando il Q-learning, una forma di apprendimento con rinforzo, del Google DeepMind. Risultati preliminari presentati nel 2014 con un articolo pubblicato su Nature nel febbraio 2015. L'applicazione di cui si fa riferimento e un gioco dell'Atari 2600.   === Hashing semantico ===   == Applicazione == Riconoscimento automatico del discorso Riconoscimento di immagini Elaborazione del linguaggio naturale Scoperta di farmaci e tossicologia Customer relationship management Sistema di raccomandazione Bioinformatica   == Librerie software == Torch  Libreria software open source di machine learning in Lua Theano  Libreria open source di machine learning in Python. Deeplearning4j  Libreria open source di deep learning in Java. Fornisce parallelizzazione di CPU e GPU. [1] OpenNN  Libreria open source in C++ che impementa reti neurali profonde e fornisce parallelizazzioni con CPU. Gensim  Libreria di elaborazione del linguaggio naturale in Python. Apache SINGA  A deep learning platform developed for scalability, usability and extensibility. TensorFlow  Libreria open source di machine learning in C++ e Python con API per entrambe le versioni di Google. Fornisce parallelizzazione con CPU e GPU.   == Note ==   == Collegamenti esterni == (EN) Deep learning, deeplearning.net. (EN) Video on Recent Developments in Deep Learning, di Geoff Hinton"
"Eduardo Renato Caianiello (Napoli, 25 giugno 1921  Napoli, 22 ottobre 1993) e stato un fisico italiano.   == Biografia == Laureato in Fisica all'Universita di Napoli nel 1944, consegui il PhD all'Universita di Rochester (Stato di New York) nel 1950. Dopo avere insegnato a Torino, Roma e Princeton, dal 1956 e stato professore di Fisica Teorica, prima all'Universita di Napoli e poi, dal 1973, nell'Universita di Salerno. I suoi principali contributi hanno riguardato la Teoria Quantistica dei Campi e la cibernetica. In particolare e stato un pioniere nello studio delle Reti Neurali. Ha affiancato alla ricerca scientifica un'intensa attivita organizzativa e direttiva. Ha fondato e diretto l'Istituto di Fisica Teorica dell'Universita di Napoli, il Laboratorio di Cibernetica del CNR ad Arco Felice (Napoli), la Facolta di Scienze Matematiche, Fisiche e Naturali dell'Universita di Salerno, l'Istituto Internazionale per gli Alti Studi Scientifici (IIASS) a Vietri sul Mare (Salerno) e la Scuola di Perfezionamento in Scienze cibernetiche e fisiche.   == Teoria delle reti neurali == I suoi principali contributi riguardano la teoria delle reti neurali adattive. Fondamentale contributo in tal senso e l'Equazione di Caianiello (Caianiello's equation) con cui si formalizza la teoria dell'apprendimento hebbiano.   == Eredita culturale == Molti sono gli allievi e continuatori del pensiero scientifico di Caianiello. Tra questi: Francesco Guerra, Francesco Lauria, Salvatore Rampone, Luigi Maria Ricciardi, Aldo de Luca, Giuseppe Trautteur.   == Note ==   == Collegamenti esterni == Istituto di Cibernetica ""Eduardo Caianiello"", cib.na.cnr.it. Ricordando Eduardo Caianiello (PDF), ulisse.sissa.it. Istituto Internazionale per gli Alti Studi Scientifici ""E.R. Caianiello"", iiassvietri.it."
"Una rete neurale feed-forward (""rete neurale alimentata per andare avanti"") o rete feed-forward e una rete neurale artificiale dove le connessione tra le unita non formano cicli, differenziandosi dalle reti neurali ricorrenti. Questo tipo di rete neurale fu la prima e piu semplice tra quelle messe a punto. In questa rete neurale le informazioni si muovono solo in una direzione, avanti, rispetto a nodi d'ingresso, attraverso nodi nascosti (se esistenti) fino ad i nodi d'uscita. Nella rete non ci sono cicli.   == Percettrone a singolo strato ==   == Percettrone multistrato ==   == Note ==   == Voci correlate == Percettrone   == Collegamenti esterni == (EN) Feedforward neural networks tutorial (EN) Feedforward Neural Network: Example (EN) Feedforward Neural Networks: An Introduction"
La rappresentazione della conoscenza e una branca dell'intelligenza artificiale che studia il modo in cui avviene il ragionamento umano, e si preoccupa di definire dei simbolismi o dei linguaggi che permettano di formalizzare la conoscenza al fine di renderla comprensibile alle macchine, per potervi fare dei ragionamenti automatici (inferendo le informazioni presenti) ed estrarre cosi nuova conoscenza. Quindi un punto chiave della rappresentazione della conoscenza e la definizione di linguaggi che siano sufficientemente espressivi da permettere di descrivere il dominio di interesse, ma non troppo ricchi di espressivita, in quanto richiederebbero troppe risorse e/o troppo tempo per applicarvi i meccanismi inferenziali. In linea generale, i linguaggi di rappresentazione della conoscenza forniscono sia una serie di costrutti per definire la sintassi del dominio di interesse (le regole sulle quali costruire delle asserzioni accettabili), sia una serie di operatori (quantificatori, operatori modali, etc.) che permettano di dare un significato, un valore di verita alle asserzioni rispetto al modello di riferimento. Attraverso il linguaggio scelto si andranno ad effettuare una serie di asserzioni sul mondo, che andranno insieme a costituire una base di conoscenza (KB, Knowledge Base). E inoltre importante che il linguaggio scelto per fare le asserzioni sia anche in grado di operare sulla KB per estrarre nuova conoscenza e per aggiungerne di nuova. Esistono principalmente due metodologie per rappresentare la conoscenza: I linguaggi formali Gli alberi di decisione.   == Voci correlate == ragionamento automatico Web semantico Ontologia (informatica) Ontologia (in senso filosofico) Intelligenza artificiale Logiche descrittive Linguaggi formali Sistema esperto Base di conoscenza Matchmaking   == Altri progetti ==   Wikimedia Commons contiene immagini o altri file su Rappresentazione della conoscenza
SKOS e l'acronimo di Simple Knowledge Organisation System ed e una famiglia di linguaggi formali creata per rappresentare glossari, classificazioni, tassonomie e qualsiasi tipo di vocabolario strutturato. SKOS si basa su RDF e RDFS e il suo obiettivo principale e di consentire una facile pubblicazione di vocabolari strutturati per il Semantic Web. SKOS e progettato come una famiglia di linguaggi modulari ed estensibili. Il suo uso e la sua implementazione dovrebbe essere il piu semplice possibile.   == Collegamenti esterni == (EN) W3C SKOS Home Page, w3.org. (EN) Presentation of SKOS at XTech 2005 Conference, idealliance.org.
"Una rete semantica e una forma di rappresentazione della conoscenza. E un grafo (orientato o non orientato) formato da vertici, che rappresentano concetti, e archi, che rappresentano relazioni semantiche tra i concetti. Le reti semantiche sono un tipo comune di dizionario leggibile da una macchina (dizionario elettronico).   == Origini == Le ""Reti Semantiche"" sono state inizialmente sviluppate per i calcolatori da Richard H. Richens del Cambridge Language Research Unit nel 1956 come un'interlingua (o ""lingua pivot"") per la traduzione automatica dei linguaggi naturali. Sono stati sviluppati da Robert F. Simmons nella System Development Corporation a Santa Monica nei primi anni del 1960 e in seguito hanno avuto una posizione di rilievo nel lavoro di M. Ross Quillian nel 1966. Dagli anni sessanta agli ottanta, l'idea di un collegamento semantico e stato sviluppato all'interno di ipertesti come la principale unita di base, o vertici, in una rete semantica. Queste idee sono state estremamente influenti, e ci sono stati molti tentativi di aggiungere link per la semantica a pagine HTML e XML.   == Esempi == Un esempio di rete semantica e il WordNet, un database lessicale della lingua inglese. WordNet comporta un semantica associativa abbastanza ampia, confrontato rispetto a reti piu formali. E possibile rappresentare descrizioni logiche usando reti semantiche come i grafi esistenziali o i correlati grafi concettuali di John F. Sowa. Questi hanno potere espressivo almeno pari allo standard della logica dei predicati del primo ordine. Diversamente da WordNet o da altre reti lessicali, le reti semantiche possono essere usate per una attendibile deduzione logica automatizzata. Alcuni ragionatori automatici sfruttano le proprieta della teoria dei grafi durante il processo. Ci sono anche tipi elaborativi di reti semantiche collegati con l'insieme corrispondenti di strumenti software utilizzati per conoscenze ingegneristiche lessicali, come il Semantic Network Processing System (SNePS), di Stuart C. Shapiro o il paradigma MultiNet di Hermann Helbig (MultiNet e un acronimo che sta per ""Multilayered ampliata Semantic Network""). Quest'ultimo e particolarmente adatto per la rappresentazione della semantica del linguaggio naturale e le espressioni utilizzate in diverse applicazioni NLP. Si puo considerare una mappa mentale come una forma libera di una rete semantica. Utilizzando i colori e le immagini si pone l'accento sulla generazione di una rete semantica che evoca creativita umana. Tuttavia, sussiste una grande differenza tra mappe mentali e reti semantiche, la struttura di una mappa mentale, con nodi che si propagano da un centro e sotto-nodi che si propagano da nodi, e gerarchica, mentre nelle reti semantiche ogni nodo puo essere collegato a qualsiasi nodo, hanno quindi una maggiore struttura eterarchica.   == Relazioni semantiche importanti == Meronimia (A e parte di B, quindi B ha A come sua parte) Olonimia (B e parte di A, quindi A ha B come sua parte) Iponimia (o troponimia) (A e subordinata a B; A e un tipo di B) Iperonimia (A e subordinata a B) Sinonimia (A denota la stessa cosa di B) Antonimia (A denota il concetto opposto a B)   == Voci correlate == Elaborazione del linguaggio naturale Logica descrittiva KL-ONE   == Altri progetti ==   Wikimedia Commons contiene immagini o altri file su Rete semantica   == Collegamenti esterni == (EN) Semantic Networks - John F. Sowa: http://www.jfsowa.com/pubs/semnet.htm"
Nell'ambito della rappresentazione della conoscenza, una base di conoscenza                         K         B                 {\displaystyle KB}    si dice completa se non esiste alcuna formula                                          {\displaystyle \alpha }    tale che                         K         B                                    K         B                                            {\displaystyle KB\nvDash \alpha \land KB\nvDash \neg \alpha }   . Un esempio di knowledge base con conoscenza incompleta puo essere                         K         B         :=         {         A                  B         }                 {\displaystyle KB:=\{A\lor B\}}    per cui abbiamo che                         K         B                 {\displaystyle KB}    non implica ne                         A                 {\displaystyle A}    ne                                  A                 {\displaystyle \neg A}   . Dato un KB coerente, per renderlo completo si puo assumere la cosiddetta ipotesi del mondo chiuso, che consiste nel considerare falsi tutti i letterali non implicati dalla base di conoscenza. Nell'esempio sopra, tuttavia, questo non funzionerebbe, in quanto renderebbe la base di conoscenza incoerente. Infatti, per                         K                    B                             :=         {         A                  B         ,                  A         ,                  B         }                 {\displaystyle KB':=\{A\lor B,\neg A,\neg B\}}    non esiste alcun modello. Data, invece, la base di conoscenza:                         K         B         :=         {         A                  B         ,         B         }                 {\displaystyle KB:=\{A\lor B,B\}}    e sfruttando l'ipotesi del mondo chiuso, si ha che                         K         B                  A                  K         B                  B                 {\displaystyle KB\nvDash A\land KB\vDash B}   , per cui, oltre ad essere completo, e anche coerente.   == Note ==   == Bibliografia == (EN) Francois Bry, Nicola Henze, Jan Mauszynski, Principles and Practice of Sematic Web Reasoning, 1a ed., Hannover, Springer, dicembre 2003, ISBN 3-540-20582-9.
"Topic Maps e una tecnologia del web semantico per l'organizzazione e la rappresentazione della conoscenza, approvata come standard ISO (ISO/IEC 13250:2003), che utilizza XML Topic Maps (XTM), una sintassi d'interscambio basata su XML e Linear Topic Map Notation (LTM), un formato abbreviato per editor di testo.   == Topic map == Una topic map e un indice analitico elettronico di piu risorse informative collocato a un livello distinto da quello delle risorse stesse. Questa distinzione tra il livello dell'indice e quello dei documenti fa si che vi sia integrazione di conoscenza tramite i link tra i soggetti stessi prima ancora che tramite i tradizionali link di cross reference tra i documenti. Una topic map consiste in una serie di nodi chiamati topic collegati tra di loro. Ogni topic costituisce un surrogato elettronico di un subject. Un subject e tutto cio che puo essere oggetto di un discorso: un concetto astratto, un oggetto concreto, una persona, un'opera, un luogo. La relazione tra un topic e il suo subject viene detta reification. I topic corrispondono alle voci di un indice analitico, le association ai rinvii ad altre voci nella forma ""vedi anche"" e le occurrence ai numeri delle pagine. Se un indice analitico non categorizza le relazioni associative tra le voci e un tesauro si limita a distinguere le relazioni associative tra i termini da quelle gerarchiche e preferenziali ricorrendo all'etichetta RT (Related term), una topic map categorizza le relazioni associative tra i topic permettendo all'utente di capire non solo che due topic sono associati ma anche il perche e il come. Per fare un esempio, Topic map non si limita ad indicare che tra Manzoni e Milano esiste un relazione associativa ma anche che essa e del tipo ""e nato a"".   == Caratteristiche di un topic == Topic Maps e quindi come RDF una tecnologia basata sul concetto di identita. Essa utilizza simboli che rappresentano cose identificabili sul web (anche se spesso non recuperabili in esso) per poter fare affermazioni su di esse. Topic map a differenza di RDF ha pero tre modi di fare asserzioni su di un topic e quindi su di un soggetto: le tre tipologie di topic characteristic (name, occurence e role in association). Un topic puo essere istanza di una o piu classi dette topic type. La relazione tra un topic e la sua classe corrisponde alla relazione gerarchica tra due termini all'interno di un tesauro. Un topic ha innanzitutto un base name. Se un topic reifica un soggetto che ha nomi in diverse lingue esso avra piu base name ciascuno compreso in uno scope distinto. In quest'ultimo caso per etichettare il topic un'applicazione potrebbe adottare il base name corrispondente al contesto linguistico selezionato dall'utente. Un topic puo avere anche delle variant, nomi che vengono adottati in particolari contesti di elaborazione quali l'ordinamento (ad esempio: Manzoni, Alessandro) o la presentazione (ad esempio: Manzoni) Una association e una relazione associativa tra due topic ognuno dei quali svolge un ruolo come membro all'interno di essa. Un association role svolto da un topic all'interno di una association e una topic characteristic del topic. Ogni association e una istanza di una classe detta association type. Una occurrence e una risorsa (o un riferimento ad essa) considerata rilevante per un topic. Essa puo essere esterna alla topic map (articolo, monografia, citazione, video, immagine) oppure in line (breve descrizione o data in forma di stringa).   === Scope === Ogni assegnazione di una topic characteristic a un topic e valida all'interno di un contesto detto scope, il quale se viene specificato e limitato altrimenti e illimitato. Lo scope e composto a sua volta da una serie di topic detti theme i quali possono essere raggruppati in classi. Lo scope di un base name puo essere ad esempio costituito da una combinazione di theme appartenenti alle classi lingua e epoca storica, quello di una occurrence da una combinazione di theme appartenenti alle classi livello di approfondimento , livello di accesso , lingua, quello di un association role da una combinazione di theme appartenenti alle classi livello di approfondimento, livello di accesso. Un tipo particolare di theme utilizzato per disambiguare topic che hanno lo stesso nome e lincidental theme. Se i topic da disambiguare appartengono a classi diverse (ad esempio Tosca l'opera e Tosca il personaggio) l'incidental theme sara un topic type(in tal caso Opera o Personaggio); se invece i topic da disambiguare appartengono alla stessa classe (ad esempio Paride il personaggio dell'Iliade e Paride il personaggio di Romeo e Giulietta) lincidental theme sara un topic associato alla definizione di ciascuno (quindi Iliade o Romeo e Giulietta).   == Identita di un topic == Le topic map possono essere fuse tra di loro. Questo processo, chiamato merging, implica la fusione dei topic che rappresentano uno stesso soggetto in un unico topic le cui topic characteristic saranno la somma di quelle dei topic originari. E opportuno a questo punto precisare che un topic puo reificare un soggetto che e una risorsa informativa (ad esempio una pagina web) e riferirsi ad esso attraverso il suo stesso URI, oppure puo reificare un soggetto che non e una risorsa informativa (ad esempio una persona o un oggetto) e riferirsi ad esso tramite l'URI di un'altra risorsa detta subject indicator la quale fornisce una indicazione univoca sulla sua identita (una descrizione testuale, una rappresentazione visiva o audio, eccetera). XTM permette di distinguere in base al contesto sintattico la diversa funzione di un URI. Due topic che reificano la stessa risorsa informativa, oppure un soggetto identificato da uno stesso subject indicator o che hanno lo stesso base name nello stesso scope (in base a una regola detta topic name constraint) dovranno essere fusi.   == Note ==   == Bibliografia == Paul Gabriele Weston, Dal controllo bibliografico alle reti documentarie (PDF), in Biblioteche Oggi, no 7, 2002, pp. 44-56. Federico Meschini, Le mappe topiche: come imparai a non preoccuparmi e ad amare i metadati, in Bollettino AIB, 2005, pp. 59-72. Salvatore Vassallo, Le mappe topiche come un ponte fra beni culturali di natura diversa, in Culture del testo e del documento, no 22, 2006, pp. 97-109. Jack Park, Sam Hunting, XML Topic Maps: Creating and Using Topic Maps for the Web, Boston, Addison-Wesley Longman, 2002, ISBN 0-201-74960-2. Lutz Maicher; Jack Park (a cura di), Charting the Topic Maps Research and Applications Landscape First International Workshop on Topic Map Research and Applications, TMRA 2005, Leipzig, Germany, October 6-7, 2005, Revised Selected Papers, Springer Berlin, 2006, DOI:10.1007/11676904, ISBN 978-3-540-32527-7. Lutz Maicher; Sigel Alexander; Lars Marius Garshol (a cura di), Leveraging the Semantics of Topic Maps Second International Conference on Topic Maps Research and Applications, TMRA 2006, Leipzig, Germany, October 11-12, 2006, Revised Selected papers, Springer Berlin, 2007, DOI:10.1007/978-3-540-71945-8, ISBN 978-3-540-71944-1. Lutz Maicher; Lars Marius Garshol (a cura di), Scaling Topic Maps: Third International Conference on Topic Maps Research and Applications, TMRA 2007 Leipzig, Germany, October 11-12, 2007 Revised Selected Papers, Springer Berlin, 2008, DOI:10.1007/978-3-540-70874-2, ISBN 978-3-540-70873-5. Giovanni Adorni, Coccoli Mauro, Vercelli Gianni, Vivanet Giuliano, Topic Maps e XTM per l'e-learning, in Journal of E-Learning and Knowledge Society (Je-LKS). Edizioni Giunti SpA, Firenze-Milano, vol. 3, no 3, settembre 2007, ISSN 1826-6223.   == Voci correlate == Web semantico Resource Description Framework (RDF) Mappa mentale Mappa concettuale   == Altri progetti ==   Wikimedia Commons contiene immagini o altri file su Topic Maps   == Collegamenti esterni == TopicMaps.org. TMXTM.it - Sito italiano sulle Topic Maps e XTM, tmxtm.it."
Un ragionatore automatico e un software in grado di svolgere dei ragionamenti su delle basi di conoscenza adeguatamente formalizzate. Il ragionamento, in questo caso, e inteso come la capacita di elaborare la base di conoscenza secondo alcune regole, in modo da validare ed analizzare la base di conoscenza stessa. Le possibilita del ragionatore dipendono strettamente dal linguaggio adoperato per formalizzare la base di conoscenza.   == Forme di ragionamento automatico == Validazione: controllo di coerenza interna della base di conoscenza. Analisi: esplicitazione, da parte del ragionatore, della conoscenza implicita nella base di conoscenza. Inferenza, o deduzione. Se il linguaggio adoperato prevede la possibilita di esprimere una conoscenza incompleta, il ragionatore potra individuare quei fatti che sono impliciti in tutti i possibili modelli che soddisfano la base di conoscenza. La possibilita di effettuare automaticamente l'inferenza e l'elemento che piu di altri mostra la differenza fra il ragionamento automatico e la semplice computazione.   == Impieghi == Un recente ambito di impiego dei ragionatori automatici e il web semantico, dove le basi di conoscenza possono essere espresse in vari linguaggi computabili, il piu espressivo dei quali e OWL.
In informatica i linked data o dati collegati sono una modalita di pubblicazione di dati strutturati atti ad essere collegati fra loro e quindi utilizzabili attraverso interrogazioni semantiche. Si basa su tecnologie e standard web aperti come HTTP e URI e ne estende l'applicazione per fornire informazioni che possano essere lette e comprese da computer. Questo rende possibile collegare e utilizzare dati provenienti da diverse sorgenti.   == Criteri == Tim Berners-Lee descrisse quattro criteri sui dati collegati: Usare URI per identificare oggetti. Usare HTTP URI in modo che questi oggetti possano essere referenziati e cercati da persone e user agent. Fornire informazioni utili sull'oggetto quando la sua URI e dereferenziata, usando formati standard come RDF. Includere link ad altre URI relative ai dati esposti per migliorare la ricerca di altre informazioni relative nel Web. Tim Berners-Lee presento i dati collegati alla conferenza TED del 2009.   == Componenti == URI (nello specifico, URI dereferenziabili) HTTP Resource Description Framework (RDF) Formati serializzabili (RDFa, RDF/XML, N3, Turtle e altri)   == Progetto Linking Open Data ==  L'obiettivo del progetto Linking Open Data del W3C e di estendere il Web pubblicando diversi open dataset come RDF sul Web e impostando link RDF tra i dati da differenti risorse. Nell'ottobre del 2007, i dataset contenevano piu di due miliardi di triple RDF, collegate da piu di due milioni di link RDF. Da maggio 2009 sono cresciuti a 4,2 miliardi di triple RDF, collegate da circa 142 milioni di link RDF.   == Note ==   == Voci correlate == Dati aperti (Open Data) DBpedia
Metadati Amministrativi Gestionali, in sigla MAG e uno standard per raccogliere metadati relativi a oggetti digitali creati nei progetti di digitalizzazione, e conforme agli standard internazionali. La versione 0 e stata creata nel 2001 dall'ICCU. L'ultima versione e la 2.0.1 del 2009. Ogni formato dei metadati e associato a un namespace per la terminologia e a uno schema XML per la struttura sintattica.   == Note ==   == Voci correlate == Dublin Core ISBD
L'Adobe Extensible Metadata Platform (XMP) e uno standard, creato da Adobe System Inc., per processare e archiviare informazione proprietaria in relazione al contenuto di un file. XMP standardizza la definizione, la creazione e il processo di metadati estensibili. Lo XMP serializzato puo essere incorporato in un gran numero di ben noti formati di file, senza interrompere la loro leggibilita per applicazioni che ignorano XMP. L'incorporazione di metadati evita molti problemi che si presentano quando i metadati sono memorizzati separatamente. XMP e usato nei PDF, in fotografia e in applicazione di fotoritocco.   == Software che lavorano con XMP == Esistono diversi strumenti per lavorare in lettura e scrittura con XMP tra cui: ACDsee, FotoWare 7.0, F-Spot, Microsoft Pro Photo Tools, Microsoft Windows Vista, XMP Manager, Zoner Photo Studio...   == Voci correlate == Resource Description Framework Metadato Exif Dublin Core Metadata Working Group Design rule for Camera File system   == Altri progetti ==   Wikimedia Commons contiene immagini o altri file su Extensible Metadata Platform   == Collegamenti esterni == Adobe XMP, adobe.com.
"Il termine thesaurus (o tesauro) e il nome che si usa per indicare una collezione di termini priva di definizioni che hanno in comune fra loro degli aspetti onomasiologici. E anche un titolo che designa una raccolta di termini, un vocabolario per opere lessicografiche, repertori scientifici, lessici storici. L'etimologia della parola e legata al latino thesaurus, e al greco antico  thesauros (cioe ""tesoreria""). In informatica si fa riferimento al thesaurus per l'insieme delle parole chiave che danno accesso a una banca dati o a vocabolari (con elenchi di sinonimi) associati a programmi di videoscrittura. La caratteristica principale di un tesauro e la sua capacita di facilitare la ricerca dei termini per mezzo di categorie generali.   == Il thesaurus in documentazione == Il thesauro e un elenco strutturato in cui le parole sono raggruppate per somiglianza semantica (contenente sinonimi e qualche volta antonimi); si differenzia dal dizionario che contiene definizioni e pronuncia. Secondo la definizione ISO il thesaurus e ""un vocabolario di un linguaggio di indicizzazione controllato in maniera formalizzata in modo che le relazioni a priori tra i concetti sono rese esplicite"" (ISO 2788-1986). Le relazioni tesaurali sono utilizzate per facilitare la navigazione nel thesauro agli utenti. Il thesauro inoltre si differenzia dall'ontologia, in quanto quest'ultima puo contenere relazioni piu complesse e una logica inferenziale inerente al modello. Le possibili relazioni tra i termini sono: gerarchiche BT - broader term: riferimento al termine piu generale NT - narrower term: riferimento a un termine piu specifico TT - top term: termine apicale  associative RT - related term: riferimento ad un termine associale in modo diverso da BT e NT  di equivalenza USE - rinvio da un termine non accettato ad uno accettato UF (use for) - riferimento da un termine accettato a uno non accettato  altri codici utilizzati nel Thesaurus SN - Scope note - nota d'uso HS - History note - nota storica Il maggior thesauro generalista italiano e quello del Nuovo soggettario curato dalla Biblioteca nazionale di Firenze. Nell'ambito del progetto di revisione del Soggettario usato dal 1956 dalle biblioteche italiane per l'indicizzazione per soggetto, la Biblioteca ha messo a punto un Manuale per la creazione dei soggetti ed un Thesaurus di termini da cui attingere   == Il thesaurus in informatica giuridica == In informatica giuridica, il thesaurus puo essere considerato una sorta di vocabolario dei termini presenti in una banca dati. Il suo scopo e quello di facilitare l'utente nella ricerca dei termini. Spesso chi compie una ricerca puo andare incontro a polisemie, sinonimie ecc. Il thesaurus, partendo da una categoria generale, guida il ricercatore fino all'uso della parola esatta, contenuta nella banca dati, che esprime esattamente il concetto che si voleva cercare. Le relazioni all'interno dei termini del thesaurus sono di gerarchia, preferenza o affinita.   == Note ==   == Bibliografia == Vanda Broughton, Costruire thesauri, Strumenti per indicizzazione e metadati semantici, Milano, Editrice Bibliografica, 2006. ISBN 9788870756746. Ferruccio Diozzi, Documentazione, Roma, 1998, AIB. ISBN 8878120588.   == Voci correlate == Analisi testuale Data mining Information brokering OPAC Motore di ricerca SKOS Nuovo soggettario"
